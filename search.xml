<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[随记-打印日志的思考]]></title>
    <url>%2F%E9%9A%8F%E8%AE%B0-%E6%89%93%E5%8D%B0%E6%97%A5%E5%BF%97%E7%9A%84%E6%80%9D%E8%80%83.html</url>
    <content type="text"><![CDATA[简介日志是软件工程的一部分，是设计中的一处代表设计人员和开发人员工作态度的细节之一，更像是生活中保险，也许它并不一定立即体现作用，但是在日后维护中，优秀的日志可能会节省很多的排查时间，记得看过一句话：”每一行代码写之前思考多一分钟，将来排查可能就少一小时。“环境介绍MAC OS Catalina 10.15.2JDK 8Spring Boot 2.1.6logbacklogback官方地址：http://logback.qos.ch/manual/index.html;Spring-boot官方地址：https://docs.spring.io/spring-boot/docs/2.2.2.RELEASE/reference/html/spring-boot-features.html#boot-features-logging（文档就用2.2.2凑合看吧…）代码根据官网描述，想使用自定义的日志配置文件，可以在resource目录下使用如下文件名：demo代码比较简单，直接创建一个空的标准Spring Boot项目即可，在resource目录下新建一个名为logback-spring.xml的配置文件，并事先定义好一些配置，如下:1234567&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;configuration scan="true" debug="false"&gt; &lt;include resource="org/springframework/boot/logging/logback/defaults.xml"/&gt; &lt;property name="log-path" value="logs"/&gt; &lt;property name="max-history" value="240"/&gt; &lt;springProperty scope="context" name="sys-log-level" source="sys.default.log.level" defaultVakye="INFO"/&gt;&lt;/configuration&gt;其中，scan=true表示更新自动加载，debug表示输出日志组件状态信息(因为日志组件加载不依赖Spring的ApplictionContext)，&lt;property&gt;标签表示定义的变量，&lt;springProperty&gt;表示从spring的配置文件中读取的变量，换句话说，是从application.properties里读取的配置，source就是application.properties里key。logback主要由appender、logger组成，appender是用来输出日志的组件，logger是记录日志的组件，首先定义一个控制台的日志输出：123456&lt;appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;encoder&gt; &lt;pattern&gt;$&#123;CONSOLE_LOG_PATTERN&#125;&lt;/pattern&gt; &lt;charset&gt;utf8&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt;pattern标签里的表达式，在defaults文件里有，也就是spring boot默认日志格式，也可以自己定义。然后配置系统文件输出组件：12345678910111213141516171819202122232425&lt;property name="PATH_APPLICATION" value="$&#123;LOG_PATH&#125;/application/application.log"/&gt; &lt;appender name="APPLICATION" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;file&gt;$&#123;PATH_APPLICATION&#125;&lt;/file&gt; &lt;encoder&gt; &lt;pattern&gt;$&#123;FILE_LOG_PATTERN&#125;&lt;/pattern&gt; &lt;/encoder&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;fileNamePattern&gt;$&#123;PATH_APPLICATION&#125;.%d&#123;yyyy-MM-dd-HH&#125;&lt;/fileNamePattern&gt; &lt;maxHistory&gt;$&#123;MAX_HISTORY&#125;&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt; &lt;level&gt;$&#123;SYS_LOG_LEVEL&#125;&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt;&lt;appender name="ASYNC_APPLICATION" class="ch.qos.logback.classic.AsyncAppender"&gt; &lt;neverBlock&gt;true&lt;/neverBlock&gt; &lt;discardingThreshold&gt;0&lt;/discardingThreshold&gt; &lt;queueSize&gt;256&lt;/queueSize&gt; &lt;appender-ref ref="APPLICATION"/&gt; &lt;/appender&gt;&lt;logger name="com.blog"&gt; &lt;appender-ref ref="ASYNC_APPLICATION"/&gt; &lt;/logger&gt;分别是日志目录，滚动文件输出组件，滚动策略为定时，并且配置级别过滤器，级别为application.properties中的系统级别。logback的高性能体现在其异步日志输出上，根据官网描述，AsyncAppender只是一个日志分发器，所以它必须引用另外的appender才能工作，最后配置日志记录组件，即logger，logger的命名会根据.产生继承，例如com.blog.controller继承于com.blog包，当子记录器没有配置级别，它会继承父记录器级别，这里创建了一个叫com.blog的日志记录器。现在一个标准的配置就完成了，最后配置ROOT：1234&lt;root level="$&#123;SYS_LOG_LEVEL&#125;"&gt; &lt;appender-ref ref="APPLICATION"/&gt; &lt;appender-ref ref="CONSOLE"/&gt; &lt;/root&gt;项目结构如下：配置dev中日志级别如下，1234sys: default: log: level: debugprod环境中日志级别：1234sys: default: log: level: info启动项目，在项目目录下即生成log目录，同时会打印不同级别的日志。但是线上其实不需要控制台输出，避免大量IO，只需要文件输出，那ConsoleAppender怎么处理？我希望本地调试保持控制台输出和文件，而线上只需要文件输出。这个时候可以巧妙利用Spring 的profile功能：1234567891011&lt;springProfile name="dev,test"&gt; &lt;root level="$&#123;SYS_LOG_LEVEL&#125;"&gt; &lt;appender-ref ref="APPLICATION"/&gt; &lt;appender-ref ref="CONSOLE"/&gt; &lt;/root&gt; &lt;/springProfile&gt; &lt;springProfile name="prod"&gt; &lt;root level="$&#123;SYS_LOG_LEVEL&#125;"&gt; &lt;appender-ref ref="ASYNC_APPLICATION"/&gt; &lt;/root&gt; &lt;/springProfile&gt;我不想把所有的日志都放到这个文件里，对于某些重要的接口或者模块，想单独输出方便排查。直接定义一个新的logger，例如mq有关的：12345678910111213141516171819202122232425&lt;property name="MQ" value="$&#123;LOG_PATH&#125;/application/mq.log"/&gt; &lt;appender name="MQ_APPENDER" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;file&gt;$&#123;PATH_APPLICATION&#125;&lt;/file&gt; &lt;encoder&gt; &lt;pattern&gt;$&#123;FILE_LOG_PATTERN&#125;&lt;/pattern&gt; &lt;/encoder&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;fileNamePattern&gt;$&#123;MQ&#125;.%d&#123;yyyy-MM-dd-HH&#125;&lt;/fileNamePattern&gt; &lt;maxHistory&gt;$&#123;MAX_HISTORY&#125;&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt; &lt;level&gt;$&#123;SYS_LOG_LEVEL&#125;&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt;&lt;appender name="ASYNC_MQ" class="ch.qos.logback.classic.AsyncAppender"&gt; &lt;neverBlock&gt;true&lt;/neverBlock&gt; &lt;discardingThreshold&gt;0&lt;/discardingThreshold&gt; &lt;queueSize&gt;256&lt;/queueSize&gt; &lt;appender-ref ref="MQ_APPENDER"/&gt; &lt;/appender&gt;&lt;logger name="com.blog.mq"&gt; &lt;appender-ref ref="ASYNC_MQ"/&gt; &lt;/logger&gt;可以通过private static final Logger mqLog = LoggerFactory.getLogger(&quot;com.blog.mq&quot;);获取特定的logger进行输出。其他什么时候需要打印日志？当我依赖其他服务或者模块时，记录入参和出参，用于排查和复盘，此时谓之边界日志，边界可以配合切面来记录，记录到单独文件；当执行了某关键操作和计算以后，结果是作为软件成果的一部分；系统异常、警告、出错，通常也是记录单独文件。日志打印格式？日志之所以起到作用，是因为输出有用的信息，例如：关键参数，错误码，错误描述等。对于debug日志，还可以在打印之前使用isDebugEnabled()进行判断，提高效率，虽然，在info级别下，debug日志不会输出，不过我的浅见是，自己判断了，就省掉了系统去构造打印参数的过程，毕竟，构造参数是在系统判断之前。Idea的小技巧无论对于eclipse还是idea等ide，都有动态模板可以生成打印debug的信息，这里简单介绍一下idea快速生成log的技巧，打开idea的设置，搜索live templates，新建一个Live Templates，可以首先新建一个自定义的template group，然后创建模板，文本选择private static final Logger log = LoggerFactory.getLogger($currentclass$.class);，点击define选择作用范围为Java，点击右边Edit Variables，选择Expression为className，如图：这样的效果是：当输入lg的时候，就会有智能提示，然后会自动生成当前类的logger。同样，还可以创建一个debug模板：这里使用了两段groovyScript来配合自动生成参数名称和参数值：123groovyScript("def result=''; def params=\"$&#123;_1&#125;\".replaceAll('[\\\\[|\\\\]|\\\\s]', '').split(',').toList(); for(i = 0; i &lt; params.size(); i++) &#123; if(params[i] == '') return result; result += i == params.size() - 1 ? params[i] +':&#123;&#125;': params[i]+':&#123;&#125;, '; &#125;; return result", methodParameters())groovyScript( "def result=''; def params=\"$&#123;_1&#125;\".replaceAll('[\\\\[|\\\\]|\\\\s]', '').split(',').toList(); for(i = 0; i &lt; params.size(); i++) &#123; if(params[i] == '') return result; result += i == params.size() - 1 ? params[i]: params[i]+', '; &#125;; return result", methodParameters())]]></content>
      <categories>
        <category>编程技术</category>
      </categories>
      <tags>
        <tag>随记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring MVC源码初探(二)-Servlet 3.0、SPI、Aware]]></title>
    <url>%2FSpring-MVC%E6%BA%90%E7%A0%81%E5%88%9D%E6%8E%A2-%E4%BA%8C-Servlet-3-0%E3%80%81SPI%E3%80%81Aware.html</url>
    <content type="text"><![CDATA[简述这篇笔记主要记录一些比较重要，但是上一篇又没有提到的内容。其中，Spring MVC对Servlet 3.0的实现是重中之重。JAVA SPI动态替换服务实现的机制，目前Dubbo就是基于SPI提供扩展机制。Demo写一个小demo感受一下：bad-printer：某家厂商good-printer：另一家厂商interface：规范制定者invoker：main方法入口interface一个只包含一个Java类文件的项目，制定了一个接口：12345package com.joy.api;public interface Printer &#123; public void print();&#125;bad-printerpom.xml：1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.joy&lt;/groupId&gt; &lt;artifactId&gt;interface&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;实现interface里的接口：123456public class BadPrinter implements Printer &#123; @Override public void print() &#123; System.out.println("I am a bad man"); &#125;&#125;同时，在resources/下创建META-INF/services文件夹，将interface里接口的完整包名+类名的路径作为文件名com.joy.api.Printer，文件内容是实现类完整包名+类名：1com.joy.service.BadPrintergood-printer操作同上。invokerpom.xml:1234567891011&lt;dependency&gt; &lt;groupId&gt;com.joy&lt;/groupId&gt; &lt;artifactId&gt;interface&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.joy&lt;/groupId&gt; &lt;artifactId&gt;bad-printer&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt;main：12345678public class MainApp &#123; public static void main(String[] args) &#123; ServiceLoader&lt;Printer&gt; printLoader = ServiceLoader.load(Printer.class); for (Printer printer : printLoader) &#123; printer.print(); &#125; &#125;&#125;结果依赖为bad-printer时，控制台输出：1I am a bad man不改变代码，将依赖替换为good-printer，执行main方法：1I am a good man这也是设计模式总纲-开闭原则的一种实现。总结在经典的日志框架jcl-over-slf4j-xxxx.jar中，就有SPI的运用：12META-INF\services\org.apache.commons.logging.LogFactory:org.apache.commons.logging.impl.SLF4JLogFactory来到最新的DriverManager，有这么一个静态代码块：12345678/** * Load the initial JDBC drivers by checking the System property * jdbc.properties and then use the &#123;@code ServiceLoader&#125; mechanism */ static &#123; loadInitialDrivers(); println("JDBC DriverManager initialized"); &#125;这是一个根据jdbc.drivers这个系统参数来加载驱动的方法，接着往下走，重头戏来了：12ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class); Iterator&lt;Driver&gt; driversIterator = loadedDrivers.iterator();注释就说了：如果有Driver类通过SPI的方式实现，就加载它。再结合类的生命周期：加载---&gt;连接(验证-准备-解析)---&gt;初始化---&gt;使用---&gt;卸载，我们不难猜到，下一步就是要准备初始化了：123456789for (String aDriver : driversList) &#123; try &#123; println("DriverManager.Initialize: loading " + aDriver); Class.forName(aDriver, true, ClassLoader.getSystemClassLoader()); &#125; catch (Exception ex) &#123; println("DriverManager.Initialize: load failed: " + ex); &#125; &#125;这就变回了我们当初刚开始学Java+数据库时，手动使用Class.forName(&quot;com.mysql.jdbc.Driver&quot;)的方式加载驱动并初始化。再到一个jdbc实现类中看一眼，以mysql的为例，最新的mysql驱动为：com.mysql.cj.jdbc.Driver，有一个静态代码块：1234567static &#123; try &#123; java.sql.DriverManager.registerDriver(new Driver()); &#125; catch (SQLException E) &#123; throw new RuntimeException("Can't register driver!"); &#125; &#125;可以看到，它会向java的驱动管理类注册自身，同时也保证了旧的 Class.forName()的正常使用。顺带提一句，即使配置了原来的类名com.mysql.jdbc.Driver，也是可以使用的，打开类看一下：12345678910public class Driver extends com.mysql.cj.jdbc.Driver &#123; public Driver() throws SQLException &#123; super(); &#125; static &#123; System.err.println("Loading class `com.mysql.jdbc.Driver'. This is deprecated. The new driver class is `com.mysql.cj.jdbc.Driver'. " + "The driver is automatically registered via the SPI and manual loading of the driver class is generally unnecessary."); &#125;&#125;但是会提示这个类被废弃了。Servlet 3.03.0以前的Filter、Listener、Servlet：在web.xml中一一配置3.0以后:提供了@WebServlet、@WebListener等注解同时提供了：ServletRegistration.Dynamic addServlet(String servletName,Class&lt;? extends Servlet&gt; servletClass)ServletRegistration.Dynamic addServlet(String servletName, Servlet servlet)ServletRegistration.Dynamic addServlet(String servletName, String className)T createServlet(Class clazz)ServletRegistration getServletRegistration(String servletName)Map&lt;String,? extends ServletRegistration&gt; getServletRegistrations()：增加动态映射等方法，这些方法，在ServletContextListener的#contextInitialized()方法中调用，或者ServletContainerInitializer的#onStartup方法中调用，ServletcontainerInitializer也是3.0新增的一个类，容器启动时会通过这个方法处理WEB/INF/lib下的jar包，使用注解@HandlersTypes可以过滤需要处理的类型。最后，在我们自己实现的ServletcontainerInitializer的项目路径下创建META-INF/services/javax.servlet.ServletContainerInitializer，即可实现彻底摆脱web.xml而创建servlet了。Spring中的Servlet 3.01org.springframework.web.SpringServletContainerInitializer其子类继承结构图如下：AbstractContextLoaderInitializer：创建Root wac，添加contextLoadListenerAbstractDispatcherServletInitializer：创建Servlet wac，注册DispactcherServlet123456789101112131415161718public void onStartup(ServletContext servletContext) throws ServletException &#123; super.onStartup(servletContext); registerDispatcherServlet(servletContext); &#125; protected void registerDispatcherServlet(ServletContext servletContext) &#123; String servletName = getServletName(); Assert.hasLength(servletName, "getServletName() must not return null or empty"); WebApplicationContext servletAppContext = createServletApplicationContext(); Assert.notNull(servletAppContext, "createServletApplicationContext() must not return null"); FrameworkServlet dispatcherServlet = createDispatcherServlet(servletAppContext); Assert.notNull(dispatcherServlet, "createDispatcherServlet(WebApplicationContext) must not return null"); dispatcherServlet.setContextInitializers(getServletApplicationContextInitializers()); ServletRegistration.Dynamic registration = servletContext.addServlet(servletName, dispatcherServlet); ... &#125;而在spring-web的META-INF/services/javax.servlet.ServletContainerInitializer中，就是指定了SPI的实现类。Spring Boot 中的Servlet 3.0Spring Boot依旧支持上一节中提到的几个注解，但是需要使用@ServletComponentScan来支持。也可以通过声明bean的方式来指定：123456789101112131415@Beanpublic ServletRegistrationBean helloWorldServlet() &#123; ServletRegistrationBean helloWorldServlet = new ServletRegistrationBean(); myServlet.addUrlMappings("/hello"); myServlet.setServlet(new HelloWorldServlet()); return helloWorldServlet;&#125;@Beanpublic FilterRegistrationBean helloWorldFilter() &#123; FilterRegistrationBean helloWorldFilter = new FilterRegistrationBean(); myFilter.addUrlPatterns("/hello/*"); myFilter.setFilter(new HelloWorldFilter()); return helloWorldFilter;&#125;打开FilterRegistrationBean看一眼继承结构(spring boot 2.1.0.RELEASE)：这几个类都是RegistrationBean的子类，其核心就是对ServletContextInitializer的实现了。我们都知道，spring boot既可以使用Jar包来运行，也可以打成war包使用外部容器来运行，而ServletContainerInitializer是在当使用war包在外部运行时的策略，在Jar包中，这种算法策略会出现问题。所以，spring boot使用了自己的一个org.springframework.boot.web.embedded.tomcat.TomcatStarter来初始化，虽然，它继承了ServletContainerInitializer，但是，并没有在META-INF/services里创建文件。看一眼Spring Boot使用内置Tomcat启动的一个调用栈(部分)：在图一，可以很明显看到，它创建了一个TomcatServletWebFactory，来看看是怎么创建的：1234567891011121314151617protected ServletWebServerFactory getWebServerFactory() &#123; // Use bean names so that we don't consider the hierarchy String[] beanNames = getBeanFactory() .getBeanNamesForType(ServletWebServerFactory.class); if (beanNames.length == 0) &#123; throw new ApplicationContextException( "Unable to start ServletWebServerApplicationContext due to missing " + "ServletWebServerFactory bean."); &#125; if (beanNames.length &gt; 1) &#123; throw new ApplicationContextException( "Unable to start ServletWebServerApplicationContext due to multiple " + "ServletWebServerFactory beans : " + StringUtils.arrayToCommaDelimitedString(beanNames)); &#125; return getBeanFactory().getBean(beanNames[0], ServletWebServerFactory.class); &#125;可以看到这里获取了BeanFactory，并且通过类型获得了beanname数组，如果有多个，只会按照数组的第一个返回实际的Bean，而ServletWebServerFactory的实现类，可以通过类图看到：获得TomcatServletWebFactory以后，又调用了#getWebServer()方法，进入一看，方法比较简单，new了Tomcat、Connector，配置connector、engine、host等，然后开始#prepareContext()，这个方法还没细看，应该都是设置一些server.xml中，&lt;Host&gt;标签所涉及到的一些配置，继续往下，重点来了，#configureContext(context, initializersToUse)这个方法中，有如下代码：12345678......TomcatStarter starter = new TomcatStarter(initializers);if (context instanceof TomcatEmbeddedContext) &#123; TomcatEmbeddedContext embeddedContext = (TomcatEmbeddedContext) context; embeddedContext.setStarter(starter); embeddedContext.setFailCtxIfServletStartFails(true); &#125;......手动new了org.springframework.boot.web.embedded.tomcat.TomcatStarter类，然后放到了上下文中。回到#getWebServer()方法，这个方法还传入了一个参数，开起来是一个lambda表达式的极度简写，返回了一个ServletContextInitializer的匿名实现类，该实现类采用了方法引用的形式，引用的方法就是下面的方法：123456789101112131415161718private org.springframework.boot.web.servlet.ServletContextInitializer getSelfInitializer() &#123; return this::selfInitialize; &#125; private void selfInitialize(ServletContext servletContext) throws ServletException &#123; prepareWebApplicationContext(servletContext); ConfigurableListableBeanFactory beanFactory = getBeanFactory(); ExistingWebApplicationScopes existingScopes = new ExistingWebApplicationScopes( beanFactory); WebApplicationContextUtils.registerWebApplicationScopes(beanFactory, getServletContext()); existingScopes.restore(); WebApplicationContextUtils.registerEnvironmentBeans(beanFactory, getServletContext()); for (ServletContextInitializer beans : getServletContextInitializerBeans()) &#123; beans.onStartup(servletContext); &#125; &#125;这种异步回调的形式，会产生什么结果呢？在该方法最后一行是getTomcatWebServer(tomcat);，这个方法会传入上面new的Tomcat对象，同时，如果端口号&gt;0，就会自动启动。剩下的步骤在上图debug2中就简单明了了，进入到Tomcat的启动周期了：tomcat.start()---&gt; LifecycleBase #start()---&gt;StandardContext #startInternal()这里的StandardContext实际上就是#prepareContext()方法中new Tomcat以后创建的上下文。在StandardContext的startInternal()方法中，有如下代码：1234567891011121314...... // Call ServletContainerInitializers for (Map.Entry&lt;ServletContainerInitializer, Set&lt;Class&lt;?&gt;&gt;&gt; entry : initializers.entrySet()) &#123; try &#123; entry.getKey().onStartup(entry.getValue(), getServletContext()); &#125; catch (ServletException e) &#123; log.error(sm.getString("standardContext.sciFail"), e); ok = false; break; &#125; &#125;......没错，注释都告诉了我们调用ServletContainerInitializers的onStartup()方法，而上文也说了，这个ServletContainerInitializers就是TomcatStarter，最终执行的就是下面这个代码，从而也就就执行了匿名类中的#selfInitialize()：12345try &#123; for (ServletContextInitializer initializer : this.initializers) &#123; initializer.onStartup(servletContext); &#125;&#125;这个方法，实际上就是执行spring boot中那些自定义的RegistrationBean的#onStartup()方法，利用上文提到的Servlet 3.0动态添加Servlet的特性，动态创建Servlet，彻底摆脱了web.xml。1234567891011121314151617181920public class ServletRegistrationBean&lt;T extends Servlet&gt; extends DynamicRegistrationBean&lt;ServletRegistration.Dynamic&gt; &#123; //......onStartup()会调用configure() protected void configure(ServletRegistration.Dynamic registration) &#123; super.configure(registration); String[] urlMapping = StringUtils.toStringArray(this.urlMappings); if (urlMapping.length == 0 &amp;&amp; this.alwaysMapUrl) &#123; urlMapping = DEFAULT_MAPPINGS; &#125; if (!ObjectUtils.isEmpty(urlMapping)) &#123; registration.addMapping(urlMapping); &#125; registration.setLoadOnStartup(this.loadOnStartup); if (this.multipartConfig != null) &#123; registration.setMultipartConfig(this.multipartConfig); &#125; &#125; // ...... 省略其他&#125;spring boot没有完全遵守Servlet 3.0，没有使用SPI，但是在灵活性和可扩展性上更胜一筹，这就是spring boot的终极魅力所在啊！Spring Aware这本来应该是Spring中的内容，但是由于Spring MVC略有涉及，因此小记一下。What？Spring中的Aware本质是一个标记interface，也是容器的核心接口之一，实现了该接口的bean具有被Spring容器通知的能力；How？采用回调的方式通知，该接口是一个空接口，实际方法签名由子接口确定，并且该接口通常只有一个接受但参数的set方法，方法命名为set+去掉Aware后缀的接口名；When？在AbstractAutowireCapableBeanFactory.java中，可以略见一二：12345678910111213141516171819private void invokeAwareMethods(final String beanName, final Object bean) &#123; if (bean instanceof Aware) &#123; // BeanNameAware if (bean instanceof BeanNameAware) &#123; ((BeanNameAware) bean).setBeanName(beanName); &#125; // BeanClassLoaderAware if (bean instanceof BeanClassLoaderAware) &#123; ClassLoader bcl = getBeanClassLoader(); if (bcl != null) &#123; ((BeanClassLoaderAware) bean).setBeanClassLoader(bcl); &#125; &#125; // BeanFactoryAware if (bean instanceof BeanFactoryAware) &#123; ((BeanFactoryAware) bean).setBeanFactory(AbstractAutowireCapableBeanFactory.this); &#125; &#125;&#125;Spring提供了大量Aware接口，但是先来个小例子感受一下：普通maven项目，首先在resources目录下创建一个空的spring.xml文件(idea 专业版可以自动生成)，然后代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class MyApplicationAware implements BeanNameAware, BeanFactoryAware, BeanClassLoaderAware, ApplicationContextAware &#123; private String beanNam; private BeanFactory beanFactory; private ClassLoader classLoader; private ApplicationContext applicationContext; @Override public void setBeanClassLoader(ClassLoader classLoader) &#123; System.out.println("ClassLoader"); this.classLoader = classLoader; &#125; @Override public void setBeanFactory(BeanFactory beanFactory) throws BeansException &#123; System.out.println("BeanFacory"); this.beanFactory = beanFactory; &#125; @Override public void setBeanName(String name) &#123; System.out.println("BeanName"); this.beanNam = name; &#125; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; System.out.println("ApplicationContext"); this.applicationContext = applicationContext; &#125; public void display() &#123; System.out.println("beanname=" + beanNam); System.out.println("是否为单例：" + beanFactory.isSingleton(beanNam)); System.out.println("系统环境" + applicationContext.getEnvironment()); &#125; public static void main(String[] args) &#123; ClassPathResource classPathResource = new ClassPathResource("spring.xml"); DefaultListableBeanFactory factory = new DefaultListableBeanFactory(); XmlBeanDefinitionReader reader = new XmlBeanDefinitionReader(factory); reader.loadBeanDefinitions(classPathResource); MyApplicationAware applicationAware = (MyApplicationAware) factory.getBean("myApplicationAware"); applicationAware.display(); //上面只运行了三个 aware接口的方法，最后打印系统环境时空指针 &#125;如果main换成以下：123456public static void main(String[] args) &#123; ApplicationContext applicationContext = new ClassPathXmlApplicationContext("spring.xml"); MyApplicationAware myApplicationAware = (MyApplicationAware) applicationContext.getBean("myApplicationAware"); myApplicationAware.display(); //上面的运行了四个aware接口的方法 &#125;原因：通过BeanFactory.getBean()获取bean时，只检测了BeanNameAware, BeanFactoryAware, BeanClassLoaderAware三个接口的实现(参见上文)。但是Root wac会检测所有实现的子Aware。部分常用的Aware如下：LoadTimeWeaverAware：加载Spring Bean时织入第三方模块，如AspectJBeanClassLoaderAware：加载Spring Bean的类加载器BootstrapContextAware：资源适配器BootstrapContext，如JCA,CCIResourceLoaderAware：底层访问资源的加载器BeanFactoryAware：声明BeanFactoryPortletConfigAware：PortletConfigPortletContextAware：PortletContextServletConfigAware`：ServletConfigServletContextAware：ServletContextMessageSourceAware：国际化ApplicationEventPublisherAware：应用事件NotificationPublisherAware：JMX通知BeanNameAware：声明Spring Bean的名字。总结这一篇主要是对基础知识的补足，下一节开始学习HandlerMapping组件。参考芋艿的源码解析，以及徐妈的博客：http://svip.iocoder.cn/Spring-MVC/context-init-integration-with-Servlet-3.0/http://svip.iocoder.cn/Spring-MVC/context-init-integration-with-SpringBoot/https://www.cnkirito.moe)]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>JAva</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring MVC源码初探(一)-容器初始化]]></title>
    <url>%2FSpring-MVC%E6%BA%90%E7%A0%81%E5%88%9D%E6%8E%A2.html</url>
    <content type="text"><![CDATA[准备工作GitGradleIDEA 2018以上版本JDK 1.8+从https://github.com/spring-projects/spring-frameworkfork出一份源代码到自己的仓库，方便自己能写注释，以及运行test等。当前使用的是Spring 5.1.3.BUILD-SNAPSHOT的版本spring框架里的web模块包括webmvc、websocket、webflux，其中，web模块是另外三个模块的父模块。代码拉下来以后，执行./gradlew :spring-oxm:compileTestJava出现success即为成功。容器在Spring MVC初始化时，总共涉及到两个容器，一个是Root WebApplicationContext，还有一个是Servlet WebApplicationContext。看一下常用的web.xml的配置：123456789101112131415161718192021222324252627282930&lt;!-- 省略非关键的配置 --&gt;&lt;!-- [1] Spring配置 --&gt;&lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;&lt;/listener&gt;&lt;!-- 指定Spring Bean的配置文件所在目录。默认配置在WEB-INF目录下 --&gt;&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:config/applicationContext.xml&lt;/param-value&gt;&lt;/context-param&gt;&lt;!-- ====================================== --&gt;&lt;!-- [2] Spring MVC配置 --&gt;&lt;servlet&gt; &lt;servlet-name&gt;spring&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!-- 可以自定义servlet.xml配置文件的位置和名称，默认为WEB-INF目录下，名称为[&lt;servlet-name&gt;]-servlet.xml，如spring-servlet.xml &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;/WEB-INF/spring-servlet.xml&lt;/param-value&gt; // 默认 &lt;/init-param&gt; --&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;spring&lt;/servlet-name&gt; &lt;url-pattern&gt;*.do&lt;/url-pattern&gt;&lt;/servlet-mapping&gt;Root WebApplication首先进入的就是ContextLoaderListener#contextInitialized方法，这个监听实现了ServletContextListener，是一个servlet与容器进行通信的接口，所以如果在web.xml中配置了&lt;Listener&gt;标签以后，容器启动时就会启动该监听，并执行contextInitialized方法，这个方法继承自contextLoader，所以直接会调用ContextLoader#initWebApplicationContext方法，顾名思义，这个方法就是用来初始化Root wac(Web Application Context简称)。这里主要是调用了createWebApplicationContext创建容器，和configureAndRefreshWebApplicationContext配置和刷新容器。创建wac：createWebApplicationContext—&gt;determineContextClass，这个方法决定了要使用什么类型的wac，默认情况下，defaultStrategies就是读取了ContextLoader.properties的Properties，它指定了默认的wac类型是XmlWebApplicationContext，源码如下：123456789101112131415161718192021222324protected Class&lt;?&gt; determineContextClass(ServletContext servletContext) &#123; //获取sc里的初始化参数 String contextClassName = servletContext.getInitParameter(CONTEXT_CLASS_PARAM); if (contextClassName != null) &#123; try &#123; return ClassUtils.forName(contextClassName, ClassUtils.getDefaultClassLoader()); &#125; catch (ClassNotFoundException ex) &#123; throw new ApplicationContextException( "Failed to load custom context class [" + contextClassName + "]", ex); &#125; &#125; else &#123; //默认策略，这里会使用Class.forName()反射创建类类型并返回 contextClassName = defaultStrategies.getProperty(WebApplicationContext.class.getName()); try &#123; return ClassUtils.forName(contextClassName, ContextLoader.class.getClassLoader()); &#125; catch (ClassNotFoundException ex) &#123; throw new ApplicationContextException( "Failed to load default context class [" + contextClassName + "]", ex); &#125; &#125; &#125;返回一个类类型以后，在createWebApplicationContext方法中，通过反射技术会创建该类类型的一个实例对象出来。接着会设置父容器，配置和刷新当前容器，但是在刚创建容器的时候，由于并没有显示指定容器中active这个AtomicBoolean的值，所以默认为false，这时候会进入设置父容器和配置wac的步骤。如果wac的父容器为空，会设置wac的父容器。当前这个已经是Root wac了，所以其实loadParentContext这个方法返回为空，并且没有任何一个子类去重写，由此得知，Root wac的父容器通常始终为空。接下来会将wac放到ServletContext(以下简称sc)的attribute里，由对应的Web容器放到自己的容器上下文里，在Tomcat里就是ApplicationContext，该类里保存了一个ConcurrentHashMap类型的成员变量attributes，保存所有属性，Spring的Root wac也放在这里。配置wac：设置contextId等属性—&gt; 将sc设置到wac里—&gt;获取web.xml里的contextConfigLocation配置路径—&gt;初始化内容资源—&gt;扫描用户配置的globalInitializerClasses和contextInitializerClasses—&gt;初始化这些类—&gt;刷新context—&gt;设置Root wac的active、closed的值，进入到Spring Ioc容器的初始化。在这里，Spring为了适应不同的Web容器打破双亲委派机制的情况，有如下代码：123456789ClassLoader ccl = Thread.currentThread().getContextClassLoader();if (ccl == ContextLoader.class.getClassLoader()) &#123; //如果当前类的类加载器和当前线程的上下文加载器是一样的，则将context赋值给当前类全局变量 currentContext = this.context;&#125;else if (ccl != null) &#123; //将上下文放入到map中 currentContextPerThread.put(ccl, this.context);&#125;拿Tomcat举例来说，Tomcat打破了JVM的双亲委派机制：CommonClassLoader：加载那些能在Web应用和Tomcat之间共享的类；SharedClassLoader：Web应用之间能够共享的类，比如Spring；CatalinaClassLoader：加载Tomcat自身需要的类；WebAppClassLoader：每一个Web应用都有自己的WebAppClassLoader，打破了双亲委派，它会首先从本地缓存查找是否加载过，然后再去使用父加载器去查找，如果没有接着会使用ExtClassLoader（也可以说会使用BootstrapClassLoader，避免Web应用的类覆盖JRE类），然后会在本地文件系统中查找，最后会交由系统类加载器（因为Class.forName默认使用的就是AppClassLoader）。使用WebAppClassLoader加载的业务类可以通过Thread.currentThread().getContextClassLoader()来获得类加载器；使用ContextLoader.class.getClassLoader()获得的是ContextLoader类加载器，如果两个类加载器是一致的，就可以将wac作为全局的静态变量currentContext的值，如果不是一致的，就需要用一个线程安全的ConcurrentHashMap来保存当前创建的wac，通过这种方式来保证线程间wac的私有。Servlet WebApplication第二个Servlet WebApplication容器，是在DispatcherServlet初始化的过程中进行创建的。其实本质而言，这就是一个最正常的Servlet，和平时常见的的那种执行doGet，doPost的servlet没有任何区别，使用IDEA生成类图（command+alt+u）如下：HttpServletBean：将ServletConfig设置到Servlet对象中FrameworkServlet：初始化ServletBean，创建Servlet wacDispatcherServlet：初始化Spring MVC中的九个组件HttpServletBean这个类实现了EnvironmentCapable, EnvironmentAware接口，通过Spring的*Aware这类接口的感知能力，将environment注入进来。在init这个方法中遍历所有的&lt;init-param&gt;标签中配置的参数，封装成PropertyValues，实现类是继承了MutablePropertyValues的ServletConfigPropertyValues，并将当前的Servlet对象转化成一个BeanWrapper对象，同时将pvs放到这个bw里。123456789101112131415161718192021222324252627282930@Override public final void init() throws ServletException &#123; // Set bean properties from init parameters. //解析web.xml中的init-param标签，封装到pvs中，这个构造函数中有一个所有initParams的遍历 PropertyValues pvs = new ServletConfigPropertyValues(getServletConfig(), this.requiredProperties); if (!pvs.isEmpty()) &#123; try &#123; //将当前这个Servlet对象转化成一个BeanWrapper对象 BeanWrapper bw = PropertyAccessorFactory.forBeanPropertyAccess(this); ResourceLoader resourceLoader = new ServletContextResourceLoader(getServletContext()); //注册自定义的属性编辑器，碰到Resource类型的属性，就会使用自定义的属性加载器进行处理 bw.registerCustomEditor(Resource.class, new ResourceEditor(resourceLoader, getEnvironment())); //留给子类实现的初始化bw对象 initBeanWrapper(bw); //TODO Joy 将属性值pvs设置到bw里,需要好好研究一下是怎么将contextConfigLocation反射赋值到FrameworkServlet里的 bw.setPropertyValues(pvs, true); &#125; catch (BeansException ex) &#123; if (logger.isErrorEnabled()) &#123; logger.error("Failed to set bean properties on servlet '" + getServletName() + "'", ex); &#125; throw ex; &#125; &#125; // Let subclasses do whatever initialization they like. //交给FrameworkServlet来实现 initServletBean(); &#125;在ServletConfigPropertyValues这个类的构造函数里，通过构造一个set集合来判断属性是否齐全：12345678910111213141516171819202122232425public ServletConfigPropertyValues(ServletConfig config, Set&lt;String&gt; requiredProperties) throws ServletException &#123; //将必须的配置转换成一个set集合，当web.xml中配置了一个，就从set中移除一个，直到所有缺失的都移除 Set&lt;String&gt; missingProps = (!CollectionUtils.isEmpty(requiredProperties) ? new HashSet&lt;&gt;(requiredProperties) : null); Enumeration&lt;String&gt; paramNames = config.getInitParameterNames(); while (paramNames.hasMoreElements()) &#123; String property = paramNames.nextElement(); Object value = config.getInitParameter(property); addPropertyValue(new PropertyValue(property, value)); if (missingProps != null) &#123; missingProps.remove(property); &#125; &#125; // Fail if we are still missing properties. if (!CollectionUtils.isEmpty(missingProps)) &#123; throw new ServletException( "Initialization from ServletConfig for servlet '" + config.getServletName() + "' failed; the following required properties were missing: " + StringUtils.collectionToDelimitedString(missingProps, ", ")); &#125; &#125;以上代码非常值得学习。FrameWork Servlet该类中有一个非常重要的参数：WebApplicationContext。对于这个servlet wac的赋值，可以有四种方式：FrameWork Servlet的构造函数实现了ApplicationContextAware接口，可以使用Spring的注入从而调用#setApplicationContext#findWebApplicationContext方法#createWebApplicationContext方法在父类HttpServletBean的#init方法里，最后一行就是调用本类中的#initServletBean方法，这个方法的重点是#initWebApplicationContext方法，而#initFrameworkServlet方法由于没有任何实现，所以暂时不管。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960protected WebApplicationContext initWebApplicationContext() &#123; //获取ContextLoader初始化的 ROOT WebApplicationContext WebApplicationContext rootContext = WebApplicationContextUtils.getWebApplicationContext(getServletContext()); //这个是方法中用于操作的引用，避免直接操作全局变量 WebApplicationContext wac = null; //如果此时不为空，可能来自于构造函数传入，或者Srping Aware接口注入 if (this.webApplicationContext != null) &#123; // A context instance was injected at construction time -&gt; use it wac = this.webApplicationContext; if (wac instanceof ConfigurableWebApplicationContext) &#123; ConfigurableWebApplicationContext cwac = (ConfigurableWebApplicationContext) wac; if (!cwac.isActive()) &#123; //还没有激活时，开始进行配置和刷新，configureAndRefreshWebApplicationContext中会注册独有的监听 // The context has not yet been refreshed -&gt; provide services such as // setting the parent context, setting the application context id, etc if (cwac.getParent() == null) &#123; // The context instance was injected without an explicit parent -&gt; set // the root application context (if any; may be null) as the parent cwac.setParent(rootContext); &#125; configureAndRefreshWebApplicationContext(cwac); &#125; &#125; &#125; if (wac == null) &#123; // No context instance was injected at construction time -&gt; see if one // has been registered in the servlet context. If one exists, it is assumed // that the parent context (if any) has already been set and that the // user has performed any initialization such as setting the context id // 主动寻找wac，这种场景是因为用户自己在web.xml中定义了`ContextAttribute`，但是一般我们都不会配置 wac = findWebApplicationContext(); &#125; if (wac == null) &#123; // No context instance is defined for this servlet -&gt; create a local one //最后会主动创建，并且执行configureAndRefreshWebApplicationContext wac = createWebApplicationContext(rootContext); &#125; //这个参数参数表示是否已经接收到刷新，如果没有就要立即执行onRefresh if (!this.refreshEventReceived) &#123; // Either the context is not a ConfigurableApplicationContext with refresh // support or the context injected at construction time had already been // refreshed -&gt; trigger initial onRefresh manually here. //即使这个wac不是支持刷新的cac，或者在构造时已经刷新过，这里也要执行onRefresh synchronized (this.onRefreshMonitor) &#123; //最最最最核心的方法来了！！！九大组件～ onRefresh(wac); &#125; &#125; //将创建的servlet wac放到ServletContext中 //每个servlet都有自己的ServletConfig，用当前类的类名+".CONTEXT."+servlet名字的方式 if (this.publishContext) &#123; // Publish the context as a servlet context attribute. String attrName = getServletContextAttributeName(); getServletContext().setAttribute(attrName, wac); &#125; return wac; &#125;过程比较复杂的是创建Servlet WebApplicationContext的过程，在#createWebApplicationContext这个方法里，还是采用的和Root wac一样的创建方式，也就是默认XmlWebApplciationContext的类型反射创建wac，然后设置父容器，设置contextConfigLocation参数，这个参数就是上一节中说过通过反射赋值到FrameworkServlet中的，随后在#configureAndRefreshWebApplicationContext方法中，设置了ServletContext，ServletConfig，NameSpace，基本和ContextLoader类里Root wac的创建方式类似。但是—这里随后又注册了一个ApplicationEventListener，简单提一下Spring中的事件机制：事件-ApplicationEvent extends EventObject发布方-ApplicationEventPublisher消费方-ApplicationListener&lt;E extends ApplicationEvent&gt; extends EventListener和容器相关的事件的又分为：跟监听有关的类图如下：#configureAndRefreshWebApplicationContext注册了一个SourceFilteringListener，这个listener专门用来监听和传入的wac有关的事件，当产生容器刷新事件时，实际上是执行refresh方法以后，会发送对应的事件类型，这里就是ContextRefreshedEvent类型的事件，被SourceFilteringListener监听到以后，在#onApplicationEvent方法中判断事件源是否是传入的wac，如果是，交由代理ContextRefreshListener的实例去执行对应的#onApplicationEvent方法，而ContextRefreshListener实际上是FrameworkServlet的私有内部类，重写了#onApplicationEvent方法，那么这个方法的作用其实很简单—调用外部类FrameworkServlet的onRefresh方法，初始化9大组件。最后，将新创建的这个Servlet wac放到Servlet Context的attribute中。总结：在FrameworkServlet中，如果Servlet wac还没有激活，就会去配置，并且执行Spring Ioc容器的刷新，然后监听事件，触发类中的onRefresh如果Servlet wac没有找到或者为空，则执行创建，同样执行Spring Ioc的刷新，触发onRefresh如果Servlet wac已经激活，需要判断是否已经收到过Ioc容器的容器刷新事件，如果没有，同样要触发onRefreshDispatcher Servlet这个类是核心调度类，但是其调用逻辑相对来说并不算复杂，只是代码量不小，其核心方法如下：1234567891011121314151617181920protected void initStrategies(ApplicationContext context) &#123; //文件上传解析器 initMultipartResolver(context); //本地化资源/国际化资源解析器 initLocaleResolver(context); //主题解析器：根据请求头判断使用PC主题还是移动主题 initThemeResolver(context); //uri映射解析器：根据uri匹配合适的handler initHandlerMappings(context); //uri处理解析器：根据匹配到到的hadler处理请求 initHandlerAdapters(context); //异常解析器：根据请求处理异常请求 initHandlerExceptionResolvers(context); //请求到视图解析器：根据请求获得视图名 initRequestToViewNameTranslator(context); //最终视图解析器：视图最终解析 initViewResolvers(context); //FlashMap解析器：重定向参数临时保存 initFlashMapManager(context); &#125;另外配一幅网上找的图：其具体的工作流程，留待后面请求处理详解里在细细梳理。总结至此，Spring MVC容器初始化部分的内容到此结束，下一节开始学习Spring MVC对于Servlet 3.0的支持、SPI机制、以及Spring Aware的动态感知。参考芋艿的源码解析博客：http://www.iocoder.cn/]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅记持续交付]]></title>
    <url>%2F%E6%B5%85%E8%AE%B0%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98.html</url>
    <content type="text"><![CDATA[定义持续交付是开发人员，如何将一个好的点子，以最快的速度交付给用户的方法。持续集成：开发反复提交-构建-测试的过程；持续部署：可交付的产品快速且安全地交给用户使用的一套方法和系统；通过统一标准、规范流程、工具化、自动化等的方式，影响着整个研发周期。人（组织文化）+事（流程）+物（架构）。DevOps是一种鼓励协作的研发文化，它的概念比持续交付更宽泛，持续交付是DevOps的一种工具和技术实现。实践拿Java中常用的maven来举例：maven的原则：最短路径优先，如果A依赖C，A依赖B，B依赖C，那么maven会使用A依赖的C的版本；第一声明优先，如果A依赖B和C，B和C都依赖了D，那么maven会使用B依赖的版本。实践：不要在生产环境使用SNAPSHOT版本的包；在父模块使用dependencyManagment来统一版本；对于一组依赖的控制，使用BOM来进行统一管理；使用properties来减少重复劳动；不要在生产环境中使用mvn install命令，因为这个命令会导致真正需要的包被覆盖；禁止变更了代码不改版本号就上传到仓库。集成分支上线后回滚，123456git fetch origin $ git checkout master$ git reset --hard V0529 # 把本地的 master 分支的指针回退到 V0529，此时暂存区 (index) 里就指向 V0529 里的内容了。$ git reset --soft origin/master # --soft 使得本地的 master 分支的指针重新回到 V05javascript:;30，而暂存区 (index) 变成 V0529 的内容。$ git commit -m &quot;rollback to V0529&quot; # 把暂存区里的内容提交，这样一来新生成的 commit 的内容和 V0529 相同。 $ git push origin master # 远端的 master 也被回滚。推动规范的完成：代码以及依赖规范；命名规范；开发规范；配置规范；部署规范；安全规范；测试规范。环境构建流水线：可以通过OpenStack进行物理机和虚拟机的初始化工作，然后通过自动化的配置管理工具（Puppet、Chef、Ansible、SaltStack）安装一些基础软件，例如JDK和Tomcat等。如果采用资源池的方式，可以根据平时机器的使用情况预先分派一个资源池，省的从paas平台申请机器时还需要等待初始化。云计算的三种模式：SaaS：软件即服务，提供用户所需要的一切应用；PaaS：平台即服务，提供了一个大的框架，包括中间件、操作系统、软件运行时环境等；Iaas：基础架构即服务，只提供网络，存储，虚拟化技术等底层，其他需要用户自助。应用部署流水线：单应用部署流水化；应用部署并行；流水线的容错机制：错误中断或者优先完成正常的，最后将错误的交给用户解决。容器技术统一了软件环境和软件代码。交付结果一致；交付自动化；交付个性化；交付版本控制。构建提速私有仓库createrepo：搭建CentOS的yum仓库；Nexus：Java的maven仓库；cnpm：NodeJS的npm仓库；pypiserver：Python的pip仓库；gitlab：代码仓库；Harbor：Docker镜像仓库。Maven调优合适堆内存；-Dmaven.test.skip=true跳过单元测试（-DskipTests命令还会编译测试文件）;构建过程异步检查和测试（Enforce检查，框架依赖检查，sona检查，单元测试，集成测试）；增量代码扫描；发布阶段不使用snapshot版本的依赖；使用-T 2C进行并行构建；-pl参数局部构建；正确使用clean，在改了类型名或者删除了某些类的情况下可以使用该参数。构建检测maven enforcer一款maven插件，使用如下：123456789101112131415161718192021222324252627282930&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-enforcer-plugin&lt;/artifactId&gt; &lt;version&gt;1.4.1&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;enforce&lt;/id&gt; &lt;configuration&gt; &lt;rules&gt; &lt;requireMavenVersion&gt; &lt;version&gt;3.5&lt;/version&gt; &lt;/requireMavenVersion&gt; &lt;requireJavaVersion&gt; &lt;version&gt;1.8&lt;/version&gt; &lt;/requireJavaVersion&gt; &lt;requireOS&gt; &lt;family&gt;Linux&lt;/family&gt; &lt;/requireOS&gt; &lt;/rules&gt; &lt;/configuration&gt; &lt;goals&gt; &lt;goal&gt;enforce&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt;通过继承pom的形式，定义公司或者bu的统一依赖管理。参考携程的做法：123456corp pom ctrip pom/qunar pom bu pom product pom project parent pom subject module pom对于一组依赖的控制，可以使用bom来统一管理依赖的公共组件。参考enforcer插件的官网https://maven.apache.org/enforcer/enforcer-rules/index.html以及扩展插件:http://www.mojohaus.org/extra-enforcer-rules/CI工具Travis CI：基于Github的CI托管解决方案之一；Circle CI：基于Github，Bitbucket的云端持续集成方案；Jenkins CI：自动化驱动编译、测试、交付、部署。容器镜像构建选择合适的Base镜像较少不必要的镜像层的产生充分利用指令的缓存Docker out Docker：在物理机上安装一个Docker daemon，所有的容器都在物理上运行；Docker in Docker：在容器里安装一个Docker daemon，需要--privileged参数取得真正的Root命令，docker官方提供了一个docker:dind镜像可以直接使用。灰度发布蓝绿发布：先增加一套新的集群，发布版本到新集群并验证，此时不介入外部流量，等验证通过以后再把流量引入新服务集群，等待一段时间没有异常以后，老版本服务集群下线。滚动发布：从旧的集群中选出一批部署新应用，进行验证，验证完毕以后接入流量，然后依次重复部署；金丝雀发布：从集群中挑选特定服务器或一小批符合条件的用户，对其进行版本更新验证，随后逐步更新。发布系统一张页面：展示尽可能详细和精准的数据和内容；两个时态：发布中：发布中内容，处理过程、结果、耗时、当前情况；未发布时：历史发布进程，集群、服务器具体版本的情况；两个按钮：开始发布中断发布局部有错误时：中断或重试发布发布被暂停时：中断或继续发布三种发布结果：成功失败中断四类操作选择：开始发布停止发布发布回退发布重试五个步骤：markdown-拉出集群，不接入新流量downland-下载代码包install-停止服务、替换代码、重启服务verify-启动检查、程序预热(异步)markup-拉回集群、接入流量六个页面产物：集群示例发布日志发布历史发布批次发布操作携程发布系统架构Roll Engine：发布引擎，用于创建发布批次，按批次粒度实施部署策略，异步调用Salt Master服务，真正用于部署任务的是agent监控类型：用户侧监控-访问速度和结果网络监控-CDN与核心网络监控业务监控-核心业务指标波动应用监控-服务调用链、P99、错误量、JVM系统监控-基础设置、虚拟机、操作系统静态代码检查SonarQube提倡开发人员在开发环境中执行静态检查。服务端环境：Sonar服务+CheckStyle插件开发端环境：Idea-SonarLint插件maven命令：mvn org.sonarsource.scanner.maven:sonar-maven-plugin:3.2:sonar -f ./pom.xml -Dsonar.host.url=sonar 服务器地址 -Dsonar.login= 账号名称 -Dsonar.password= 账号密码 -Dsonar.profile= 检查规则的集合 -Dsonar.global.exclusions= 排除哪些文件 -Dsonar.branch= 检查的分支集成GitLab：在Merge Request中增加Sonar环节，包括检查状态和结果等。破坏性测试严格设计和执行破坏性测试的手段和过程；权衡破坏性测试的量和度。混沌工程步骤：正常系统行为的可测量数据-稳定态对照组：假定对照组-实验组都是稳定态引入真实世界变量-断网、磁盘损坏、服务器崩溃对比对照组和实验组，找出系统弱点高级原则：真实场景生产环境自动化连续实现最小爆破半径Chaos MonkeyNetflix对于混沌工程的先驱实践，随机杀死一些服务制造混乱测试Mock测试用例独立提升测试执行速度提高测试用例准备效率-无需考虑依赖端情况基于对象和类的Mock：Mockito或者EasyMock，在运行时为每一个被Mock的对象或类动态生成一个代理对象适合DAO层数据库操作和复杂逻辑基于微服务的Mock：Weir Mock和Mock Server，模拟API、http形式对象：标记被代理的类或对象，或声明被代理的服务通过Mock框架定制代理的行为调用代理，从而获得预期的结果回放方案一：在统一的SLB上做统一的拦截和复制转发处理，容易产生生产链路的故障方案二：在集群中新增一台服务器，启动一个软交换，由该软交换负责复制和转发用户请求移动APP静态检查Clang Static Analyzer：被Xcode集成OCLintInferAndroid热修复：百川hHotFix、美团Robust、手机QQ空间、微信ThinkerIOS热修复：Rollout.io、JSPatch、DynamicCocoa，只针对IOSReact Native(FaceBook)、Weex(Alibaba)，跨平台热更新Wax、Hyrid，前者用Lua语言，比较适合游戏，Hybrid主要面向H5Jenkins实践Jenkins Pipeline：运行在Jenkins上的一个工作流框架，支持将原先运行在一个或多个节点的任务通过一个Groovy脚本串联起来，以实现之前单个任务难以完成的复杂工作流安装Jenkins配置Jenkins对GitLab的访问权限-配置Jenkins钥匙-凭据-系统-全局凭据-添加凭据，添加私钥配置gitlab或者github的公钥安装GitLab plugin选择GitLab API Token，将GitLab的/profile/personal_access_tokens这个api生成的access token保存到GitLab API Token创建Jenkins Pipeline任务：GitLab项目-settings—&gt;intergrations—&gt;Merge request eventssettings—&gt;Merge Request—&gt;Only allow Merge Requests to be merge if the pipeline succeeds贴入代码：1234567891011121314151617181920212223242526node &#123; def mvnHome # 修改 Merge Request 的状态，并 checkout 代码 stage('Preparation') &#123; // for display purposes mvnHome = tool 'M3' updateGitlabCommitStatus name: 'build', state: 'running' checkout scm &#125; # 执行 Maven 命令对项目编译和打包 stage('Build') &#123; echo 'Build Start' // Run the maven build sh "'$&#123;mvnHome&#125;/bin/mvn' -Dmaven.test.skip=true clean package" &#125; # 启动 sonar 检查，允许 junit 单元测试，获取编译产物，并更新 Merge request 的状态 stage('Results') &#123; // Run sonar sh “'$&#123;mvnHome&#125;/bin/mvn' org.sonarsource.scanner.maven:sonar-maven-plugin:3.2:sonar” junit '**/target/surefire-reports/TEST-*.xml' archive 'target/*.war' updateGitlabCommitStatus name: 'build', state: 'success' &#125;&#125;对于Docker镜像，在上面的检查结束以后，还需要在检查以后安装Centos软件以及搭建Tomcat等容器运行环境。对于IOS应用，需要指定应用在Mac Slave的Jenkins中进行编译构建。企业级持续交付方案推荐：代码管理：GitLab构建打包：Jenkins自动部署：AnsibleWeb管理界面：Ansible Tower交付平台：Spinnaker]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>CI/CD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java调优-代码调优]]></title>
    <url>%2FJava%E8%B0%83%E4%BC%98-%E4%BB%A3%E7%A0%81%E8%B0%83%E4%BC%98.html</url>
    <content type="text"><![CDATA[String 调优以上是几个版本JDK中String对象的组成。JDK6的时候是通过offset和count来定位char[]数组；JDK7去处了offset和count，解决了substring方法导致的内存泄漏问题（该方法里的char数组仍然指向原字符串导致String字符串无法回收）；JDK9使用byte[]来代替char，char是两个byte，因此9的String更节省空间，coder的作用适用于在indexOf()函数时，计算字符串长度，coder属性有0，1两个值，0代表Latin-1（单字节编码），1代表UTF-16（双字节编码）。在Java中，常用的构造字符串的方式有两种：12String str = "abc";String str = new String("abc");第一种：str引用的是字符串常量池的地址；第二种：编译类文件时，“abc”加入到类常量，类加载时，字符串将会在常量池中创建；最后在new时，调用构造函数，同时引用常量池中的“abc”字符串，在堆内存中创建一个String对象，最后将str指向String对象；字符串常量会直接放到字符串常量池，字符串变量对象是创建在堆内存中，同时也会在字符串常量池中创建一个字符串对象，复制到堆内存对象中，并返回堆内存引用。如果在运行时创建字符串对象，例如new 了一个包含String类型成员变量的类，那么这个字符串对象会放入到堆中，只有当调用intern方法时并且常量池中没有时，才会将这个字符串对象放到常量池中，以后当堆中其他的字符串对象调用intern方法获取字符串引用对象时，才会去常量池中判断是否有相同值的字符串的引用并且返回（JDK7以后）。JDK6的做法是调用intern方法会去常量池中创建常量并且返回字符串引用。所以，对于类似国家、地名等具有重复性的名字，可以使用intern方法来节省空间。常量池分为：类文件常量池，运行时常量池，字符串常量池。JDK7之前运行时常量池包含字符串常量池，都在方法区，此时对方法区的实现为永久代；JDK7运行时常量池还在方法区，但是字符串常量池放到了堆；JDK8时，永久代移除，变为了元空间，此时运行时常量池在元空间，字符串常量池在堆。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java调优-概述]]></title>
    <url>%2FJava%E8%B0%83%E4%BC%98-%E6%A6%82%E8%BF%B0.html</url>
    <content type="text"><![CDATA[概述最近在阿里做驻场开发，发现阿里的员工考虑问题习惯从How、When、What三个角度来考虑事情，针对Java调优，恰好在这篇文章中也锻炼一下这种思维。What？Java调优不只是针对代码的调优，还有对项目的调优、JVM的调优、数据库的调优，甚至还有设计方面的调优。学习调优的好处不仅能够提高系统性能指标，还可以节省公司资源。When？介入性能调优的时期最好是在系统编码完成以后，在进行功能测试的同时可以再做性能测试，借此分析是否按足访问量的要求。How？首先了解哪些计算机资源会成为系统性能瓶颈：内存；磁盘I/O；网络I/O；异常：Java应用中，抛出异常需要构建异常栈，高并发场景中会影响到系统性能；数据库：数据库的操作往往涉及到磁盘I/O，而调用数据库也会产生网络消耗；锁竞争。衡量系统性能的因素：响应时间：数据库操作消耗时间；服务端响应时间：Nginx分发+服务端程序执行；网络响应时间；网络传输时硬件解析的耗时；客户端响应时间：客户端处理耗时。吞吐量：TPS，包含两个方面：IOPS：磁盘吞吐量；网络吞吐量。资源分配使用率；负载承受力。调优策略测试 - 分析 - 调优微基准性能测试定位到某个模块或者某个方法的性能问题。宏基准性能测试考虑到测试环境、测试场景和测试目标，如果达标可以继续加大测试的并发数，探底TPS。1.热身问题虚拟机会将频繁运行的方法或者代码块通过JIT编译成与本地平台相关的机器码，并进行各个层次的优化，然后存储在内存中。2.测试结果不稳定通过多次测试，统计结果获得平均值。3.多JVM避免多JVM的环境。性能测试报告包含元素：接口平均、最大、最小吞吐量，响应时间，服务器CPU、内存、I/O、网络使用率、GC频率等。策略自下而上：操作系统层面；JVM层面；应用程序。策略：优化代码：例如遍历循环时采用合适的方式；优化设计：例如使用单例模式创建常被使用并且无状态的类，例如Spring Bean；优化算法；时间换空间：存储空间要求比较严苛的场景；空间换时间：Mysql分库分表提升访问性能；JVM参数调优，减少GC占用时间；制定兜底策略（保证系统稳定性）：限流；根据需求自动横向新增服务；提前扩容（例如抢购业务）；总结]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入Tomcat/Jetty(七)-性能优化]]></title>
    <url>%2F%E6%B7%B1%E5%85%A5Tomcat-Jetty-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96.html</url>
    <content type="text"><![CDATA[CMS 和 G1CMS将整个堆分成了新生代、老年代两大部分，新生代分为Eden和Survivor，新的对象通常情况下都在Eden区域创建，收集一次以后如果对象还在则会转移到Survivor区域，收集多次达到一定次数对象还在的话就会转移到老年代。分代收集是为了更好地管理和回收对象，因为每个代对对象管理的方法不一样。G1使用非连续空间，所以它能够管理更大的堆，同时能够并发完成大部分GC的工作，这期间不会发生STW；G1管理的每个区域都称之为region，它的固定大小通常为2m。调优原则CMS：合理设置新生代和老年代的大小；G1：设置堆总的大小和GC最大停顿时间：-XX:MaxGCPauseMillis;JVM调优工具Apache Jmeter：5.1.1，https://jmeter.apache.org/download_jmeter.cgi；GCViewer：JDK 8使用 1.3.5的Release版本即可，如果是JDK 8以上，需要下载1.3.5以上的版本，没有的话可能需要自己下载当前最新代码进行构建，https://github.com/chewiebug/GCViewer。代码创建一个Spring Boot程序（Spring Boot 2.1），只需要mvc依赖即可，测试代码如下：12345678910111213141516171819@RestControllerpublic class GcTestController &#123; //公有的全局变量，队列里数量到达200000即进行回收，用来模仿老年代对象 private Queue&lt;Greeting&gt; objCache = new ConcurrentLinkedQueue&lt;&gt;(); @GetMapping("/greeting") public Greeting greeting()&#123; Greeting greeting = new Greeting("Hello World"); if (objCache.size() &gt; 200000) objCache.clear(); else objCache.add(greeting); return greeting; &#125;&#125;@Data@AllArgsConstructorclass Greeting&#123; private String message;&#125;JDK8 下，启动参数如下：java -Xmx32m -Xss256k -verbose:gc -Xloggc:gc-pid%p-%t.log -XX:+PrintGCDetails -jar target/tomcat-jetty-test-0.0.1-SNAPSHOT.jar。JDK 9以及以上，启动参数如下：java -Xmx32m -Xss256k -verbosegc -Xlog:gc*,gc+ref=debug,gc+heap=debug,gc+age=trace:file=gc-%p-%t.log:tags,uptime,time,level:filecount=2,filesize=100m32M方便看到Full GC，-verbose:gc打印GC日志，-xloggc:gc用于生成gc日志文件，后面是文件名格式，PrintGCDetails打印日志详情包括停顿时间等。使用Jmeter工具创建一个线程组，并创建一个Http请求，持续时间为15分钟。15分钟以后，使用GCviewer打开gc日志，结果如下：这里只勾选了上面view工具栏中的蓝色、黑色、绿色这三条线，蓝色代表使用的堆，黑色代表进行了full gc，密集绿色代表了总的GC。可以得出结论：堆的使用率提升导致了新生代频繁GC（绿色线）；full gc以后堆内存降低，不是内存泄漏。所以判断出，这是堆内存不够，因为绿色线和黑色线都比较密集。调大内存，再试一试15分钟Jmeter：java -Xmx1024m -Xss256k -verbose:gc -Xloggc:gc-pid%p-%t.log -XX:+PrintGCDetails -jar target/tomcat-jetty-test-0.0.1-SNAPSHOT.jar可以看到没有了Full GC，并且新生代GC没有上一幅图那么频繁密集，而GC停顿时间也只有2.6秒，比上图15秒好太多了。监控为了模拟服务端Tomcat的监控，改造一下上节的spring boot项目，主要是pom文件里的两个依赖：12345678910111213141516&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;然后修改启动类中的代码：12345678910111213@SpringBootApplicationpublic class Application extends SpringBootServletInitializer &#123; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder builder) &#123; return builder.sources(Application.class); &#125; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125;如果提示缺少javax的jar包，在pom文件中引入并将scope填写为provided即可。这样就可以放到外置的Tomcat容器中运行了，在启动外置Tomcat之前，还需要编辑一个脚本文件setenv.sh，写入以下脚本：12345export JAVA_OPTS="$&#123;JAVA_OPTS&#125; -Dcom.sun.management.jmxremote"export JAVA_OPTS="$&#123;JAVA_OPTS&#125; -Dcom.sun.management.jmxremote.port=9001"export JAVA_OPTS="$&#123;JAVA_OPTS&#125; -Djava.rmi.server.hostname=x.x.x.x"export JAVA_OPTS="$&#123;JAVA_OPTS&#125; -Dcom.sun.management.jmxremote.ssl=false"export JAVA_OPTS="$&#123;JAVA_OPTS&#125; -Dcom.sun.management.jmxremote.authenticate=false"放到tomcat的bin目录下，这样即可设置好环境变量，但是使用bin目录下shutdown.sh关闭时可能会报address already in use的错，猜测是在执行该脚本的时候又执行了setenv.sh文件，所以报了地址被占用的错。推荐在bin目录下再写一个脚本：1234#! /bin/shsource /etc/profileps -ef | grep tomcat | grep -v grep | awk '&#123;print $2&#125;'| xargs killsh /usr/local/tomcat9/bin/startup.sh用于重启tomcat。输入jconsole x.x.x.x:9001打开jconsole界面，这里主要记录吞吐量、响应时间、错误数、线程池、CPU、JVM情况等。maxTime:最长响应时间；processTime:平均响应时间；requestCount:吞吐量；errorCount:错误数。线程标签可以看到线程的堆栈和等待状态，以及堆栈；内存标签能够看到各个区的空间使用量，VM概要能够看到JVM的基本信息。命令行可以使用以下方式：12ps -ef | grep tomcatcat /proc/30086/status其中30086就是tomcat的pid，然后使用top -p 30086可以看到该进程所占用的系统资源。工具和上一节一样。实战在controller添加代码：12345678910@GetMapping("/greeting/latency/&#123;seconds&#125;") public Greeting delayGreeting(@PathVariable Long seconds)&#123; try &#123; TimeUnit.SECONDS.sleep(seconds); &#125; catch (InterruptedException e) &#123; log.error("睡眠异常", e); &#125; Greeting greeting = new Greeting("Hello Second"); return greeting; &#125;通过url传入参数来达到睡眠的效果。使用Jmeter测试，分为三个阶段，即睡眠2s、睡眠4s和睡眠6s来测试，同时设置线程组响应超时为1000ms（这样Jemeter就不会等到请求返回），100个线程。得到如下结果：图中有几条不和谐的线是当时由于连接数太多导致Jconsole丢失连接，所以线程数降为0。首先看线程，一开始压测未开始的时候只有30条线程左右，等到2s睡眠的压测开始以后，由于睡眠2s才会返回数据，所以同时有200条线程在运行，加上一些负责网络通线和后台任务，线程一共差不多250条左右；第一阶段停止后，又下降到40（不是0，为0是因为第二阶段压测开始，丢失连接导致无法正确获取数据），第二阶段需要450条线程，第三阶段需要650条左右线程。再看内存，基本上随着线程的增加，创建线程导致内存的消耗也会提高。最后看CPU，基本上CPU的峰值稳定，只要吞吐量一定，CPU的占用率基本保持一定。I/O和线程池调优I/O选择NIO：Tomcat默认的连接器，大多数场景够用；ARP：适用于 TLS加密传输的场景，通过OpenSSL（C语言实现）实现；NIO2：用于Windows系统，因为Linux的异步本质上和NIO的底层都是通过epoll实现，相比而言NIO会更简单高效。线程池调优线程池核心参数：threadPriority（优先级，默认是5）；daemon（是否后台线程，默认是tue）；namePrefix（线程前缀）；maxThreads（线程池中最大线程数，默认是200）；minSpareThreads（最小线程数、线程空闲超过一定时间会回收，默认是25）；maxIdleTime（线程最大空闲时间，超过该时间就会回收，默认是一分钟）；maxQueueSize（任务队列长度，默认是Integer.MAX_VALUE）;prestartminSpareThreads（是否在线程池启动时就创建最小线程数，默认为false）。重点是最大线程数，如果过小，会产生线程饥饿，大量任务等待；如果过大，会耗费大量的cpu资源和内存资源。利特尔法则（Little`s Law）系统中请求数 = 请求到达速率 * 每个请求处理时间对应：线程池大小 = 每秒请求数 * 平均请求处理时间上面是理想公式，不考虑I/O的情况，如果是I/O密集型任务，那么需要更多线程。考虑综合情况：线程池大小 = （线程I/O阻塞时间+线程CPU时间） / 线程CPU时间其中上面公式中括号里的I/O阻塞时间 + 线程CPU时间 = 平均处理时间；根据上面两个公式，可以得到下面三个结论：请求处理时间越长，需要的线程数越多；请求处理过程中，I/O等待时间越长，需要的线程数越多；请求进来的速率越快，需要的线程数越多。实际上，线程池个数是先用上面两个公式算出大概的数字（先用较小的值），然后通过压测调整从而达到最优。先设置一个较小的值，通过压测发现错误数增加或者响应时间大幅度增加等情况，就调大线程数，如果发现线程数增大并没有提升TPS甚至下降，那这个值可以认为是最佳线程数。OOM分析Java heap space原因可能有三种：内存泄漏；配置过低；finalize方法的过度使用，添加了该方法的对象实例会被添加到”java.lang.ref.Finalizer.ReferenceQueue”的队列中，直到执行了finalize()了以后才会回收。解决：通过heap dump日志以及stack信息追踪，适当调大配置，不使用finalize方法。GC overhead limit exceeded垃圾收集器一直在运行，但是效率很低。解决：查看GC日志或者生成Heap Dump。Requested array size exceeds VM limit尝试请求了一个超出VM限制的数组。解决：调大配置，或者是代码计算错误。MetaSpace元空间耗尽，可能本地空间耗尽或者分配的太小。Request size bytes for reason. Out of swap space本地堆内存或者本地内存快要耗尽。解决：需要根据JVM抛出的错误信息来进行诊断，或者使用操作系统的DTrace工具来跟着那个系统调用。unable to create native threads步骤：请求新线程；JVM本地native code代理该请求向操作系统申请创建native thread；操作系统尝试创建native thread，并分配-Xss线程栈；由于各种原因，分配失败，抛出上述异常。用户空间内存 = 堆内存 + 元数据空间内存 + 线程数 * 栈空间，由于内存空间的不足导致了创建线程创建失败。Linux的系统限制也会导致该情况，执行ulimit -a，看到以下结果：12345678910111213141516171819[root@VM_0_8_centos ~]# ulimit -acore file size (blocks, -c) 0data seg size (kbytes, -d) unlimitedscheduling priority (-e) 0file size (blocks, -f) unlimitedpending signals (-i) 7281max locked memory (kbytes, -l) 64max memory size (kbytes, -m) unlimitedopen files (-n) 100001pipe size (512 bytes, -p) 8POSIX message queues (bytes, -q) 819200real-time priority (-r) 0## 线程栈大小stack size (kbytes, -s) 8192cpu time (seconds, -t) unlimited## 用户最大进程限制max user processes (-u) 7281virtual memory (kbytes, -v) unlimitedfile locks (-x) unlimited可以使用ulimit -u 65535进行修改。系统中sys.kernal.threads-max限制了全局的系统参数：12[root@VM_0_8_centos ~]# cat /proc/sys/kernel/threads-max 14563可以在/etc/sysctl.conf配置文件中，加入sys.kernal.threads-max=99999；sys.kernal.pid_max限制了系统全局的PID号数值的限制，每一个线程都有自己的id，id超过这个值线程就会创建事变。同样可以在/etc/sysctl.conf加入sys.kernal.pid_max=99999。内存泄漏实战使用上面的程序，写入代码：123456789101112131415@Slf4j@Componentpublic class MemLeader &#123; private List&lt;Object&gt; objs = new LinkedList&lt;&gt;(); @Scheduled(fixedRate = 1000) public void run()&#123; log.info("scheduler run"); for (int i = 0; i &lt; 50000 ; i++)&#123; objs.add(new Object()); &#125; &#125;&#125;每秒启动一次定时job，记住要在启动类加上@EnableScheduling，模拟内存泄漏，然后使用jps和jstat -gc pid 2000 1000观察内存分配情况。其中参数简介如下：S0C：表示第一个Survivor总大小；S1C：第二个Survivor总大小；S0U：第一个Survivor已使用的大小；S1C：第二个Survivor已使用的大小。后面的E表示Eden区域，O表示Old区域，M表示Metaspace，CCSC压缩空间，YGC是指YoungGC，FGC是FullGC。使用gcviewer打开gc.log文件，如下：蓝色的是堆内存，粉红色线是老年代的使用内存，黑色线是full GC，可以看到后期在频繁地进行full gc，但是堆内存和老年代的内存并没有降下来，此时我们需要使用jmap -dump:live,format=b,file=153232.bin 153232将堆内存情况转储下来，并借助Eclipse Memory Analyzer（下载地址https://www.eclipse.org/mat/downloads.php）打开dump文件进行分析。网络优化java.net.SocketTimeoutException连接超时或者读取超时，即Socket.connect或者Socket.read超时，连接超时通常是由于网络不稳定造成的，但是读取超时可能是由于下游服务响应时间过长造成。java.net.BindException:Address already in use:JVM_Bind端口被占用，可以用netstat -an查看，并换一个端口。java.net.ConnectException:Connection refused:connect指定IP地址没有找到；或者是指定IP没有开辟指定的端口号。java.net.SocketException:Socket is closed一方关闭了连接，但是另一方又调用了读写操作。java.net.SocketException:Connection reset/Connect reset by peer:Socket write error一方在读写数据的时候另一方关闭了连接，或者退出了程序。tips：网络通信编程要保证程序退出前要关闭所有的网络连接，检测另一方的关闭连接操作，检测到的同时自己也要关闭。java.net.SocketException:Too many open files进程打开文件句柄数超过限制，lsof -p pid可以看到进程打开了哪些文件，是不是又资源泄漏的情况。网络参数三次握手：客户端向服务端发送SYN，服务端回复SYN+ACK，同时将这个处于SYN_RECV状态的连接保存到半连接队列，客户端返回ACK，同时服务端将处于ESTABLISHED状态的连接放入accept队列，等待应用程序比如tomcat调用accept方法从队列中取走。半连接队列：保存SYN_RECV状态的连接，由net.ipv4.tcp_max_syn_backlog设置；accept队列：保存ESTABLISHED状态的连接，队列长度为min(net.core.somaxconn,backlog)，backlog是创建ServerSocket时指定的参数，也就是Tomcat的acceptCount参数，默认是100，但是net.core.somaxconn（该参数位于/etc/sysctl.conf里，修改该文件后需要执行sysctl -p）默认是128，所以当高并发请求进入时，会导致accept队列快速积满，然后产生connection reset的错误。maxConnection是Tomcat在任意时刻接收和处理的最大线程数，当接受的连接数到达该最大值时，Accept线程不会从accept队列中取走数据，导致数据越积越多。NIO默认是10000，ARP默认是8192。CPU占用JVM在峰值下的负载常常为40%，如果飙升到80%可以认为不合理。问题定位：找到哪些线程在大量消耗CPU资源，通过线程栈；如果1不存在，猜测是不是大量的线程上下文切换。实战，新增一个定时任务：12345678910private ExecutorService executorService = Executors.newFixedThreadPool(4096); private int count; @Scheduled(fixedRate = 10) public void lockContention()&#123; IntStream.range(0,1000000).forEach(i -&gt; executorService.submit(this::increamSync)); &#125; private synchronized void increamSync()&#123; count = (count + 1) % 100000; &#125;设置栈-Xss256k防止出现OOM，然后启动该程序，使用top命令，结果如下：发现Java进程占用了93%的CPU资源，使用top -H -p 10095可以看到进程内更详细的信息：这里可以看到各个线程的一个资源占用情况，由于这里各个线程都没有显示名称，所以更近一步的情况不太好看到，这里记载一下如果能够看到更详细的线程名字时下一步的做法：1234# 输出堆栈信息到log文件里，可以在log文件里查看具体信息jstack 10095 &gt; 10095.log# 查看pool-1-thread 在日志文件中出现的数量，可以粗略判断占用情况grep -o 'pool-1-thread' 10095.log | wc -l进入到日志文件里查看某个线程的状态，这里要理解Java中线程的几种状态：如果看到大量线程处于blocking状态，则证明：在等待锁的释放；如果看到大量线程处于waiting状态，则证明：在等待其他线程执行某项操作。详细的进程内信息表明只占用了不到79%的CPU，那么剩下的CPU开销猜测有可能是发生了大量的线程上下文切换导致的，使用vmstat（https://linux.die.net/man/8/vmstat）可以查看：其中，in是CPU中断次数，cs是上下文切换次数。此时我再把这个Java进程停掉，再次查看信息：表明就是该Java进程占用了大量CPU资源。Jetty性能调优操作系统层面参数主要在/etc/security/limits.conf中，或者直接使用sysctl命令进行配置，这些配置理论来说，对于Tomcat也是实用的。1234567891011121314## 调整TCP的发送和接收缓冲区sysctl -w net.core.rmem_max = 16777216sysctl -w net.core.wmem_max = 16777216sysctl -w net.ipv4.tcp_rmem =“4096 87380 16777216”sysctl -w net.ipv4.tcp_wmem =“4096 16384 16777216”## 控制TCP连接队列大小sysctl -w net.core.somaxconn = 4096## 传入数据队列的大小sysctl -w net.core.netdev_max_backlog = 16384sysctl -w net.ipv4.tcp_max_syn_backlog = 8192sysctl -w net.ipv4.tcp_syncookies = 1## 增加可用端口范围，允许在TIME_WAIT中重用套接字sysctl -w net.ipv4.ip_local_port_range =“1024 65535”sysctl -w net.ipv4.tcp_tw_recycle = 1高负载服务器的文件句柄数很容易耗尽，可以在/etc/security/limits.conf文件中增加以下配置：12用户名 hard nofile 40000用户名 soft nofile 40000获取内核可用的拥塞控制算法：sysctl net.ipv4.tcp_available_congestion_control;推荐设置为cubic：sysctl -w net.ipv4.tcp_congestion_control = cubic容器层面Acceptor的个数大于等于1并且小于等于CPU核数：因为每个Acceptor是和每一个线程绑定的；ThreadPool大小 = 应用的TPS * 任务最多在等待队列中存在的时间；线程池合理配置，根据压测数据进行调整，线程池的提升同时也需要提升堆内存，通常线程池数量在50-500之间；Jetty性能测试首先下载Jetty容器jar包：https://repo1.maven.org/maven2/org/eclipse/jetty/aggregate/jetty-all/9.4.19.v20190610/jetty-all-9.4.19.v20190610-uber.jar；然后下载apache benchmark 的包，ab集成在了apache中，下载httpd即可：http://httpd.apache.org/download.cgi，安装过程与Nginx类似，即configure - make - make install的步骤，详情参考：Nginx安装实践；编写一个Java文件HelloWorld.java，代码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243import org.eclipse.jetty.server.*;import org.eclipse.jetty.server.handler.AbstractHandler;import org.eclipse.jetty.util.thread.QueuedThreadPool;import javax.servlet.ServletException;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;/** * @description: * @author: 刘会俊 * @date: 2019-09-01 16:28 */public class HelloWorld extends AbstractHandler &#123; @Override public void handle(String target, Request baseRequest, HttpServletRequest request, HttpServletResponse response) throws IOException, ServletException &#123; response.setContentType("text/html; charset=utf-8"); response.setStatus(HttpServletResponse.SC_OK); response.getWriter().println("&lt;h1&gt;Hello World&lt;/h1&gt;"); baseRequest.setHandled(true); &#125; public static void main(String[] args) throws Exception &#123; // 根据传入的参数控制线程池中最大线程数的大小 int maxThreads = Integer.parseInt(args[0]); System.out.println("maxThreads:" + maxThreads); // 创建线程池 QueuedThreadPool threadPool = new QueuedThreadPool(); threadPool.setMaxThreads(maxThreads); Server server = new Server(threadPool); ServerConnector http = new ServerConnector(server, new HttpConnectionFactory(new HttpConfiguration())); http.setPort(8000); server.addConnector(http); server.start(); server.join(); &#125;&#125;将jetty的包改名为jetty.jar，并复制到HelloWorld.java同一目录下；使用Jetty的包编译自己的Handler：javac -cp jetty.jar HelloWorld.java；启动jetty，线程池大小为4：java -cp .:jetty.jar HelloWorld 4;启动ab（20万个请求，100个线程同时发送）：ab -n 200000 -c 100 http://localhost:8000/；(实验中出了些问题，导致访问localhost:8000/的时候一直404所以以下为别人的测试结果)：RPS达到了20020，此时逐渐调大线程数到6，8，16等，结果如下：maxThread46816128256RPS200202343122571212551793815296所以，最佳线程数是6，因为这里都是CPU在处理任务，而几乎没有I/O阻塞，对于这种程序，最大最好设置为CPU核数的1.5倍；但是现实的web程序几乎都涉及到I/O阻塞，所以前文中会说jetty通常是50-500。Note：QPS：Queries Per Second，每秒的请求数，单次请求来算；TPS：Transactions Per Second，每秒事务数，某个接口返回的数据可能中间调用了其他数据，例如一个页面有css、js、html三次请求，一个接口或者一个页面就称为一个事务；PV：Page View，页面浏览量；RV：Repeat Visitors，重复访问者数量；GMV：Gros Merchandise Volume，只要是订单，不管消费者是否付款、卖家是否发货、是否退货，都可以放进GMV；RPS：Requests Per Second，类似于QPS，同一种统计方式的两种叫法。Jetty 和 TomcatJetty：简洁小巧，一个Jar包即可，只有不到4M。扩展Handler和剪裁容易，Hadoop和Solr的内置服务容器；Tomcat：多级、父子容器，扩展Valve较为方便，但学习成本比Jetty稍高。（由于硬件关系，以下为别人的测试代码，尚未验证）使用上文中监控一节的休眠代码，模拟I/O阻塞，Jmeter客户端线程数100，压测10分钟，查看统计指标：tomcat的tps、资源占用如下：排除Tomcat的包，使用Jetty的包，Jetty的tps、资源占用如下：结论：TPS/s平均延迟/ms错误率/%CPU/%内存/MBClass数量线程数Tomcat98.8101000.8约2007092218Jetty101.29862.451.1约1607264161Jetty吞吐量、线程开销和资源占用略好于Tomcat，恰好反映其设计很轻量小巧；Tomcat比Jetty更加稳定。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Jetty</tag>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入Tomcat/Jetty(六)-通用组件]]></title>
    <url>%2F%E6%B7%B1%E5%85%A5Tomcat-Jetty-%E9%80%9A%E7%94%A8%E7%BB%84%E4%BB%B6.html</url>
    <content type="text"><![CDATA[日志框架slf4j：日志接口和门面，记录日志；JCL：commons logging，和slf4j类似的门面日志；log4j：第三方日志输出的具体实现；JUL：Java原生的日志输出；logback：第三方日志输出，性能由于log4j，也是Spring Boot默认日志框架；log4j2：第三方日志输出的具体实现，号称目前Java平台性能最好。slf4j结构如下：Java 日志框架路径：java.util.logging；Logger：记录日志；Handler：日志输出格式；Level：日志的不同等级；Formatter：日志信息格式化；使用示例：123456789public static void main(String[] args) &#123; Logger logger = Logger.getLogger("com.mycompany.myapp"); logger.setLevel(Level.FINE); logger.setUseParentHandlers(false); Handler hd = new ConsoleHandler(); hd.setLevel(Level.FINE); logger.addHandler(hd); logger.info("start log"); &#125;Tomcat 日志框架JULI：基于JCL和JUL的处理框架。JVM原生的日志框架是每个JVM用同一份日志配置，但是Tomcat中每个Web应用可能有自己的日志框架；DirectJDKLog：基于JUL中的Logger类，修改了默认输出格式；LogFactory：单例，默认使用DirectJDKLog，通过ServiceLoader为Log提供自定义的实现版本；Handler：FileHandler：读写锁实现，在某个特定位置往文件里输出日志；AsyncFileHandler：继承自FileHandler，实现了异步写操作，缓存存储通过LinkedBlockingQueue来实现，通过publish方法写入相应文件内。Formatter：通过format方法将日志记录LogRecord转化成格式化的字符串，JULI提供了三个新的Formatter：OnlineFormatter：基本类似于JDK的SimpleFormatter，只不过把所有内容写到了同一行。VerbatimFormatter：只记录日志信息，没有任何额外信息；JdkLoggerFormatter：格式化了一个轻量级的日志信息。配置文件：conf/logging.properties；以1catalina.org.apache.juli.AsyncFileHandler为例：数字是为了区分同一个类的不同实例；catalina、localhost、manager和host-manager是Tomcat用来区分不同系统日志类的标志，后面的字符串表示了handler具体类型，如果需要添加Tomcat服务器的自定义Handler，需要在字符串里添加。接下来是日志等级，目录和文件前缀等。123451catalina.org.apache.juli.AsyncFileHandler.level = FINE1catalina.org.apache.juli.AsyncFileHandler.directory = $&#123;catalina.base&#125;/logs1catalina.org.apache.juli.AsyncFileHandler.prefix = catalina.1catalina.org.apache.juli.AsyncFileHandler.maxDays = 901catalina.org.apache.juli.AsyncFileHandler.encoding = UTF-8Tomcat+Slf4j+Logback去下该地址下载适合自己版本的Tomcat：https://github.com/tomcat-slf4j-logback/tomcat-slf4j-logback/releases/；解压以后分别用bin、conf、lib下的内容替换或者复制到自己原有的Tomcat对应目录里；启动Tomcat，可以看到日志格式已经变了：123456718:06:17.595 INFO &#123;main&#125; [o.a.c.h.Http11NioProtocol] : Initializing ProtocolHandler ["http-nio-8080"]18:06:17.996 INFO &#123;main&#125; [o.a.t.u.n.NioSelectorPool] : Using a shared selector for servlet write/read18:06:18.010 INFO &#123;main&#125; [o.a.c.a.AjpNioProtocol] : Initializing ProtocolHandler ["ajp-nio-8009"]18:06:18.018 INFO &#123;main&#125; [o.a.t.u.n.NioSelectorPool] : Using a shared selector for servlet write/read18:06:32.216 INFO &#123;main&#125; [o.a.j.s.TldScanner] : At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.18:06:33.843 INFO &#123;main&#125; [o.a.c.h.Http11NioProtocol] : Starting ProtocolHandler ["http-nio-8080"]18:06:33.860 INFO &#123;main&#125; [o.a.c.a.AjpNioProtocol] : Starting ProtocolHandler ["ajp-nio-8009"]Session管理Session的创建Context中的interface Manager，默认实现类是StandardManager。主要API：load：持久化；unload：从磁盘加载；getSession：获取该次请求的session，如果参数为ture，不存在时会新建；class Request：Tomcat实现了HttpServletRequest的类；class RequestFacade：具体拿到的类，为了保证安全在Request上做的包装；Request持有context，context持有manager，manager创建session。Tomcat中Session的具体实现类是StandardSession，StandardSession implements javax.servlet.http.HttpSession,org.apache.catalina.Session，所有创建的session都在一个名为sessions的ConcurrentHashMap中。Session的清理StandardContext调用StandardManager的后台backgroundProcess完成session的清理。每隔10s启动一次，backgroundProcess调用6（对6进行了取模）次才会执行一次session清理。Session事件通知servlet：Session生命周期过程中，要将事件通知监听者：interface HttpSessionListener extends EventListener。通过StandardContext中的集合取出HttpSessionListener类型的监听器，依次调用它们的sessionCreated方法或者sessionDestroyed方法。集群通信需要将server.xml中集群的一行注释打开：123&lt;!-- &lt;Cluster className="org.apache.catalina.ha.tcp.SimpleTcpCluster"/&gt; --&gt;该配置等同于以下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141&lt;!-- SimpleTcpCluster 是用来复制 Session 的组件。复制 Session 有同步和异步两种方式： 同步模式下，向浏览器的发送响应数据前，需要先将 Session 拷贝到其他节点完； 异步模式下，无需等待 Session 拷贝完成就可响应。异步模式更高效，但是同步模式 可靠性更高。 同步异步模式由 channelSendOptions 参数控制，默认值是 8，为异步模式；4 是同步模式。 在异步模式下，可以通过加上 " 拷贝确认 "（Acknowledge）来提高可靠性，此时 channelSendOptions 设为 10--&gt;&lt;Cluster className="org.apache.catalina.ha.tcp.SimpleTcpCluster" channelSendOptions="8"&gt; &lt;!-- Manager 决定如何管理集群的 Session 信息。 Tomcat 提供了两种 Manager：BackupManager 和 DeltaManager。 BackupManager－集群下的某一节点的 Session，将复制到一个备份节点。 DeltaManager－ 集群下某一节点的 Session，将复制到所有其他节点。 DeltaManager 是 Tomcat 默认的集群 Manager。 expireSessionsOnShutdown－设置为 true 时，一个节点关闭时， 将导致集群下的所有 Session 失效 notifyListenersOnReplication－集群下节点间的 Session 复制、 删除操作，是否通知 session listeners maxInactiveInterval－集群下 Session 的有效时间 (单位:s)。 maxInactiveInterval 内未活动的 Session，将被 Tomcat 回收。 默认值为 1800(30min) --&gt; &lt;Manager className="org.apache.catalina.ha.session.DeltaManager" expireSessionsOnShutdown="false" notifyListenersOnReplication="true"/&gt; &lt;!-- Channel 是 Tomcat 节点之间进行通讯的工具。 Channel 包括 5 个组件：Membership、Receiver、Sender、 Transport、Interceptor --&gt; &lt;Channel className="org.apache.catalina.tribes.group.GroupChannel"&gt; &lt;!-- Membership 维护集群的可用节点列表。它可以检查到新增的节点， 也可以检查没有心跳的节点 className－指定 Membership 使用的类 address－组播地址 port－组播端口 frequency－发送心跳 (向组播地址发送 UDP 数据包) 的时间间隔 (单位:ms)。 dropTime－Membership 在 dropTime(单位:ms) 内未收到某一节点的心跳， 则将该节点从可用节点列表删除。默认值为 3000。 --&gt; &lt;Membership className="org.apache.catalina.tribes.membership. McastService" address="228.0.0.4" port="45564" frequency="500" dropTime="3000"/&gt; &lt;!-- Receiver 用于各个节点接收其他节点发送的数据。 接收器分为两种：BioReceiver(阻塞式)、NioReceiver(非阻塞式) className－指定 Receiver 使用的类 address－接收消息的地址 port－接收消息的端口 autoBind－端口的变化区间，如果 port 为 4000，autoBind 为 100， 接收器将在 4000-4099 间取一个端口进行监听。 selectorTimeout－NioReceiver 内 Selector 轮询的超时时间 maxThreads－线程池的最大线程数 --&gt; &lt;Receiver className="org.apache.catalina.tribes.transport.nio. NioReceiver" address="auto" port="4000" autoBind="100" selectorTimeout="5000" maxThreads="6"/&gt; &lt;!-- Sender 用于向其他节点发送数据，Sender 内嵌了 Transport 组件， Transport 真正负责发送消息。 --&gt; &lt;Sender className="org.apache.catalina.tribes.transport. ReplicationTransmitter"&gt; &lt;!-- Transport 分为两种：bio.PooledMultiSender(阻塞式) 和 nio.PooledParallelSender(非阻塞式)，PooledParallelSender 是从 tcp 连接池中获取连接，可以实现并行发送，即集群中的节点可以 同时向其他所有节点发送数据而互不影响。 --&gt; &lt;Transport className="org.apache.catalina.tribes. transport.nio.PooledParallelSender"/&gt; &lt;/Sender&gt; &lt;!-- Interceptor : Cluster 的拦截器 TcpFailureDetector－TcpFailureDetector 可以拦截到某个节点关闭 的信息，并尝试通过 TCP 连接到此节点，以确保此节点真正关闭，从而更新集 群可用节点列表 --&gt; &lt;Interceptor className="org.apache.catalina.tribes.group. interceptors.TcpFailureDetector"/&gt; &lt;!-- MessageDispatchInterceptor－查看 Cluster 组件发送消息的 方式是否设置为 Channel.SEND_OPTIONS_ASYNCHRONOUS，如果是， MessageDispatchInterceptor 先将等待发送的消息进行排队， 然后将排好队的消息转给 Sender。 --&gt; &lt;Interceptor className="org.apache.catalina.tribes.group. interceptors.MessageDispatchInterceptor"/&gt; &lt;/Channel&gt; &lt;!-- Valve : Tomcat 的拦截器， ReplicationValve－在处理请求前后打日志；过滤不涉及 Session 变化的请求。 --&gt; &lt;Valve className="org.apache.catalina.ha.tcp.ReplicationValve" filter=""/&gt; &lt;Valve className="org.apache.catalina.ha.session. JvmRouteBinderValve"/&gt; &lt;valve className="org.apache.catalina.ha.tcp.ReplicationValve" filter=".*\.gif|.*\.js|.*\.jpeg|.*\.jpg|.*\.png|.*\.htm|.*\.html|.*\.css|.*\.txt" &lt;!-- Deployer 用于集群的 farm 功能，监控应用中文件的更新，以保证集群中所有节点 应用的一致性，如某个用户上传文件到集群中某个节点的应用程序目录下，Deployer 会监测到这一操作并把文件拷贝到集群中其他节点相同应用的对应目录下以保持 所有应用的一致，这是一个相当强大的功能。 --&gt; &lt;Deployer className="org.apache.catalina.ha.deploy.FarmWarDeployer" tempDir="/tmp/war-temp/" deployDir="/tmp/war-deploy/" watchDir="/tmp/war-listen/" watchEnabled="false"/&gt; &lt;!-- ClusterListener : 监听器，监听 Cluster 组件接收的消息 使用 DeltaManager 时，Cluster 接收的信息通过 ClusterSessionListener 传递给 DeltaManager，从而更新自己的 Session 列表。 --&gt; &lt;ClusterListener className="org.apache.catalina.ha.session. ClusterSessionListener"/&gt; &lt;/Cluster&gt;集群同通信：组播，即Tomcat启动和运行的时候会周期性（默认500ms）向一组服务器发送组播心跳包，同一个集群的Tomcat都在相同的地址和端口监听这些信息，一定时间（默认3s）内不发送组播报文的节点被认为删除，就将其从本地维护的集群列表中移除。默认情况下，使用DeltaManager进行集群通信，采用的是All-to-All的工作方式，Session会拷贝到集群内所有服务，集群内数量比较多的时候同步时间较长。也可以使用BackupManager进行通信，Session只会拷贝到备份节点。集群时，推荐所有的Tomcat使用相同的配置。工作过程（Tomcat A和Tomcat B构成集群）：当在server.xml中配置了cluster组件时，Tomcat A在启动Host容器时，会关联Cluster组件。如果web应用在web.xml中配置了Distributable时，Tomcat会为此上下文创建一个DeltaManager，Cluster的默认实现SimpleTcpCluster启动Membership和Replication服务；Tomcat B启动，前面也是启动Host容器，关联Cluster，然后启动一个由A和B组成的Membership。接着Tomcat B会向A请求Session数据，如果A没用响应，则60s后time out，session完成以前不回响应浏览器请求；用户请求，如果是ReplicationValve filter中配置的请求，就不拦截，否则就会更新session，并利用Replication服务通过TCP连接发送到Tomcat B进行拷贝；拷贝时会拷贝Session中所有可序列化的数据；A崩溃，Tomcat B将A从MemberShip中移除，同时负载均衡器会将所有的请求发到Tomcat B；B正常提供服务；A启动，重复1，2步；A接收用户注销请求，同时向B发送session过期的消息；B创建session，同步到A；A上的session超时过期，B同样过期（只要系统时间保持一致）。Tomcat原生的集群通信适用于小规模集群。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Jetty</tag>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入Tomcat/Jetty(五)-抽象容器]]></title>
    <url>%2F%E6%B7%B1%E5%85%A5Tomcat-Jetty-%E6%8A%BD%E8%B1%A1%E5%AE%B9%E5%99%A8.html</url>
    <content type="text"><![CDATA[Tomcat-Host容器热加载：后台线程定期检测类的变化，如果有变化，就重新加载类，不会清空session；热部署：后台线程定时检测应用的变化，如果有变化，就会清空session；线程池：ScheduledThreadPoolExecutor，周期性执行方法：12345exec.scheduleWithFixedDelay( new ContainerBackgroundProcessor(),// 要执行的 Runnable backgroundProcessorDelay, // 第一次执行延迟多久 backgroundProcessorDelay, // 之后每次执行间隔多久 TimeUnit.SECONDS); // 时间单位`ContainerBackgroundProcessor，ContainerBase内部类，实现Runnable接口；执行当前容器里的backgroundProcess()，并且递归调用子容器的backgroundProcess()，如果子容器的backgroundProcessorDelay大于0，表明子容器有自己的线程，所以此时就不用父类来调用；这个方法是接口中的默认方法，所以顶层engine启动后台线程以后，它会启动顶层engine以及子engine的周期性任务。由于ContainerBase是所有组件基类，所以其他组件都可以由自己的周期性任务。热加载通过context的backgroundProcess实现：webapploader检查WEB-INF/classes和WEB-INF/lib下目录的类文件有没有变化；sessionManager检查是否有过期session；WebResources检查静态资源是否有变化。webapploader的工作：停止和销毁context以及wrapper；停止和销毁关联的filter和listener；停止和销毁关联的pipline-value；停止和销毁类加载器，和相关的类文件资源；启动context，并重新生成前四步销毁的资源。默认情况下，Tomcat的热加载功能是关闭的，需要配置&lt;Context reloadable=&quot;true&quot;/&gt;来启用。热部署通过Host容器实现，Host通过监听HostConfig实现，HostConfig就是前文”周期性事件“的监听器。检查web应用目录是否被删除，如果被删除了就把相应的Context容器销毁；如果有新的War包，就部署相应的应用。宏观webapps目录级别，而不是web应用目录下文件的变化。Servlet管理Wrapper：核心：变量Field Servlet，方法Method loadServlet用来创建servlet并初始化（Servlet规范要求）。执行时期：延迟加载，用到时才会加载该Servlet，除非在web.xml里设置了loadOnStartUp=true，但是Wrapper会在Tomcat启动时就会被创建。机制：Pipeline-Valve链，每一个容器都有一个BasicValve，Wrapper的BasicValve为StandardWrapperValve。步骤：创建Servlet实例；给当前请求创建一个Filter链；调用这个Filter链，链中的最后一个Filter会调用Servlet。Filter管理可以在web.xml里配置，所以Filter的实例是在Context容器中管理的，本质上是用一个HashMap来保存Filter。Filter生命周期很短，是和每次请求对应的，请求结束这个Filter链就结束了。核心：ApplicationFilterChain，每个链包含了末尾的链所要调用的Servlet。最后会调用servlet的service方法。本质上和Pipeline-Valve都是一样的责任链模式，但是它的实现方式是：FilterChain有doFilter方法，并且每一个Filter首先调用FilterChain的doFilter方法，由于Filter链中会保存当前Filter所在的位置，这样就会调用下一个Filter的doFilter方法，形成了一个链式调用。Listener管理可以在web.xml里配置，所以Listener也是在Context容器中管理的。Listener可以监听容器内生命状态的变化（比如Context容器的启动和停止，Session的创建和销毁），或者Context、Session的某个属性变了或者新的请求来了等等。12345// 监听属性值变化的监听器,每个请求的属性可能不一样，所以要保证线程安全，并且写多读少private List&lt;Object&gt; applicationEventListenersList = new CopyOnWriteArrayList&lt;&gt;();// 监听生命事件的监听器，Context容器的启动和停止是能保证线程安全，所以这里直接用数组private Object applicationLifecycleListenersObjects[] = new Object[0];Tomcat定义了ServletContextListener接口作为第三方扩展，在启动的时候遍历所有该类型的监听器触发事件，Spring就是实现了这个接口，监听Context的启停事件，和LifecycleListener不同的是，LifecycleListener定义在生命周期管理组件中，由基类LifecycleBase统一管理。异步Servlet用法：@WebServlet(urlPatterns = {&quot;/async&quot;}, asyncSupported = true)；异步默认超时时长：30s；原理：req.startAsync和ctx.complete，前者创建一个异步上下文AsyncContext对象，用来保存request和response等上下文信息；CoyoteAdapter：flush数据把响应发回浏览器；如果是异步请求，就设置一个异步标志为truel，并在随后的ProtocolHandler判断该标志，如果是一个异步请求，那么它会把当前的Socket的协议处理者Processor缓存起来，将SocketWrapper对象响应的Processor存到一个Map数据结构里。ctx.complete：调用request的action方法，通知连接器这个请求处理完了—-&gt;传入操作码processSocketEvent—-&gt;processSocket—-&gt;创建SocketProcess任务类—-&gt;交给Tomcat线程池处理。适合场景：I/O密集型业务。内嵌式的Tomcat以Spring Boot为例，它抽象了WebServer接口，提供给Tomcat和Jetty去实现：12345public interface WebServer &#123; void start() throws WebServerException; void stop() throws WebServerException; int getPort();&#125;同时还提供了ServletWebServerFactory来创建容器，即返回WebServer。123public interface ServletWebServerFactory &#123; WebServer getWebServer(ServletContextInitializer... initializers);&#125;其中ServletContextInitializer就是ServletContext的初始化器，并且在getWebServer方法中会调用onStartUp方法，所以如果想在Servlet容器中注册自己的Servlet，可以实现该接口。WebServletFactoryCutomizerBeanPostProcessor：这是一个BeanPostProcessor，在postProcessBeforeInitialization过程中寻找WebServerFactoryCustomizer类型的Bean，并依次调用WebServerFactoryCustomizer接口的customize方法做一些定制化。启动过程Spring核心：ApplicationContext；抽象类：AbstractApplicationContext；方法：refresh()或者onRefresh()；原理：ServletWebServerApplicationContext重写了onRefresh方法创建内嵌式Web容器；1234567891011121314151617181920public WebServer getWebServer(ServletContextInitializer... initializers) &#123; //1. 实例化一个 Tomcat，可以理解为 Server 组件。 Tomcat tomcat = new Tomcat(); //2. 创建一个临时目录 File baseDir = this.baseDirectory != null ? this.baseDirectory : this.createTempDir("tomcat"); tomcat.setBaseDir(baseDir.getAbsolutePath()); //3. 初始化各种组件 Connector connector = new Connector(this.protocol); tomcat.getService().addConnector(connector); this.customizeConnector(connector); tomcat.setConnector(connector); tomcat.getHost().setAutoDeploy(false); this.configureEngine(tomcat.getEngine()); //4. 创建定制版的 "Context" 组件。 this.prepareContext(tomcat.getHost(), initializers); return this.getTomcatWebServer(tomcat);&#125;注册Servlet的方式注解式Spring Boot 的配置类需要开启@ServletComponentScan用于扫描@WebServlet、@WebFilter、@WebListener等。Java Config在Spring的配置类中加入Bean：1234@Beanpublic ServletRegistrationBean servletRegistrationBean() &#123; return new ServletRegistrationBean(new HelloServlet(),"/hello");&#125;动态注册实现前文提到的上下文初始化类：12345678910111213141516@Componentpublic class MyServletRegister implements ServletContextInitializer &#123; @Override public void onStartup(ServletContext servletContext) &#123; //Servlet 3.0 规范新的 API，动态注册新的Servlet ServletRegistration myServlet = servletContext .addServlet("HelloServlet", HelloServlet.class); myServlet.addMapping("/hello"); myServlet.setInitParameter("name", "Hello Servlet"); &#125;&#125;这里需要注意的是，其实ServletRegistrationBean也是通过实现ServletContextInitializer来实现的，会交给Spring来管理。而ServletContainerInitializer的实现类是被Tomcat管理的。Web容器定制在Spring Boot 2.0中，可以通过两种方式定制Web容器：通过Web容器工程ConfigurableServletWebServerFactory来定制参数：123456789@Componentpublic class MyGeneralCustomizer implements WebServerFactoryCustomizer&lt;ConfigurableServletWebServerFactory&gt; &#123; public void customize(ConfigurableServletWebServerFactory factory) &#123; factory.setPort(8081); factory.setContextPath("/hello"); &#125;&#125;通过特定web容器的工厂，比如TomcatServletWebServerFactory来进一步定制：1234567891011121314151617181920212223242526272829@Componentpublic class MyTomcatCustomizer implements WebServerFactoryCustomizer&lt;TomcatServletWebServerFactory&gt; &#123; @Override public void customize(TomcatServletWebServerFactory factory) &#123; factory.setPort(8081); factory.setContextPath("/hello"); factory.addEngineValves(new TraceValve() ); &#125;&#125;//实现追踪分布式项目中的路径class TraceValve extends ValveBase &#123; @Override public void invoke(Request request, Response response) throws IOException, ServletException &#123; request.getCoyoteRequest().getMimeHeaders(). addValue("traceid").setString("1234xxxxabcd"); Valve next = getNext(); if (null == next) &#123; return; &#125; next.invoke(request, response); &#125;&#125;Jetty-HandlerWrapperJetty通过HndlerWrapper实现责任链。WebAppContext -&gt; SessionHandler -&gt;SecurityHandler -&gt;ServletHandler。核心：protected Handler _handler，持有下一个Hadnler的引用，并且会在handle方法里执行下一个Handler。ScopeHandler：核心Handler，被间接或者直接地继承，_handler是持有的下一个Handler的引用，并且会在handler方法里调用下一个Handler；_outerScope：根据它是否为null来判断使用doScope()还是doHandler()，头节点肯定为null，其他节点的该字段肯定指向Handler链中头节点，言下之意—如果是头节点，就执行doScope，如不是头节点，执行doHandler；__outerScope：使用ThreadLocal&lt;ScopeHandler&gt;进行包装，在需要时取出赋值给_outerScope，由于一般不能在上下文作为参数传递，所以这里作为线程私有变量；_nextScope：表示下一个ScopeHandler，和_handler区别在于，_handler的下一位可能是Wrapperx，而_nextScope表示下一个必须是ScopeHandler。通过这几个参数，保证让ScopeHandler链上的doScope方法在doHandle、handle方法之前执行，并且保证不同ScopeHandler的doScope都是按照它在链上的先后顺序执行。ContextHandler：ScopeHandler的子类，类似于Tomcat中的Context组件，对应一个Web应用，功能是给Servlet的执行维护一个上下文环境，并且将请求转发到相应的Servlet，doHandler里做了请求的修正，类加载器设置，以及调用nextScope。Spring框架中的设计模式简单工厂：interface BeanFactory，使用方式：beanFatory.get(&quot;userService&quot;)；工厂方法：interface FactoryBean，使用方式：定义一个类UserFactory实现FactoryBean，那UserFactory所产生的实例就都是User了；单例模式：private final Map&lt;String,Object&gt; singletonObjects = new ConcurrentHashMap&lt;String,Object&gt;;先到HashMap中获取对象，如果没有拿到，则通过Class.forName(String)反射创建一个实例并添加到singletonObjects里。代理模式：抽象接口：代理角色和被代理角色都要实现该接口；目标对象：被代理的对象，用于实现业务；代理对象：内部含有对目标对象的引用，在执行目标对象的前后执行一部分逻辑。静态代理：12345678910111213141516171819202122//抽象接口public interface IStudentDao()&#123; void save();&#125;//目标对象public class StudentDao implements IStudentDao()&#123; public void save()&#123; System.out.println("保存成功"); &#125;&#125;//代理对象public class StudentDaoProxy implements IStudentDao()&#123; private IStudentDao target; public StudentDaoProxy(IStudentDao target)&#123; this.target = target; &#125; public void save()&#123; System.out.pritln("我增强了某某某"); target.save(); System.out.pritln("增强结束了"); &#125;&#125;Spring Aop采用的是动态代理：123456789101112131415161718192021222324//代理对象不是自己生成，而是由InvocationHandler生成和管理public class MyInvocationHandler implements InvocationHandler &#123; private Object object; public MyInvocationHandler(Object object) &#123; this.object = object; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println("开始事务"); Object result = method.invoke(object, args); System.out.println("结束事务"); return result; &#125;&#125;//测试public static void main(String[] args) &#123; IStudentDao stuDao = new StudentDao(); InvocationHandler handler = new MyInvocationHandler(stuDao); IStudentDao studentDao = (IStudentDao) Proxy.newProxyInstance(stuDao.getClass().getClassLoader(), stuDao.getClass().getInterfaces(), handler); studentDao.save(); &#125;Spring Aop有两种代理方式：JDK（JdkDynamicAopProxy implements InvocationHandler）；Cglib（CglibAopProxy）。123456789101112131415161718192021JDK 8class Proxy: private static final Class&lt;?&gt;[] constructorParams = &#123; InvocationHandler.class &#125;;//newProxyInstance：public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException &#123; //通过ProxyClassFactory调用ProxyGenerator生成了代理类 Class&lt;?&gt; cl = getProxyClass0(loader, intfs); //找到参数为InvocationHandler.class的构造函数 final Constructor&lt;?&gt; cons = cl.getConstructor(constructorParams); //创建代理类实例 return cons.newInstance(new Object[]&#123;h&#125;);&#125;//在ProxyGenerator类中：public static byte[] generateProxyClass(final String name,Class&lt;?&gt;[] interfaces, int accessFlags))&#123;&#125;private byte[] generateClassFile() &#123;&#125;//根据接口生成实现类的字节码文件而Cglib使用的是字节码拼接，不依赖接口，更强大更灵活。类加载概念：将.class文件加载到JVM方法区，并在堆区创建一个java.lang.Class的对象实例 ，作为具体业务类对象实例。时期：需要用到时才加载。Java实现：abstract class：ClassLoader，包含private final ClassLoader parent、public loadClass(String name)，protected findClass(String name)。步骤：如果父加载器不为空，委托给父加载器加载（递归），否则查找bootstrap加载器是否加载过，最后才会调用自己的findClass方法。findClass：从本地文件系统或者网络中寻找.class文件读入到内存；将读入内存的字节数组转成Class对象。JDK类加载器:BootstrapClassLoader:启动类加载器，由C语言实现，加载rt.jar，resources.jar等；ExtClassLoader:扩展类加载器，加载jre\lib\ext目录下的jar；AppClassLoader:系统类加载器，加载classpath下的类，也是默认的应用程序类加载器。自定义：用于加载自定义自定义路径下的类。这种指向不是继承关系，而是parent指向了另一个ClassLoader，所以如果想打破双亲委派的话，只需要新写一个ClassLoader继承ClassLoader类再重写loadClass和findClass。Tomcat类加载器结构：CommonClassLoader：加载那些能在Web应用和Tomcat之间共享的类；SharedClassLoader：Web应用之间能够共享的类，比如Spring；CatalinaClassLoader：加载Tomcat自身需要的类；WebAppClassLoader：每一个Web应用都有自己的WebAppClassLoader，打破了双亲委派，它会首先从本地缓存查找是否加载过，然后再去使用父加载器去查找，如果没有接着会使用ExtClassLoader（也可以说会使用BootstrapClassLoader，避免Web应用的类覆盖JRE类），然后会在本地文件系统中查找，最后会交由系统类加载器（因为Class.forName默认使用的就是AppClassLoader）。Spring 加载也是通过Class.forName的方式加载的，并且Spring加载Bean也是用的加载Spring的类加载器。通常Spring是用SharedClassLoader来加载，但是业务类又应该使用WebAppClassLoader来加载，所以Tomcat在启动的时候会设置线程上下文加载器，Spring在启动时可以通过Thrad.currentThread().getContextClassLoader()来获取类加载器来加载业务类。总结第三方Jar包加载特定Web应用的类，可以通过线程上下文加载器来实现；每个WEB应用自己的Java类文件和JAR包，分别放在WEB-INF/lib和WEB-INF/classes目录中；多个WEB应用共享类，放在Web容器指定的共享目录下。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Jetty</tag>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入Tomcat/Jetty(四)-零拷贝与高性能]]></title>
    <url>%2F%E6%B7%B1%E5%85%A5Tomcat-Jetty-%E5%86%85%E6%A0%B8%E7%9F%A5%E8%AF%86%E5%92%8C%E9%AB%98%E6%80%A7%E8%83%BD%E4%B9%8B%E9%81%93.html</url>
    <content type="text"><![CDATA[Linux-进程和线程执行程序：程序文件加载到内存，然后CPU读取和执行；进程：一次程序的执行过程；关键字：每一个进程都有自己的task_struct;内核：也是一个程序，启动时加载到内存；内存分配：假如进程分配有4G虚拟内存，但是只有当访问到的虚拟内存没有分配物理内存时，才会产生缺页中断，此时内存管理单元（MMU）才会将虚拟内存和物理内存的映射关系保存在表中，再次访问虚拟内存就能读找到物理内存页。高位1G在内核空间，低位3G在用户空间。只有内核才可以直接访问各种资源，如果用户向访问，需要调用内核函数，比如ssize_t read(int fd,void *buf,size_t nbyte)就是用Socket的read函数。栈向低位增长，堆向高位增长。其中的mmap映射区可以将文件内容映射到这片区域，由于Linux一切设备皆文件，所以I/O事件可以通过映射到mmap区来实现用户程序直接读取文件内容，而无需再调用系统函数，Java的MappedByteBuffer（DirectByteBuffer的父类）就是通过这种方式实现，同时用户程序调用的系统程序也是通过该区域来实现共享。mmap是零拷贝的一种实现方式，其核心思想是内核空间和用户空间共享；还有一种实现方式称之为sendfile，就是对数据传输流程的一种简化，传统socket数据的传输流程是：网络-&gt;socket(网卡)-&gt;内核空间读缓冲-&gt;应用程序内存-&gt;内核空间写缓冲-&gt;socket发送，这其中，socket到内核，或者内核到socket都需要进行一次DMA。所以传统模式进行了四次模式切换，sendfile就是将内核空间读缓冲的数据直接输出到内核空间写缓冲，减少两次模式切换。task_struct:包含vm_struct-保存了各个区域的内存起始和终止地址；还有类似进程号、打开的文件、创建的Socket以及CPU运行上下文等。线程是一个CPU调度单元，因此线程有自己的task_struct和运行栈区，但是其他资源都是和进程共享的。阻塞和唤醒工作方式：内核-进程运行队列，当任务为Task_Running状态进入该队列，由CPU调度（时间片轮转法）。进程运行队列：双向链表，task_struct-task_struct-task_struce调度：从进程队列中选择一个进程，再从CPU列表中选择一个可用CPU，将进程上下文恢复到CPU中，(用户态)执行上下文里的下一条指令；阻塞：从进程队列里移除线程，添加到等待队列，置为Task_Uninterruptible或者Task_Interruptible，重新触发一次调度；唤醒：添加到等待队列的同时，向内核注册一个回调函数。当数据到达（比如网卡）时，产生硬件中断，内核通过回调函数唤醒等待队列中的进程，添加到运行队列，置为Task_Running。这个过程中，CPU(内核态)还会将内核空间里的网络数据复制到堆中(Buffer)。Tomcat和Jetty中的对象池Tomcat:SynchronizedStack类实现，类中的Object[] 实现栈的功能，同步的push和pop方法来归还对象和获得对象；Jetty:ByteBufferPool，对象池，分配对象时从池里获得对象，原理：用不同的桶(bucket)管理不同bytebuffer，桶的内部用一个ConcurrentLinkDeque来放置ByteBuffer的引用。注意点：用完要归还；再次使用要重置；已经归还的对象不可以再做操作；对池操作要考虑阻塞、异常、返回Null值的处理。为什么要用对象池：http请求时间短，但是需要创建大量复杂对象并且创建对象的代价比较高（CPU负载高），或者限制部分资源的使用，比如连接池。Tomcat和Jetty的高效之道减少资源浪费；当某种资源称为瓶颈时，用其他资源来换取。处理原则：连接由专门的Acceptor来做；I/O事件侦测由Selector来做；协议解析交由线程池（Tomcat），或者交由Selector线程（Jetty）。减少系统调用channel带有缓冲区，尽量少地调用系统网卡的write，并且采用延迟解析，Tomcat只读取了request header，WEB应用程序才会读取到request body。高效并发缩小锁范围，例如synchronized关键字，对对象加锁，而不对方法加锁；用原子变量和CAS取代锁；合理使用并发容器-CopyOnWriteArrayList、ConcurrenHashMap等；用volatile修饰当前组件的生命状态。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Jetty</tag>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入Tomcat/Jetty(三)-连接器]]></title>
    <url>%2F%E6%B7%B1%E5%85%A5Tomcat-Jetty-%E8%BF%9E%E6%8E%A5%E5%99%A8.html</url>
    <content type="text"><![CDATA[Tomcat-NioEndpointJava I/O模型：一个进程的地址空间分为用户空间和内核空间，用户线程不能直接访问内核空间。同步阻塞I/O：用户线程发起read调用，然后阻塞让出CPU，接着内核等待网卡数据到来，把数据从网卡拷贝到内核空间，最后把数据拷贝到用户空间，把用户线程唤醒；同步非阻塞I/O：用户线程不断发起read调用，如果没有数据，内核就返回失败，直到数据到了内核空间。在等待数据从内核空间拷贝到用户空间这个时间里，线程还是阻塞的，等数据到了用户空间再把线程叫醒。I/O多路复用：首先：线程发起select调用，询问内核是否准备好，等准备好，用户线程再发起read调用；多路复用是指select可以向内核查多个数据通道（Channel）的状态。异步I/O：用户线程发起read调用的同时注册一个回调函数，内核将数据准备好后，再调用指定的回调函数完成处理。在这个过程中，用户线程一直阻没有塞。NioEndpoint实现了多路复用。包含组件：LimitLatch：限制连接数；Acceptor：监听连接请求，单独线程，死循环调用accept，返回Channel，交给Poller处理；Poller：监测Channel的I/O事件，创建SocketProcess任务类扔给线程池处理；Executor：Http11Processor处理请求，通过NioSocketWrapper读写数据。设计特点：LimitLatch：内部类Sync，Sync扩展了AQS，AQS内部维护了一个状态和线程队列，用来控制线程什么时候挂起，什么时候唤醒。sync类重写了AQS的tryAcquireShared()方法，如果连接数count小于limit，线程就可以获取锁，否则返回-1，同时还重写了releaseShared()方法。Accept：实现了Rnnable接口，可以跑在单独线程里。由于一个端口号对应一个ServerSocketChannel，所以这个ServerSocketChannel实在多个Accept线程之间共享的，它是Endpoint的属性，由Endpint完成初始化和端口绑定。123serverSock = ServerSocketChannel.open();serverSock.socket().bind(addr, getAcceptCount());serverSocket.configureBlock(true);bind()的第二个参数表示操作系统的等待队列，默认100；ServerSocketChannel设置称阻塞模式，通过accept()接受新的连接，并返回获得的SocketChannel对象，然后封装在一个PollerEvent对象中，并将该对象压入Poller的Queue中。Poller，本质是一个Selector，内部维护了一个Queueprivate final SynchornizedQueue&lt;PollerEvent&gt; = new SynchornizedQueue&lt;&gt;()；poller线程可以有多个同时运行，不断通过内部的Selector对象向内核查询Channel状态，一旦可读就生成任务类SocketProcessor交给Executor处理，并且还需要循环遍历自己所管理的SocketChannel是否已经超时，如果超时就关闭。SocketProcessor：任务类，交由线程池Executor处理；Excutor：执行SocketProcessor的run方法。Tomcat-Nio2EndPointNio2EndPoint实现了异步I/O。Java NIO.2 API创建服务端：1234567891011121314public class Nio2Server&#123; void listen()&#123; //1.ExecutorService ExecutorService es = Executors.newCachedThreadPool(); //2.ChannelGroup AsynchronousChannelGroup tg = AsychronousChannelGroup.with //3.Open Channel AsynchronousServerSocketChannel assc = AsynchronousServerSocketChannel.open(tg); //4.bind assc.bind(new InetSocketAddress("127.0.0.1", 8080)); //5.accept assc.accept(this,new AcceptHandler()); &#125;&#125;向内核注册回调函数，同时给内核提供一个线程池，内核只需要将工作交给线程池。NIO2和NIO的明显区别是：NIO2没有Poller组件，因为Selector的工作交给内核来做了。包含组件：LimitLatch：限制连接数；Acceptor：自己实现了CompletionHandler接口，自己就是回调类，所以自己调用自己serverSock.accept(null,this);Executor：Http11Processor处理请求，通过Nio2SocketWrapper读写数据。Nio2SocketWrapper主要作用是封装Cahnnel，并提供接口给Http11Processor读写数据。为了实现异步非阻塞I/O，Http11Processor通过两次read调用来完成数据读取操作，第一次read调用发生于连接刚刚建立，acceptor创建了SocketProcessor任务类交给线程池处理，http11Processor在处理过程中会调用Nio2SocketWrapper的read方法发出第一次请求，并且注册回调类readCompletionHandler，由于数据没读到，因此将Nio2SocketWrapper标记为不完整，然后SocketProcessor线程被回收，Http11Processor并没有阻塞等待数据，但是Http11Processor维护了一个Nio2SocketWrapper列表，也就是维护了连接状态；第二次read调用发生于内核把数据拷贝到Http11Processor指定的buffer里，回调类readCompletionHandler被调用，重新创建一个SocketProcessor来继续处理这个连接，这个新的sp持有原来的Nio2SocketWrapper。Tomcat-AprEndpointAPR是Apache Protable Runtime Libraries，基于C语言实现的可移植运行库，目的是向上层应用提供一个跨平台的操作系统接口库。ArpEndpoit通过JNI调用APR实现非阻塞I/O。包含的组件类似于NioEndpoint，但是采用DirectByteBuffer和sendfile来进行优化。Accept：监听连接，通过JNI调用APR里的socket、bind、listen、accept；Poller：通过JNI调用APR里的poll方法，APR调用操作系统的epoll API；Tomcat的endpoint组件在接收网络数据时需要预先分配好一块buffer，也就是数组byte[];在进行JNI调用时，将这个buffer地址传递给C代码，C代码把数据填充到这块buffer。HeapByteBuffer：ByteBuffer buf = ByteBuffer.allocate(1024),该类型buffer本质上还是开辟在JVM的堆内存中，内核将数据复制到本地临时内存，在从本地临时内存复制到JVM堆内存，如果直接从内核复制到JVM堆内存，JVM GC的时候由于对象移动而导致buffer失效，如果通过中转的方式，本地内存写入到JVM堆内存时，由于没有safepoint因此不会发生GC；DirectByteBuffer：ByteBuffer buf = ByteBuffer.allocateDirect(1024)该类型buffer是开辟在本地内存，JVM中只是持有该本地内存的虚引用，DirectByteBuffer在JVM的对象中有个long类型字段address，记录本地内存地址，这样内核将数据拷贝到本地内存地址后，JVM可以直接读取，省掉了一次拷贝过程。sendfile（系统API）：文件读取到内核缓冲区-&gt;数据位置+长度 的描述符添加到Socket缓冲区，内核将对应数据传递给网卡；传统传输文件的方式：文件读取到内核缓冲区-&gt;内核缓冲区放到本地临时内存-&gt;本地临时内存-&gt;JVM堆-&gt;本地临时内存-&gt;内核缓冲区-&gt;网卡Tomcat-ExecutorJava线程池1234567public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler)corePoolSize:核心线程数，如果提交任务时核心线程没满，则创建新线程来执行；workQueue:如果核心线程数满了，新增任务就放到workQueue里，线程池调用poll方法从workQueue里获取任务；maximumPoolSize:如果workQueue满了，则创建临时线程，当临时线程达到maximumPoolSize时，执行拒绝策略handler，比如抛出异常或者由调用者线程执行任务；临时线程使用poll(keepAliveTime,unit)方法从工作队列中拉取任务，如果达到超时时间依然没有获取到任务，则该线程会被回收。FixedThreadPool:固定长度(nThreads)的线程数组，它的workQueue是一个LinkedBlockingQueue无界队列；CachedThreadPool:maximumPoolSize大小为Integer.MAX_VALUE的线程池，无限创建临时线程，闲下来再回收，它的任务队列是SynchronousQueue，长度为0；Tomcat线程池关键点：线程个数；队列长度；重写execute方法；基本步骤和Tomcat的步骤类似，区别在于：到达maximumPoolSize后，继续尝试把任务添加到任务队列中去；如果缓冲队列也满了，则执行拒绝策略。其原理就是调用Java的Execute方法，然后捕捉其拒绝策略抛出的异常，再尝试将该任务放到任务队列，如果任务队列也满了，再执行拒绝策略。123456789101112131415161718192021222324public class ThreadPoolExecutor extends java.util.concurrent.ThreadPoolExecutor &#123; ... public void execute(Runnable command, long timeout, TimeUnit unit) &#123; submittedCount.incrementAndGet(); try &#123; // 调用 Java 原生线程池的 execute 去执行任务 super.execute(command); &#125; catch (RejectedExecutionException rx) &#123; // 如果总线程数达到 maximumPoolSize，Java 原生线程池执行拒绝策略 if (super.getQueue() instanceof TaskQueue) &#123; final TaskQueue queue = (TaskQueue)super.getQueue(); try &#123; // 继续尝试把任务放到任务队列中去 if (!queue.force(command, timeout, unit)) &#123; submittedCount.decrementAndGet(); // 如果缓冲队列也满了，插入失败，执行拒绝策略。 throw new RejectedExecutionException("..."); &#125; &#125; &#125; &#125;&#125;上面代码中，用submittedCount来维护已经提交到了线程池，但是还没有执行完的任务个数。原因：Tomcat定制版的任务队列TaskQueue扩展了LinkedBlockingQueue，默认情况下长度是长度无限的，除非给它一个capacity。这个参数一般情况下是maxQueueSize参数设置，但问题是默认情况下maxQueueSize值是Integer.MAX_VALUE，当前线程数达到核心线程数，再来任务直接就被添加到任务队列了，这样永远不会有机会创建新线程。所以定制版的TaskQueue重写了LinkedBlockingQueue的offer方法，在合适的时候返回false，表示添加失败，这样就可以返回新的线程。判断逻辑：线程数达到maxQueueSize了，直接添加进任务队列；已提交任务数小于当前线程，表示有空闲线程，无需创建新的；已提交任务数大于当前线程，线程不够用，新任务放进TaskQueue；所以，上面线程池代码中，执行时首先会对任务数首先加一，然后捕捉到异常时又减一。WebSocket请求头：Connection: Upgrade Upgrader: websocket Tomcat实现方式：WebSocket Endpoint，每一个WebSocket连接创建一个Endpoint实例，对应一个session。编程方式：继承javax.websocket.Endpoint，并实现onOpen、onClose和onError方法，每一个session会被作为endpoint各个生命周期事件的参数，通过在session中添加了MessageHandler消息处理器接收消息。注解@ServerEndpoint(value=&quot;/websocket/chat&quot;)在类上，然后类中方法加上@OnOpen,@OnClose,@OnMessage等注解。Tomcat工作方式：Web加载，通过SCI(ServletContainerInitializer，Servlet 3.0规范中定义)机制接收web 应用启动事件的接口。在实现了SCI接口的类上增加HandlerTypes({ServerEndpoint.class,ServerApplicaitonConfig.class,Endpoint.class})注解，这样Tomcat在启动阶段就会扫描出类出来，作为SCI的onStartup方法参数，并调用onStartup方法。所有扫描到的Endpoint子类和添加了@ServerEndpoint的类都会被放到WebSocketContainer容器中，并且维护了url和endpoint的映射关系。处理请求，使用UpgradeProcessor处理WebSocket请求。在WebSocket握手请求到来时，HttpProtocolHandler首先接收到这个请求，通过一个特殊的Filter判断是否具有Upgrader: websocket信息，如果有，就用UpgradeProtocolHandler替换原来的HttpProtocolHandler，并把当前Socket的Processor替换成UpgradeProcessor，由该Processor调用最终的Endpoint实例处理请求。Jetty-SelectorManagedSelector1234567891011121314151617181920212223242526public class ManagedSelector extends ContainerLifeCycle implements Dumpable&#123; // 原子变量，表明当前的 ManagedSelector 是否已经启动 private final AtomicBoolean _started = new AtomicBoolean(false); // 表明是否阻塞在 select 调用上 private boolean _selecting = false; // 管理器的引用，SelectorManager 管理若干 ManagedSelector 的生命周期 private final SelectorManager _selectorManager; //ManagedSelector 不止一个，为它们每人分配一个 id private final int _id; // 关键的执行策略，生产者和消费者是否在同一个线程处理由它决定 private final ExecutionStrategy _strategy; //Java 原生的 Selector private Selector _selector; //"Selector 更新任务 " 队列 private Deque&lt;SelectorUpdate&gt; _updates = new ArrayDeque&lt;&gt;(); private Deque&lt;SelectorUpdate&gt; _updateable = new ArrayDeque&lt;&gt;(); ...&#125;SelectorUpdate接口Jetty将Channel注册到Selector的事件抽象为SelectorUpdate接口，如果操作ManageSelector中的Selector，需要提交一个任务类，这个类需要实现接口的update方法，在方法里定义想要的操作。例如Connector中Endpoint组件对读就绪事件感兴趣，于是就向ManagedSelector提交了一个内部任务类ManagedSelector.SelectorUpdate，并在update方法里调用updateKey方法，这些update方法的调用者就是ManagedSelector自己，它在一个死循环里拉取这些SelectorUpdate任务类逐个执行。Selectable接口I/O事件到达时，通过这个接口返回一个Runnable，这个Runnable就是I/O事件就绪时的处理逻辑。12345678public interface Selectable&#123; // 当某一个 Channel 的 I/O 事件就绪后，ManagedSelector 会调用的回调函数 Runnable onSelected(); // 当所有事件处理完了之后 ManagedSelector 会调的回调函数，我们先忽略。 void updateKey();&#125;当Channel被选中时，ManagedSelector调用这个Channel所绑定的附件类的onSelected方法来拿到一个Runnable。例如，Endpoint组件在向ManagedSelector注册读就绪事件时，同时也要告诉ManagedSelector在事件就绪时执行什么任务，具体而言就是传入一个附件类，这个附件类需要实现Selectable接口。ExecutionStrategy123456789101112131415public interface ExecutionStrategy&#123; // 只在 HTTP2 中用到，简单起见，我们先忽略这个方法。 public void dispatch(); // 实现具体执行策略，任务生产出来后可能由当前线程执行，也可能由新线程来执行 public void produce(); // 任务的生产委托给 Producer 内部接口， public interface Producer &#123; // 生产一个 Runnable(任务) Runnable produce(); &#125;&#125;具体的策略实现类有四种：ProduceConsume：生产者自己依次生产和执行任务，也就是用一个线程来侦测和处理一个ManagedSelector上所有的I/O事件；ProduceExecuteConsume：生产者开启新线程来运行任务；ExecuteProduceConsume：生产者自己运行自己生产的任务，但是该策略可能会新建一个新线程继续生产和执行任务，能利用CPU缓存；EatWhatYouKill：对ExecuteProduceConsume策略的改良，如果线程不够或者系统繁忙，就会切换成ExecuteProduceConsume的策略，因为它使用的线程来源于Jetty全局线程池，一旦被阻塞的多了，会连I/O侦测都没有线程可用。Jetty的实现：SelectorProducer是ManagedSelector的内部类，ExecutionStrategy中的Producer接口中的produce方法，需要向ExecutionStrategy返回一个Runnable。这个方法里SelectorProducer主要干了三件事：如果Channel集合中有I/O事件就绪，就通过Selectable接口获取Runnable，直接返回给ExecutionStrategy去处理；如果没有，就看看有没有提交SelectorUpdate等事件注册；继续侦测select方法，侦测I/O事件。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Jetty</tag>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入Tomcat/Jetty(二)-基本架构]]></title>
    <url>%2F%E6%B7%B1%E5%85%A5Tomcat-Jetty-%E4%B8%A4%E7%A7%8D%E5%AE%B9%E5%99%A8%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84.html</url>
    <content type="text"><![CDATA[Tomcat系统架构连接器，将网络数据包装成Request以及将servlet返回的数据包装成Response；Servlet容器：加载、调用Servlet处理Request。连接器：ProtocolHandler组件+Adapter组件；ProtocolHandler组件：EndPoint，通信端点，包含Accept监听Socket连接请求，SocketProcess（实现runnable接口）处理Socket连接请求（Executor线程池）；Processor，读取网络数据字节包装成Request和Response，定义了请求的处理，即：EndPoint生成一个SocketProcessor，提交到线程池，SocketProcessor的Run方法调用Processor组件解析应用层协议，Processor生成Request对象后，会调用Adapter的Service方法。Adapter组件：适配器模式，将传进来的Request转成ServletRequest，然后执行Service方法。Servlet容器结构Engine：一个Tomcat最多只有一个；Host：每个站点对应一个；Context：每一个WEB程序都有一个；Wrapper：每一个Servlet有一个。对应的server.xml文件格式如下：123456789101112&lt;Server&gt; &lt;Service&gt; &lt;Connector&gt; &lt;/Connector&gt; &lt;Engine&gt; &lt;Host&gt; &lt;Context&gt; &lt;/Context&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt;树形结构，所以Tomcat采用组合模式来管理这些子容器，它们都共同实现了Container的接口，该接口还扩展了LifeCycle接口来进行生命周期的管理。通过Mapper组件来实现组件与访问路径的映射关系。调用过程通过Pipeline-Valve责任链来实现，其中Valve是节点的接口，Pipeline是组装链的接口。每一个子容器都有一个PipleLine对象，只要Adapter触发第一个Valve，整个链都会执行，而最后一个Valve又会调用下层子容器的Pipleline中的第一个Valve，并由Valve来invoke。Wrapper的最后Valve会创建一个FilterChain，并执行doFilter方法。生命周期LifeCycle接口定义了init，start，stop，destroy等方法，通过上层组件的状态变化触发子组件的状态变化，同时状态变化作为一种事件，通过观察者模式来监听到事件变化。LefeCycleBase抽象基类定义了一些通用逻辑，利用模板设计模式在基类中实现了生命状态的转变和维护，以及监听器的添加和删除等。Tomcat自定义了一些监听器在创建子组件的时候添加，同时用户还可以在server.xml中手动配置监听器。各个组件的职能（从上往下依此）：start.sh脚本，启动一个JVM进程来运行BootStrap；BootStrap，初始化Tomcat类加载器，并创建Catalina；Catalina，启动类，解析server.xml，创建相应组件，调用Server的start方法；Server，管理Service组件，调用Service的start方法；Service，管理连接器和顶层容器Engine。Jetty系统架构Connector:多个连接器，功能也是接收Socket收到的请求；Handler：多个处理器，处理请求；ThreadPool：分配线程资源给以上两个组件。和Tomcat的区别：没有Service；连接器是被所有Handler共享的，Tomcat是每一个Service都有一个Connector；ThreadPool资源是全局的，Tomcat中每一个连接器有自己的连接池。Accept:功能：接收请求，对应NIO中的channel；类型：ServerConnector内部类，实现了runnable；描述：通过阻塞的方式来接收连接，接收连接成功以后会调用accepted()函数。SelecetorManager：功能：选择具体的Selector来处理Channel；类型：具体类，内部保存了一个ManagedSelector数组；描述：调用Selector的register方法把Channel注册到Selector上，拿到一个SelectionKey，然后创建一个EndPoint和Connection，并跟这个SelectionKey绑定在一起，通过调用EndPoint获得一个具体执行任务的线程，交给线程池执行。Connection：功能：处理Channel；类型：EndPoint内部类，类似于Tomcat的Processor，解析协议包装成Request，并调用Handler；描述：HttpConnection是具体实现类，会向EndPoint注册一堆回调方法，模拟了异步IO的模型。Jetty总结：Accept接收请求，一个连接对应一个Channel，并交由SelecetorManager将Channel注册到Selector上，同时创建EndPoint和Connection绑定注册时产生的SelectionKey，然后获得线程执行，并调用Connection注册到EndPoint里的回调方法读取数据，Connection生成请求对象调用具体的Handler组件，我们可以通过自定义Handler实现功能的。Jetty核心设计-HandlerHandler是一个接口，有一个AbstractHandler，抽象类有两种子类，HandlerWrapper包含一个其他Handler的引用，HandlerCollection中有一个Handler数组的引用。Handler有三种类型：协调Handler：负责将请求路由到一组Handler中去，比如路由到HandlerCollection中；过滤Handler：自己处理请求，然后转发到下一个Handler，例如HandlerWrapper；内容Handler：真正调用Servlet处理请求，比如ServletHandler处理动态资源或者ResourceHandler处理静态资源请求。Jetty对Servlet规范的实现ServletHandler：实现了规范中的Servlet，Filter，Listener的功能，依赖FilterHolder、ServletHolder、ServletMapping、FilterMapping；SessionHandler：管理Session，同时包含SecurityHandler和GzipHandler；WebAppContext：本身是一个Context，管理ServletHandler和SessionHandler。总结组件化和可配置：利用面向接口编程的思想，实现组件的扩展；并设计成链，在一起链式调用；启动过程中动态创建组件对象实例（反射）；父组件负责子组件的创建、启停、销毁；并且将容器的生命周期状态转变定义成一个事件，组件的状态变化触发另一个组件的启动或停止（这些称之为触发点或者扩展点，Spring框架就射这么设计的）。spring生命周期：反射实例化Bean和注入属性值；如果有实现了Aware接口，执行相应的Aware注入：BeanNameAware，BeanFactoryAware，ApplicationContextAware等；调用BeanPostProcessor的postProcessBeforeInitialization()方法；调用InitializingBean的实现类中的afterPropertiesSet()方法；执行init-method定义的方法或者@PostContruct注解的方法；调用BeanPostProcessor的postProcessBeforeInitialization()方法；销毁bean时执行，如果该bean实现了DisposableBean接口，则执行destroy()方法；执行destroy-method定义的方法或者@PreDestroy注解的方法。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Jetty</tag>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入Tomcat/Jetty(一)-servlet容器简介]]></title>
    <url>%2F%E6%B7%B1%E5%85%A5Tomcat-Jetty-%E5%AE%B9%E5%99%A8%E7%AE%80%E4%BB%8B.html</url>
    <content type="text"><![CDATA[学习路径概念和基础Tomcat或者Jetty：”HTTP服务器+Servlet容器”，又称为WEB容器，本文基于Tomcat 9。操作系统：《UNIX环境高级编程》Java基础：面向对象设计概念，集合，I/O体系，多线程并发，网络模型（NIO，BIO，AIO），注解和反射WEB基础：Spring框架开发经验。Http协议基础HTTP本质：浏览器和服务器之间通信的内容格式，属于应用层协议;http请求的组成：请求行请求头请求体数据在网络中传输都是通过字节流，即8位二进制，tomcat能够把字节流转成Request对象，该对象封装了HTTP所有的请求信息，经过程序处理后又得到一个Response对象。http响应的组成：状态行响应头响应体cookie和session技术：为了弥补HTTP协议无状态的特性而产生的技术，每次浏览器和服务器建立连接时都会产生一个session，并在Cookie中填充了sessionID用来标请求的身份。Tomcat后台会有线程定时轮询session，删除过期session。在HTTP 1.1中引入了长连接，会在响应头中加入Connection:keep-alive，这样会使得每一次建立的TCP连接可以被HTTP请求复用。servlet规范和servlet容器servlet实质上是一个Java中的接口。servlet规范=servlet接口+servlet容器。servlet接口：123456789public interface Servlet &#123; //加载某个servlet的时候会调用该servlet实现类的init方法 public void init(ServletConfig config) throws ServletException; //web.xml中配置的参数 public ServletConfig getServletConfig(); public void service(ServletRequest req, ServletResponse res) throws ServletException, IOException; public String getServletInfo(); public void destroy();&#125;service用于调用业务，其中的ServletRequest和ServletResponse就是对通信协议的封装。ServletContext：每一个WEB应用都会有一个ServletContext。WEB应用标准结构：| - MyWebApp | - WEB-INF/web.xml --配置ServletConfig信息 | - WEB-INF/classes --servlet编译输出目录 | - WEB-INF/lib --web依赖的jar包存放 | - META-INF/ --工程清单信息 Filter：web应用部署完成以后，会实例化所有Filter并组装成一个FilterChain；Listener：当Servlet容器内发生某些指定事件时，Servlet容器会调用指定方法，比如Servlet容器启动时会触发Spring的ServletContext的监听器，使得Spring容器被创建并初始化。Spring MVC中，第一个请求进入到DispatcherServlet时，如果该类还未实例化，就会调用该类的init方法，创建Spring MVC容器，创建过程中还可以通过ServletContext拿到Spring的Ioc容器，并将Spring 容器设置为自己的父容器，Spring MVC能够访问Spring容器里的Bean，但是反过来是不行的。Tomcat日志catalina.***.log：启动过程信息，包括JVM参数以及操作系统信息；catalina.out：标准输出和标准错误；localhost.**.log：初始化过程中遇到的未处理异常；localhsot_access_log.**.txt：请求日志，包含IP地址、路径、时间、协议以及状态码等信息；manager.***.log/host-manager.***.log：自带的manager项目的日志信息。源码学习方法经典开源框架和中间件：服务接入层：Nginx、Node.js；业务逻辑层：Tomcat、Jetty、Spring家族、Mybatis；数据缓存层：Redis、Kafka；数据存储层：Mysql、MondoDB、文件存储HDFS、搜索分析引擎ES。通过问题找到解决办法。网络通信要考虑的问题：IO模型，同步还是异步，阻塞还是非阻塞；通信协议，二进制（gRPC）还是文本（HTTP）；序列化方式，JSON还是Protocol Buffer。服务端处理网络连接的过程：accept-select-read-decode-process-encode-send对应角色和职责：Acceptor-acceptSelector-selectProcessor-read，decode，process，encode，send组件：netty: 通过EventLoop将Selector和Processor跑在同一个线程，充分利用CPU缓存来侦测I/O事件和读写数据，同时可以设置业务处理和I/O处理的事件比率，超过这个比率就会将任务扔到专门的线程池来执行，Jetty的EatWhatYouKill线程也与之类似；kafka：Selector和Processor跑在不同的线程里，因为kafka的业务逻辑大多涉及与磁盘读写，处理时间不确定，这一点Tomcat与之类似；学习Tomcat源码的过程：弄清楚中间件的核心功能是什么，比如Tomcat，核心功能是Http服务器和Servlet容器，怎么连接，怎么读取，怎么解析，怎么调用servlet，怎么处理业务等；核心架构，核心骨架类：Server；Service；连接器：流程Acceptor-&gt;SocketProcessor-&gt;Executor-&gt;Processor-&gt;Adapter，其中顶层为Connector，包含ProtocolHandler和Adapter，ProtocolHandler又包括EndPoint和Executor、Processor，而EndPoint包含了Acceptor和SocketProcessor；容器： Engine-&gt;Host-&gt;Context-&gt;Wrapper(Servlet)。实战优化Tomcat启动速度删除webapps文件夹下不需要的工程；server.xml文件尽量简洁；清理不需要的jar文件，对于servlet-api等的jar包，通常tomcat都已经提供，如果项目里需要，引入该jar包时将其作用域调整为provided；清理logs文件夹下不需要的日志文件，还有work下的Catalina，这个文件夹是Tomcat把jsp转换为class文件的工作目录；禁止TomcatTLD扫描，如果项目中没有用到jsp，或者不需要TLD，可以配置为禁止。At least on jar was scanned for TLDs yet contained no TLDs.Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs这种提示也表明tomcat推荐禁止TLD扫描。对于没有使用jsp的项目，可以直接禁止TLD扫描：在tomcat的conf/context.xml文件中，加如下配置：12345&lt;Context&gt; &lt;JarScanner&gt; &lt;JarScanFilter defaultIdScan="false"/&gt; &lt;/JarScanner&gt;&lt;/Context&gt;如果使用了Jsp，那么TLD扫描无法避免，但是可以在tomcat目录下的conf/catalina.properties里配置tomcat指定扫描的Jar：1tomcat.util.scan.StandardJarScanFilter.jarsToSkip=xx.jar不需要websocket时关闭websocket支持，或者直接删除tomcat lib下的websocket-api.jar和tomcat-websocket.jar；12&lt;Context containerSciFilter="org.apache.tomcat.websocket.server.WsSci"&gt;&lt;/Context&gt;不需要jsp时，关闭jsp功能；12&lt;Context containerSciFilter="org.apache.jasper.servlet.JasperInitializer"&gt;&lt;/Context&gt;如果没有用到注解式servlet，可以在web应用的web.xml文件中，设置&lt;web-app metadata-complete=&quot;true&quot;&gt;告诉tomcat web.xml中配置的servlet时完整的，不需要再去jar包中扫描servlet；关闭web-fragment扫描；servlet 3.0引入了web-fragment.xml，这是一个部署描述文件，可以完成web.xml的配置功能，这个文件必须放置在jar的META-INF目录下，所以tomcat需要扫描所有jar包来扫描该文件，可以通过在项目里的web.xml加入&lt;web-app&gt; ...&lt;absolute-ordering /&gt; ... &lt;/web-app&gt;让它不扫描;随机数熵源优化，tomcat 7以上的版本依赖Java的SecureRandom类来生成随机数，比如Session ID，而Jvm默认使用阻塞式熵源（/dev/random），容易导致启动速度变慢，可以设置Jvm参数-Djava.security.egd=file:/dev/urandom;允许并行启动多个web应用，因为默认情况下tomcat是一个一个启动程序的，可以配置conf/server.xml并行启动：12345&lt;Engine startStopThreads="0"&gt; &lt;Host startStopThreads="0"&gt; ... &lt;/Host&gt;&lt;/Engine&gt;]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Jetty</tag>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK-入门搭建和使用]]></title>
    <url>%2FELK-%E5%85%A5%E9%97%A8%E6%90%AD%E5%BB%BA%E5%92%8C%E4%BD%BF%E7%94%A8.html</url>
    <content type="text"><![CDATA[简述ELK是现在流行的数据采集、监控、分析系统，其本质是由三个开源组件ElasticSearch+Logstash+Kibana组成，常用于系统监控，日志分析等场景。ElasticSearch:基于Json的分布式分析和搜索引擎，水平扩展，高可靠性，管理便捷，后面简称ES。LogStash:动态数据收集管道，拥有可扩展的插件系统，强大的与ES的协同功能。Kibana:以图表的形式呈现数据，具有可扩展的用户界面管理和配置Elastic Stack。由于logstash比较重量级，所以有时候也会直接通过Beats输入到ES，但是更多的是beats+logstash的结合使用，即ES和Logstash放在同一台机器，用logstash做文本格式化，用轻量级的beat在端点采集日志传输到logstash。环境简述Linux Centos 7.2ElasticSearch 7.1.1Logstash 7.1.1FileBeat 7.1.1Kibina 7.1.1日志文件类型：Java WEB：格式如下：12345672019-04-02 08:47:40.067 [http-bio-9081-exec-4] DEBUG org.mybatis.spring.SqlSessionUtils [287]- Transaction synchronization deregistering SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@5ce37a0d]2019-04-02 08:47:40.067 [http-bio-9081-exec-4] DEBUG org.mybatis.spring.SqlSessionUtils [292]- Transaction synchronization closing SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@5ce37a0d]2019-04-02 08:47:40.070 [http-bio-9081-exec-4] DEBUG druid.sql.Connection [129]- &#123;conn-10008&#125; commited2019-04-02 08:47:40.070 [http-bio-9081-exec-4] DEBUG druid.sql.Connection [129]- &#123;conn-10008&#125; setAutoCommit true2019-04-02 08:47:40.071 [http-bio-9081-exec-4] DEBUG druid.sql.Connection [129]- &#123;conn-10008&#125; pool-recycle2019-04-02 08:47:43.034 [http-bio-9081-exec-10] INFO c.a.ykp.filter.RedisSessionFilter [47]- RequestURI-----&gt;/fp/list.do2019-04-02 08:47:43.047 [http-bio-9081-exec-10] INFO c.a.ykp.service.impl.BaseServiceImpl [188]- 接口编码为ECREST.DDLB.CX.E_INV的请求信息为&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&#123;"NSRSBH":"140301201811057","FJH":"0","KPLX":"","DDSJQ":"","DDSJZ":"","GHFMC":"","GHF_EMAIL":"","GHF_SJ":"","FPKJ_ZT":"","PAGE_START":"0","PAGE_COUNT":"10","CZLX":"0","FPZL_DM":""&#125;APP：格式如下：123456789101112131415161718192021222324252644 20190614 184715 0 07 ------ 1019MakeInvCrypt ret= 045 20190614 184715 0 07 ------ 1019 MakeInv_Proc_2 结束46 20190614 184715 0 07 ------ 101947 20190614 184715 0 07 ------ c1400171320V1B13.00H12782637V0.03,100.00,3.00;20190614 18:47:16购货方名称140301000000000购方地址、邮编661850000021*园艺产品*石头￠§hwq14184713752IqiCUU@PTZCCS011C180企业三十110101000000030杏石口路甲18号1# 020-28381999---1111111111111111111111111111--1开票人复核人收款人wLbGsbXEt6LGsbG416I=100.003.00N*园艺产品*石头某硬件打印日志：1234567963 2019-07-03 05:47:21 2A 0 超时触发964 2019-07-03 05:47:21 2A 0 夜间空闲，开始自动扫描965 2019-07-03 05:47:21 2A 0 scan_flag的值，0夜间自动 -1，业务错误，不会执行扫描，1，2手动触发966 2019-07-03 05:47:21 2A 0 启动中触发自动扫描，不进行批量扫描 scan_flag == 0 &amp;&amp; scanStartFlg == 1967 20190703 055128 0 31 ------ DDZQ2019-07-03 05:51:28 172968 20190703 055128 0 31 ------ interfaceCodeECXML.DDZQ.BC.E_INV.V2969 20190703 055128 0 31 ------ m_WSAddrhttp://192.168.15.107:18082/51ykp/eInvoice安装ES详情请参考原来我写的一篇Skywaking的文章：skywalking基础实践。安装LogStash启动前配置需要注意的配置项：ElasticSearch的配置文件config/elasticsearch.yml的network.host如果没有配置为”0.0.0.0”，那么就只能允许指定的IP访问，所以要保证logstash的配置文件里的IP为es指定的IP。192.168.29.30上的ES配置的network.host为192.168.29.30，所以这里修改的logstash配置文件config/logstash-sample.conf为：1234567output &#123; elasticsearch &#123; hosts =&gt; [&quot;http://192.168.29.30:9200&quot;] index =&gt; &quot;%&#123;type&#125;-%&#123;+YYYY.MM.dd&#125;&quot; #user =&gt; &quot;elastic&quot; #password =&gt; &quot;changeme&quot; &#125;如果es配置了用户名和密码，那么也要进行对应的配置。启动方式启动脚本：进入到logstash所在目录cd /elk/logstash-7.1.1;启动方式（保证当前用户具有该目录下的可执行权限）：nohup ./bin/logstash -f config/logstash-sample.conf &gt;/dev/null 2&gt;&amp;1 &amp;;查看日志tail -f logs/logstash-plain.log，如果提示[2019-06-19T16:38:00,235][INFO ][org.logstash.beats.Server] Starting server on port: 5044 [2019-06-19T16:38:00,386][INFO ][filewatch.observingtail ] START, creating Discoverer, Watch with file and sincedb collections [2019-06-19T16:38:00,769][INFO ][logstash.agent ] Successfully started Logstash API endpoint {:port=&gt;9600} 即代表启动成功。完整配置说明配置文件主要由三大部分组成，input可以配置数据来源：type：自定义，这里我配置为项目的名称；path：指定了收集的日志所在目录；codec：是一项通用配置，不光可以用于file input，其中：charset：指定了读取的文件的编码格式，如果不配置charset，默认是UTF-8，pattern：匹配该正则的日志会被收集，可以使用grok表达式；negate：当日志不匹配时是否转置正则；what：把当前行追加到前一行后面，直到新进行匹配pattern;start_position指定了日志的读取起始位置；add_field：添加新成员到收集的数据中，即在收集过来的json中添加123&quot;fields&quot;: &#123; &quot;app_id&quot;: &quot;app-to51&quot; &#125;filter配置数据的格式：根据自定义的成员fields里的app_id的值，判断来源于哪一个系统，根据不同系统日志的格式，使用grok表达式进行格式化输出，收集过来的日志数据都放在message中，所以这里格式化message：例如：从web收集过来的日志如下： 2019-06-20 10:15:51.389 [http-bio-9081-exec-5-110101100000031-gxSplb262] INFO c.a.ykp.service.impl.BaseServiceImpl [188]- 接口编码为ECREST.SPXXTB.CX.E_INV的请求信息为iNSRSBH\&quot;:\&quot;110101100000031\&quot;,\&quot;USER_ID\&quot;:\&quot;12677\&quot;,\&quot;ZHGXSJ\&quot;:\&quot;2019-06-19 17:32:45\&quot;} grok规则如下： match =&gt; {&quot;message&quot; =&gt; &quot;%{TIMESTAMP_ISO8601:51web-date}%{SPACE}\[%{DATA}\]%{SPACE}%{WORD:51web-level}%{SPACE}%{DATA:51web-class}%{SPACE}\[\d+\]-%{SPACE}%{DATA:51web-desc}&gt;+(?&lt;web-data&gt;.*)&quot;} 那么输出后存放到es中的json就会添加对应的字段，类似下面： { ... &quot;web-data&quot;: &quot;{\&quot;NSRSBH\&quot;:\&quot;911403016NLWYA33EE\&quot;,\&quot;FJH\&quot;:\&quot;0\&quot;,\&quot;KPLX\&quot;:\&quot;\&quot;,\&quot;DDSJQ\&quot;:\&quot;\&quot;,\&quot;DDSJZ\&quot;:\&quot;\&quot;,\&quot;GHFMC\&quot;:\&quot;\&quot;,\&quot;GHF_EMAIL\&quot;:\&quot;\&quot;,\&quot;GHF_SJ\&quot;:\&quot;\&quot;,\&quot;FPKJ_ZT\&quot;:\&quot;\&quot;,\&quot;PAGE_START\&quot;:\&quot;0\&quot;,\&quot;PAGE_COUNT\&quot;:\&quot;10\&quot;,\&quot;CZLX\&quot;:\&quot;0\&quot;,\&quot;FPZL_DM\&quot;:\&quot;\&quot;,\&quot;DDSJBZ\&quot;:\&quot;0\&quot;}&quot;, &quot;51web-level&quot;: &quot;INFO&quot;, &quot;51web-date&quot;: &quot;2019-06-21 11:39:06.382&quot;, &quot;51web-class&quot;: &quot;c.a.ykp.service.impl.BaseServiceImpl&quot;, &quot;51web-desc&quot;: &quot;接口编码为ECREST.DDLB.CX.E_INV的请求信息为&quot;, ... } output配置了输出目的，这里配置输出到ES，还可以配置输出到控制台，方便调试。input { beats { port =&gt; 5044 } file { type =&gt; &quot;app-to51&quot; path =&gt; [&quot;/elk/app/*&quot;,&quot;/elk/to51/*&quot;] codec =&gt; multiline { charset =&gt; &quot;GBK&quot; pattern =&gt; ^(\d+)(\s|\t)+(\d{4}-?\d{2}-?\d{2})(.|\n)* negate =&gt; true what =&gt; &quot;previous&quot; } start_position =&gt; &quot;beginning&quot; add_field =&gt; { &quot;[fields][app_id]&quot; =&gt; &quot;app-to51&quot; } } } filter { if [fields][app_id] == &quot;51-web&quot;{ grok{ match =&gt; {&quot;message&quot; =&gt; &quot;%{TIMESTAMP_ISO8601:51web-date}%{SPACE}\[%{DATA}\]%{SPACE}%{WORD:51web-level}%{SPACE}%{DATA:51web-class}%{SPACE}\[\d+\]-%{SPACE}%{DATA:51web-desc}&gt;+(?&lt;web-data&gt;.*)&quot;} remove_field =&gt; {&quot;message&quot;} } }else if [fields][app_id] == &quot;app-to51&quot;{ grok { match =&gt; {&quot;message&quot; =&gt; &quot;\d+%{SPACE}(?&lt;app-to51.date&gt;\d{4}-?\d{2}-?\d{2}%{SPACE}\d{2}:?\d{2}:?\d{2})%{SPACE}(?&lt;app-to51.action&gt;\w+)%{SPACE}(?&lt;app-to51.code&gt;\d+)%{SPACE}(?&lt;app-to51.message&gt;(.|\n|\t)*)&quot;} remove_field =&gt; [&quot;message&quot;] } } } 为了方便启动，我在logstash目录下编写了一个start.sh脚本，方便启动，stop.sh脚本方便关闭。grok表达式grok表达式内置了一些变量，这些变量能直接引用作为正则表达式，logstash启动的时候会将这些变量替换为正则，详情参考https://github.com/logstash-plugins/logstash-patterns-core/blob/master/patterns/grok-patterns：语法一： %{TIMESTAMP_ISO8601:51web-date} 符合TIMESTAMP_ISO8601格式的日志文本会作为字段51web-date的内容输出到es里，TIMESTAMP_ISO8601就是grok预置变量； 语法二： (?&lt;app-to51.date&gt;\d{4}-?\d{2}-?\d{2}%{SPACE}\d{2}:?\d{2}:?\d{2}) 这句的含义就是形式20190621 171600或者2019-06-21 17：16：00的文本作为app-to51.date字段的内容输出到es里。 grok是基于正则表达式，所以也可以直接用正则表达式来匹配从而输出自定义字段内容，语法为(?&lt;自定义字段名&gt;正则表达式)。 filebeat配置配置文件为filebeat目录下的filebeat.yml，yaml配置的配置名称和值中间有一个空格。inputs配置- type：log：filebeat会按行读取log类型的文件；enable：true：启用该配置；path: - /home/tomcat9080/logs/catalina.out：收集的日志目录，可以使用*进行模糊匹配，也可以配置多个路径；document_type：写入es的文档类型；tags：标签，可以无需配置；include_lines：正则，采集匹配该正则的日志；multiline.pattern：多行日志的日志起始标志；multiline.negate：改为true，启用转置multiline.pattern（具体作用不明确）；multiline.match：改为after，表示合并起始行后面的行；fields.app_id：自定义的字段，会在发送到logstash的json数据中添加：123&quot;fields&quot;: &#123; &quot;app_id&quot;: &quot;app-to51&quot; &#125;output配置由于没有将filebeat直接输出到es所以这里将所有Elasticsearch output的配置全部注释掉;只需要Logstash output：#----------------------------- Logstash output -------------------------------- output.logstash: # The Logstash hosts hosts: [&quot;192.168.29.30:5044&quot;] 启动进入到filebeat目录下执行以下命令：nohup ./filebeat &gt;/dev/null 2&gt;&amp;1 &amp;为了方便启动，我在filebeat目录下编写了一个start.sh脚本，方便启动，stop.sh脚本方便关闭。]]></content>
      <categories>
        <category>编程技术</category>
      </categories>
      <tags>
        <tag>ELK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构和算法-散列表和哈希算法]]></title>
    <url>%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95-%E6%95%A3%E5%88%97%E8%A1%A8%E5%92%8C%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95.html</url>
    <content type="text"><![CDATA[简述散列表：利用数组支持按下标访问数据的特性扩展出的一种数据结构；哈希算法：将任意长度的二进制值串映射为固定长度的二进制值串的一种算法。散列表散列思想：即哈希算法的思想原理；散列函数：计算得出的散列值是一个非负整数；两个相等key得出的散列值必然相等；两个不相等key得出的散列值必然不相等。实际上，第三个条件几乎没有任何算法能够满足。散列冲突：两个不相等key得出同一个散列值。散列冲突的解决方案：开放寻址法：如果出现散列冲突，就重新探测新的位置，即从冲突的位置往后找一步步，找到空闲位置就插入，没找到则从头开始找（线性探测）；或者是往后1的平方，2的平方步找（二次探测）；又或者是对冲突的散列值再进行一次散列（二次散列）；不过不管用什么方法，如果散列表中空闲位置不多的话，散列冲突的概率还是很高，为了尽可能保证散列表的操作效率，一般情况下都会尽可能保证三列表中有一定比例的空闲槽位，用装载因子表示空位的多少，计算公式是：load factor = 表中元素个数/散列表总长度，装载因子越大，空位越少，散列表性能越低。链表法：在冲突的槽位上有一个链表，冲突的即放到相同槽位的链表中，其删除和查找的时间复杂度都是O(n)，只和链表长度成正比。Word文档的单词提示就可以借助散列表来实现：常用的英文单词大概在20万个左右，假设单词平均长度为10个字母，平均一个单词占用10个字节的内存空间，那么20万个英文单词大概占用2MB空间，完全可以利用散列表的形式存储在内存中，当用户输入单词时，通过散列函数生成散列值然后去散列表中查找，能够找到即表示拼写可能正确；找不到即提示错误。散列函数设计原则：不能太复杂，否则影响执行效率；散列值要随机，并且均匀分布。散列表设计原则：合理的默认初始大小，比如Java中HashMap为16；合理的装载因子和扩容方案，比如HashMap的0.75和扩容为两倍；散列冲突解决方案，采用线性探测的开放寻址法适合数据量小，装载因子小的时候，比如ThreadLocalMap；采用链表法适合存储大对象，大数据量的散列表，并且有更多的优化策略，比如JDK8的HashMap中链表长度大于8时，链表转换为红黑树，小于8时变成链表。哈希算法的应用安全加密MD5信息摘要算法、SHA安全散列算法、DES数据加密标准、AES高级加密标准；唯一标识对要上传大量图片时，会对每张图片的二进制码提取部分进行散列，或者对图片的全部二进制码进行散列，作为图片的唯一标识或者图片文件名称，并放入散列表，下次需要查找时，就可以在散列表中快速找到。数据校验经常下载Windows镜像文件的都会在下载完成以后进行校验，如果文件不完整，那么生成的散列值肯定和完整的散列值不一致。负载均衡负载均衡算法有很多，比如轮询、随机、加权轮询等。会话粘滞（session sticky）的负载均衡算法就是在同一客户端上的会话请求都路由放到同一个服务器上。对客户端IP地址或者会话ID计算哈希值，对取得的哈希值与服务器列表的大小进行取模运算，最终得到的值就是应该被路由到的服务器编号。数据分片统计关键词出现次数假如有1T的日志文件，里面记录了用户的搜索关键词，先依次读出所有关键词，并且通过哈希函数计算哈希值，然后跟机器数n进行取模，最终得到的值就是应该被分配到的机器编号。快速判断图片是否在图库中1亿张图片，n台机器处理，让每台机器只维护某一部分图片对应的散列表，我们每次从图库中读取一个图片，计算唯一标识，然后与机器个数求余取模，得到的值就对应要分配的机器编号，然后将这个图片的唯一标识和图片路径发往对应的机器构建散列表。分布式存储海量的数据肯定需要存储，一个机器往往不够，所以用哈希算法提取哈希值，然后对机器个数取模，获得的值就是对应机器编号，扩容时，由于机器数增加，因此原来的哈希算法算出来的哈希值就不对了，这里一致性哈希算法就登场了。一致性哈希算法：假设有k台机器，数据的哈希值范围时[0,max]，我们将整个范围划分为m个小区间，m远大于k，每个机器负责m/k个小区间，当有新机器加入的时候，我们将某几个小区间的数据，从原来的机器中搬移到新机器中。]]></content>
      <categories>
        <category>数据结构/算法</category>
      </categories>
      <tags>
        <tag>数据结构/算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySql-join实战]]></title>
    <url>%2FMySql-join%E5%AE%9E%E6%88%98.html</url>
    <content type="text"><![CDATA[简述Join语句在Mysql多表联查的使用中非常广泛，通常来说，开发人员的意识中都会觉得Join的查询效率比子查询要高，但是如果滥用时，Join的效率并不如人意。Index Nested-Loop Join首先看一个sql语句：1select * from t1 straight_join t2 on t1.id = t2.id这里直接使用straight_join指定t1作为驱动表，t2作为被驱动表。执行流程：从t1中读入一行数据R；从R中取出a字段去t2表中查找；取出t2中满足条件的行，跟R组成一行，作为结果集的一部分；重复执行1~3，直到表t1的末尾循环结束。在这个流程里：扫描t1时候时全表扫描n；a字段去t2表中搜索走的树搜索m，总的扫描行数时n+m；如果将join改成单表查询：12select * from t1;select * from t2 where a=$R.a查出t1所有数据n；循环遍历n行数据；从每一行取出a，到t2中去查；把返回的结果和R构成结果集的一行。扫描行数也是m+n，但是客户端要多发100条语句，同时自己拼接语句和结果。可以看到在INL中，驱动表都是全表扫描n；被驱动表需要先扫描索引a（假如用到了索引），再搜索主键索引，每一个索引树所花费的时间都是log₂M，所以总的是log₂M*2*N+N，可以看出N对于时间复杂度的影响要更大。Simple Nested-Loop Join1select * from t1 straight_join t2 on (t1.a=t2.b)由于t2的字段b上没有索引，所以不会再走树搜索，而是会全表扫描并且每一都需要做判断，次数为m*n，这样效率就会很低，也就是SNLJ算法。Block Nested-Loop Join如果被驱动表t2的条件字段没有索引，那么流程就成了：t1的数据读入线程内存join_buffer中，由于这里是select * ，因此整个t1放入了内存；扫描t2，把表t2中每一行取出来，跟join_buffer中数据做对比，满足join条件的，作为结果集的一部分返回。由于会对t1和t2都做一次全表扫描，因此总的扫描行数是m+n，对于表t2中的每一行，都需要与t1中的每一行做一次判断，因此总的是m*n次判断，但是由于是内存的join_buffer里的判断，所以速度很快，性能很好。join_buffer的大小是由参数join_buffer_size设定的，默认是256k，如果放不下表t1的所有数据就会采取分段放的策略，这样执行过程就变成了：扫描表t1，顺序读取数据行仿佛join_buffer中，放完某一行join_buffer满了，执行第2步；扫描表t2，把t2中的每一行取出来，跟join_buffer中数据对比，满足join条件的，作为结果集的一部分返回；清空join_buffer；继续扫描表t1，读取第一步该行后面的行放入到join_buffer中，继续执行第2步。假设驱动表的数据行数是N，需要分K段才能完成算法流程，被驱动表的数据行数是M；N越大，需要分的段数K就越大，所以这里把K表示为u*N,那么在这个过程中：扫描行数是N+u*N*M；内存判断N*M次。结论是：N对时间的影响更大，所以N小一些更好，即驱动表小一些更好。对于小表的定义：12select * from t1 straight_join t2 on (t1.b=t2.b) where t2.id&lt;=50;select * from t2 straight_join t1 on (t1.b=t2.b) where t2.id&lt;=50;第一个语句是t1作为驱动表，但是条件里是t2.id，所以第一个语句t2是小表；12select t1.b,t2.* from t1 straight_join t2 on (t1.b=t2.b) where t2.id&lt;=100;select t1.b,t2.* from t2 straight_join t1 on (t1.b=t2.b) where t2.id&lt;=100;t2表数据和t1表数据相差不多的情况下，由于t1只查一个字段，而t2需要查所有字段，所以第一个语句使用t2做驱动表时，需要放入join_buffer_size的字段就越多，那么能够放入的数据就越少，所以t1是小表2。准确说：决定驱动表的时候，应该是按照两个表各自的条件过滤，过滤完成以后，计算参与join的各字段的总数据量，数据量小的表，就是“小表”。join优化Muti-Range Read在查询的时候经常会回表，而回表需要首先在普通索引上找到主键，然后根据主键索引一条条查询整行数据，MRR优化就是将需要查询的数据的id顺序排列然后依次查询，这样对磁盘的读就变成了顺序读，提升读性能。如果想要稳定地使用read_rnd_buffer_size，根据官方文档，需要设置optimizer_switch=&quot;mrr_cost_based=off&quot;流程：根据普通索引，找到id，放入到read_rnd_buffer中；将read_rnd_buffer中的id进行递增排序；排序以后到主键索引中依次查找记录，并作为结果返回。Batched Key Access对NLJ的一种优化：join_buffer在NLJ中没有用上，所以5.6引入这个优化算法，用上了join_buffer，将驱动表里的数据尽可能多地取出放到join_buffer中，原来地NLJ是一行一行读取。首先需要开启一个设置:set optimizer_switch=&#39;mrr=on,mrr_cost_based=off,batched_key_access=on&#39;;BAK算法依赖于MRR。总结能够使用索引时，可以使用join；使用join尽量用小表做驱动表；不能使用被驱动表索引的语句尽量不要用。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>MySql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构和算法-二分查找和跳表]]></title>
    <url>%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95-%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE%E5%92%8C%E8%B7%B3%E8%A1%A8.html</url>
    <content type="text"><![CDATA[简述二分查找（Binary Search）是一种针对有序数据集合的查找算法。跳表（Skip List）是一种优秀的动态数据结构，支持快速的插入、删除、查找操作。二分查找（Binary Search）原理：通过每次跟区间的中间元素对比，将待查找的区间缩小为之前的一半，直到找到待查找元素，或者区间被缩小为0。时间复杂度：O(logn)。最简单的二分：123456789101112131415161718192021222324252627//二分查找的普通实现(简单版)public int bsearch(int[] a, int n, int value)&#123; int low = 0; int high = n - 1; while(low &lt;= high)&#123; int mid = (low + high) /2; if(a[mid] == value)&#123; return mid; &#125; else if(a[mid] &lt; value)&#123; low = mid + 1; &#125; else &#123; high = mid -1; &#125; &#125; return -1;&#125;//二分查找的递归实现public int bsearch(int[] a, int high,int low, int value)&#123; if(low &gt; high) return -1; int mid = low + ((high - low) &gt;&gt; 1); if(a[mid] == value) return mid; else if(a[mid] &lt; value) bsearch(a,high,mid + 1,value); else bsearch(a,high - 1,mid,value);&#125;要点：循环退出条件，是low &lt;= high，而不是low &lt; high;mid的取值通常为(low+high)/2，但是可以写为low+(high-low)/2，为了提高效率，除以2可以写为右移一位，即low+((high-low)&gt;&gt;1);low和high的下标要常更新。局限性：依赖顺序表结构；数据必须是有序的；数据量很小时时间和顺序遍历差别不大；数据量太大时数组连续内存可能不够。变种1：查找第一个值等于给定值的元素（提示：判断下标是否等于0，或者某下标的前一节点是否等于给定值）。参考代码：12345678910111213141516public int bsearch(int[] a, int n, int value) &#123; int low = 0; int high = n - 1; while (low &lt;= high) &#123; int mid = low + ((high - low) &gt;&gt; 1); if (a[mid] &gt; value) &#123; high = mid - 1; &#125; else if (a[mid] &lt; value) &#123; low = mid + 1; &#125; else &#123; if ((mid == 0) || (a[mid - 1] != value)) return mid; else high = mid - 1; &#125; &#125; return -1;&#125;变种2：查找最后一个值等于给定值的元素（提示：判断下标是否等于0，或者某下标的后一节点是否等于给定值）。变种3：查找第一个子节点大于等于给定值的元素（提示某下标的前一节点是否小于给定值）。变种4：查找最后一个小于等于给定值得元素（提示：某下标的后一节点是否大于给定值）。二分查找总结一般情况下，凡是可以用二分查找解决的，绝大部分都倾向于使用散列表或者二叉查找树，即使二分查找在内存使用上更节省。但是一般对于近似查找，二分查找的优势比较明显。跳表（Skip list）原理：对要查找的数据进行索引操作，一般情况下，两个节点中间都会有一个索引节点；时间复杂度：O(logn)空间复杂度：O(n)两个节点中间都有一个节点则第一层索引有n/2个节点；第二层有n/4个节点，k级有n/(2^k)……假设索引有h级，最高级有2个节点，则n/2^h=2，从而求得h=log2n - 1,如果包含原始链表，则h = log2n,如果每一层都要遍历m个节点，则跳表中查询一个数据的时间复杂度是(m logn)，再加上每一层需要遍历的节点不超过3个节点，所以算出时间复杂度是O(logn)。动态插入和删除：主要时间耗费在插入位置的查找上，所以是O(logn)。跳表索引动态更新：插入数据时，根据随机函数，来决定将这个节点插入到哪几级索引中，以此来维护索引平衡性，不至于使得两个索引节点之间包含大量节点。参考本节相关的学习代码参考github：https://github.com/liuhuijun11832/algorithm]]></content>
      <categories>
        <category>数据结构/算法</category>
      </categories>
      <tags>
        <tag>数据结构/算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构和算法-递归和排序]]></title>
    <url>%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95-%E9%80%92%E5%BD%92%E5%92%8C%E6%8E%92%E5%BA%8F.html</url>
    <content type="text"><![CDATA[简述Recursion，递归是一种非常广泛的算法，很多数据结构和算法的编码实现都要用到递归，比如DFS深度优先搜索、前中后序二叉树遍历等。Sort，排序算法是每个人都要掌握的算法，分析排序算法同样也能够锻炼对大O表示法的掌握。递归递归条件递归需要满足的三个条件：一个问题可以分解为几个子问题的解；问题和子问题之间，除了数据规模，解题思路是一样；存在递归终止条件。递归代码的关键在于如何找到将大问题分解为小问题的规律，并且基于此写出递归公式，然后推敲终止条件，最后将递推公式和终止条件翻译成代码，例如f(n)=f(n-1)+f(n-2)。递归问题警惕堆栈溢出和重复计算。堆栈溢出：计算中的函数调用会使用临时变量所封装的栈帧压入栈，系统栈或者虚拟机栈空间一般都不大，如果递归的数据规模很大，很容易堆栈溢出，解决办法是，最好设置一个最大的调用深度。重复计算：例如计算f(5)，可以分解为f(4)+f(3)，也就是分解为f(3)+f(2)+f(3)，此时f(3)就计算了两次，解决办法是，利用散列表或者某种其他的数据结构保存已经计算的结果。还有空间复杂度可能会较高的问题。排序种类：排序算法时间复杂度是否基于比较冒泡、插入、选择O(n²)√快排、归并O(nlogn)√桶、计数、基数O(n)×分析方法：最好情况、最坏情况、平均情况时间复杂度，因为有序度不同的数据对排序会有一定影响;时间复杂度的系数、常数、低阶，由于常用的排序数据可能不多，所以要考虑这些因素;比较次数和交换次数;内存消耗，原地排序就是指空间复杂度为O(1)的排序算法;稳定性，如果待排序的数据中存在相等的数据，这两个相等数据没有发生前后顺序的变化，则称该算法为稳定排序；有序度：数组中具有有序关系的元素对的个数，满有序度就是所有元素有序，其值为：n*(n-1)/2，逆序度=满有序度-有序度。冒泡排序（Bubble Sort）原理：前后两个元素两两比较，根据结果排序。例如：[4,5,6,3,2,1] 满有序度：6*5/2=15 有序度：3 逆有序度：12（需要交换12次） 第一次冒泡：[4,5,3,2,1,6]交换3次 第二次冒泡：[4,3,2,1,5,6]交换3次 第三次冒泡：[3,2,1,4,5,6]交换3次 第四次冒泡：[2,1,3,4,5,6]交换2次 第五次冒泡：[1,2,3,4,5,6]交换1次 第六次冒泡：[1,2,3,4,5,6]交换0次 特征：原地排序、稳定排序时间复杂度：最好：O(n);最坏：O(n²);平均：最好的情况下，有序度就是n(n-1)/2，所以平均可以取中间值O(n(n-1)/4)，即为O(n²)，这是种好用但是不严格的分析方法。插入排序（Insertion Sort）原理：将待排序数据分为两个区间，已排序区和未排序区，然后分别取未排序区数据放入到已排序区。例如：[4,5,6,1,3,2] 满有序度：15 有序度：5 逆有序度：10（需要交换10次） 4作为已排序区，剩下的作为未排序区 第一次插入：5&gt;4，位置不变 第二次插入：6&gt;4，位置不变 第三次插入：1&lt;4，将1往前移3位到第一位[1,4,5,6,3,2] 第四次插入：1&lt;3&lt;4，将3往前移3位到第二位[1,3,4,5,6,2] 第五次插入：1&lt;2&lt;3，将2往前移4位到第二位[1,2,3,4,5,6] 特征：原地排序、稳定排序时间复杂度：最好：O(n)最差：O(n²)平均：O(n²)选择排序（Selection Sort）原理：将待排序数据分为两个区间，已排序区和未排序区，每次从未排序区找到最小的元素，将其放到已排序区的末尾。例如：[4,5,6,3,2,1] 第一次选择：1和4交换[1,5,6,3,2,4] 第二次选择：2和5交换[1,2,6,3,5,4] 第三次选择：6和3交换[1,2,3,6,5,4] 第四次选择：6和4交换[1,2,3,4,6,5] 第五次选择：6和5交换[1,2,3,4,5,6] 特征：原地排序、非稳定排序（因为交换可能导致前面的数被交换到最后一位）最好：O(n²)最差：O(n²)平均：O(n²)归并排序（Merge Sort）原理：分治思想，将大问题分解成小问题，解决小问题以后合并。例如：初始：[11,8,3,9,7,1,2,5] 第一次分治：[11,8,3,9] [7,1,2,5] 第二次分治：[11,8][3,9][7,1][2,5] 排序：[8,11][3,9][1,7][2,5] 合并并排序：[3,8,9,11][1,2,5,7] 合并并排序：[1,2,3,5,7,8,9,11] 伪代码：//归并排序算法，A是数组，n表示数组大小 merge_sort(A,n){ merge_sort_c(A,0,n-1) } //递归调用函数 merge_sort_c(A,p,r){ //递归终止条件 if p &gt;= r then return q = (p+r)/2 //分治递归 merge_sort_c(A,p,q) merge_sort_c(A,q+1,r) merge(A[p...r],A[p,,,q],A[q+1...r]) } //合并函数 merge(A[p..r],A[p...q],A[q+1...r]){ var i := p,j := q + 1,k := 0 //申请一个大小跟第一个数组长度相等的数组 var tmp := new array[0...r-p] while i &lt;= q AND j &lt;= r do { if A[i] &lt;= A[j]{ tmp[k++] = A[i++] }else tmp[k++] = A[j++] } //判断哪个子数组中有剩余的数据 var start := i,end := q if j&lt;= r then start := j, end := r //将剩余数据拷贝到临时数组tmp while start &lt;= end do { tmp[k++] = A[start++] } //将tmp中数组拷贝回A[p...r] for i:=0 to r-p do { A[p+i] = tmp[i] } } 类型：非原地排序，非稳定排序（空间复杂度O(n)）复杂度：任何情况下都是O(nlogn)快速排序（Quick Sort）原理：分治思想，选择待排序数据中的任意一点作为pivot分区点，然后对左右两个分区执行递归，直到分区缩小为1。快速排序主要难点在于分区函数的实现，可以使用如下伪代码来实现分区：partition(A,p,r){ pivot := A[r] i := p for j := p to r - 1 do{ if A[j] &lt; pivot{ swap A[i] with A[j] i := i + 1 } } swap A[i] with A[r] return i } 时间复杂度：最好：O(nlogn)最坏：O(n²)快速排序的顺序是从大问题开始，而归并排序是从小问题开始，最后合并结果，而且快拍是可以原地排序的，所以应用范围大于归并排序。桶排序（Bucket sort）原理：将要排序的n个数据均匀地分到m个桶内，对每个桶内的元素进行快排。时间复杂度O(n)为m个桶乘以每个桶的时间复杂度O(n/m*log(n/m))，将m带入到括号即为O(nlog(n/m))，如果桶的数量m无限接近于n时，log(n/m)则是一个常数。所以桶排序的时间复杂度接近O(n)。虽然桶排序的时间复杂度看起来很低，但是不能替代之前的排序算法，因为要求桶和桶之间有着天然的大小顺序，并且数据在各个桶之间的分布是比较均匀的，极端情况下会退化为O(nlogn)。桶排序适用于外部排序中，即将数据存储在外部磁盘中，数据量大的场景，例如对10个G的订单数据进行排序，可以按照订单价格区间放入到100个文件中。计数排序（Counting sort）原理：可以将计数排序理解为特殊的桶排序，当要处理数据所处范围不大的时候，可以将其分成固定数量的桶。例如：A[2,5,3,0,2,3,0,3] 数字范围从0到5，可以再申请一个数组C计算每个元素出现次数，数组中的元素记录待排序数据出现的次数，下标代表待排序数据的值：[2,0,2,3,0,1],此时对该数组内的值进行求和得到[2,2,4,7,7,8]，接下来就到了关键的一步； 取出A[0]，该值为2，则它应该放在已排序数组R第4位（下标为3的位置），而此时C[2]的值应该减1变成4，再取出A[1]，此时应该放在已排序数组R第8位（下标为7的位置），依此类推； 当A数组遍历完的时候，R数组中所有数据都是有序的了。 代码如下：1234567891011121314151617181920212223242526272829303132public void countingSort(int[] a,int n)&#123; if(n &lt; 1) return; //找到待排序数组中最大值 int max = a[0]; for(int i = 1;i&lt;n;i++)&#123; if(max &lt; a[i]) max = a[i]; &#125; //声明一个能容纳最大值范围内所有数据的数组c,计算每个数出现次数 int[] c = new int[max+1]; for(int i = 0;i&lt; = max;i++)&#123; c[i] = 0; &#125; //遍历a数组，每出现一次，C数组对应下标的数+1 for(int i = 0;i&lt;n;i++)&#123; c[a[i]]++; &#125; //将c数组的数求和 for(int i = 1;i&lt;=max;i++)&#123; c[i] = c[i-1]+c[i]; &#125; //存放排序后的数 int[] r = new int[n]; for(int i = n -1;i&gt;0;i--)&#123; int index = c[a[i]] - 1; r[index] = a[i]; c[a[i]]--; &#125; //将排序后的数放回到原数组 for(int i = 0;i &lt; n;i++)&#123; a[i] = r[i]; &#125;&#125;应用场景：只能用在数据范围不大的场景，如果范围k比待排序数据的数量大的多，就不适合这种排序，而且它不能排序负数，基数排序（Radix Sort）原理：例如10万个手机号，排序可以按照最后一位依此往前排序，经过11次排序以后，所有手机号就都是有序的了，并且保证了稳定排序，时间复杂度是O(k*n)，这里的k是指手机号有11位，n是数据量10万就，所以其时间复杂度近似于O(n)。如果不从最后一位低位开始排序，而从高位开始排序，就不是稳定排序了。应用场景：对排序的数据有要求，需要可以分割出独立的”位“来比较，而且位之间有递进关系，每一位的访问不能太大，要用线性排序来排序，不然做不到O(n)的时间复杂度。总结如何选择合适的排序算法：如果数据量不大，可以选择O(n²)复杂度的排序算法；如果数据量大，选择O(nlogn)复杂度的排序算法，所以O(nlogn)优先；快速排序选择的pivotal尽量能够使得两个分区数量差不多，可以使用三数取中法，即从区间首、尾、中间分别取数然后对比大小，取三个数的中间值作为分区点；可以多种排序算法结合，例如小数据量使用归并排序；大数据量使用快速排序。有时候数据极少时，还可以退化为插入排序，因为复杂度为O(n²)的排序在数据量极少时，不一定比时间复杂度为O(nlogn)的算法的执行时间长。参考本节相关的学习代码参考github：https://github.com/liuhuijun11832/algorithm]]></content>
      <categories>
        <category>数据结构/算法</category>
      </categories>
      <tags>
        <tag>数据结构/算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring-RabbitMQ]]></title>
    <url>%2FSpring%E6%95%B4%E5%90%88RabbitMQ.html</url>
    <content type="text"><![CDATA[简述RabbitMQ应该是业界内最大名鼎鼎的消息队列之一了，尤其随着分布式系统架构的盛行，消息队列的作用也越来越大，它的应用场景有解耦，削峰，数据冗余，广播，缓冲，顺序保证等等。RabbitMQ使用Erlang语言编写，实现AMQP，同时支持MQTT，STOMP等多种消息协议，具有高可靠性、高扩展性等特点，现在由Pivotal公司维护。环境服务器环境：CentOS Linux 7.2 RabbitMQ Server 3.6.10 Erlang OTP 20.0 客户端环境：JDK 11 IDEA 2019.1 RabbitMQ分析首先看一下RabbitMQ的模型：这里的每一台broker即代表一台服务器，一个生产者-消费者模型，producer发送的消息里会包含routingKey，经过exchange时，交换器会根据bindingKey发送到对应的queue，routingKey和bindingKey大部分情况下是相等的，除了topic的exchange以外，bindingKey是绑定queue和exchange的routingKey。下面看一下它的工作流程：这里使用NIO模型，每一个连接线程打开了一个channel，多个channel复用同一个TCP连接。RabbitMQ中常用的交换机Exchange有四种类型：fanout，发送到该类型交换机的消息会发送到与之绑定的所有队列上，即不会管RoutingKey和BindingKey的关系；direct，会根据消息的RoutingKey发送到对应BindingKey=RoutingKey的队列中；topic，与direct类似，但是BindingKey是特殊格式，用以模糊匹配RoutingKey；headers，绑定交换机和队列时需要指定键值对KV1，同时发送消息时会在消息内容中带上headers属性，该属性也为一个键值对KV2，只有当KV1=KV2时才发送到对应队列，效率和实用性都很低。RabbitMQ安装RabbitMQ依赖于Erlang环境，所以我们需要下载Erlang的包https://www.erlang.org/downloads/20.0。下载tar.gz包到服务器，解压开，在解压开的目录下分别执行123./configure --prefix=/opt/erlangmakemake install过程不再赘述，缺对应的包即安装缺少的包（baidu即可）。最后编辑环境变量，由于prefix已经指定了目录，剩下的配置和JDK的配置类似，最后可以输入erl命令看是否安装成功，如果安装成功，则会打印：Erlang/OTP 20 [erts-9.1] [source] [64-bit] [smp:48:48] [ds:48:48:10] [async-threads:10] [hipe] [kernel-poll:false] Eshell V9.1 (abort with ^G) 然后下载RabbitMQ的tar.gz包，使用tar xzvf 命令解压开，进入到解压后的目录下的bin目录中，输入rabbitmq-server -detached即可启动，并保持后台运行。如果需要启用控制台，还需要执行rabbitmq-plugins enable rabbitmq_management，使用guest/guest可以登录。不过，默认情况下这个账户只允许本地网络访问，所以我们需要添加一个新用户，添加权限和角色：123[root@load_balance_2 ~]rabbitmqctl add_user root root123[root@load_balance_2 ~]rabbitmqctl set_permissions -p / root ".*" ".*" ".*"[root@load_balance_2 ~]rabbitmqctl set_user_tags root administrator访问rabbitmq所在服务器的15672端口，即可访问控制台。当然，docker安装更为简单，无需上面那么多步骤，直接下载rabbitmq的镜像，然后一步搞定：docker run -d --name rabbitmq -p 25672:25672 -p 5672:5672 -p 15672:15672 rabbitmq:latest代码整合这里采用父子模块的方案来构建整体骨架。点击New，新建一个Project，在弹出来的框中选择Maven选项，并勾选Create from archetype，选择maven-archetype-quickstart，新建项目后，删除src等源代码目录。在该项目里再New一个Module，同样是Maven项目，但是archetype选择maven-archetype-webapp。父pom文件主要内容如下：123456789101112131415161718192021222324252627282930313233... &lt;modules&gt; &lt;module&gt;rabbit-provider&lt;/module&gt; &lt;module&gt;rabbit-consumer&lt;/module&gt; &lt;module&gt;rabbit-common&lt;/module&gt; &lt;/modules&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.amqp&lt;/groupId&gt; &lt;artifactId&gt;spring-amqp&lt;/artifactId&gt; &lt;version&gt;1.7.6.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.amqp&lt;/groupId&gt; &lt;artifactId&gt;spring-rabbit&lt;/artifactId&gt; &lt;version&gt;1.7.6.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;4.3.14.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; ...消费者和生产者pom文件主要内容：123456789101112131415...&lt;parent&gt; &lt;artifactId&gt;simple-rabbit-demo&lt;/artifactId&gt; &lt;groupId&gt;com.joy&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;packaging&gt;war&lt;/packaging&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.joy&lt;/groupId&gt; &lt;artifactId&gt;rabbit-common&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;...消费者和生产者的mq配置文件resources/rabbit.properties：12345rabbit.hostname=192.168.15.118rabbit.port=5672rabbit.username=rootrabbit.password=root123default-queue=default-queuespring配置resources/applicationContext.xml如下：12345678910111213141516&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"&gt; &lt;context:property-placeholder location="classpath:rabbit.properties"&gt;&lt;/context:property-placeholder&gt; &lt;!-- 自动扫描 (需要修改为自己项目的路径)--&gt; &lt;context:component-scan base-package="com.joy"&gt; &lt;/context:component-scan&gt;&lt;/beans&gt;消费者和生产者WEB-INF/web.xml配置如下：123456789101112131415&lt;?xml version="1.0" encoding="UTF-8"?&gt; &lt;web-app xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://java.sun.com/xml/ns/javaee" xsi:schemaLocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd" version="2.5"&gt; &lt;display-name&gt;Archetype Created Web Application&lt;/display-name&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:applicationContext.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;!-- 防止spring内存溢出的监听器--&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.util.IntrospectorCleanupListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;/web-app&gt;common模块中只有一个实体类User：12345678910111213141516171819202122232425262728293031public class User implements Serializable &#123; private final static long serialVersionUID = 1L; private String name; private Integer age; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Integer getAge() &#123; return age; &#125; public void setAge(Integer age) &#123; this.age = age; &#125; @Override public String toString() &#123; return "User&#123;" + "name='" + name + '\'' + ", age=" + age + '&#125;'; &#125;&#125;生产者默认配置如下，统一使用个人钟爱的注解式配置：12345678910111213141516171819202122232425262728293031323334353637383940/** * @Description: 生产者配置 * @Author: Joy * @Date: 2019-05-20 11:28 */@Configurationpublic class RabbitConfiguration &#123; @Value("$&#123;rabbit.hostname&#125;") private String rabbitHost; @Value("$&#123;rabbit.port&#125;") private int rabbitPort; @Value("$&#123;rabbit.username&#125;") private String rabbitUName; @Value("$&#123;rabbit.password&#125;") private String rabbitPassword; @Bean public ConnectionFactory connectionFactory()&#123; CachingConnectionFactory cachingConnectionFactory = new CachingConnectionFactory(); cachingConnectionFactory.setHost(rabbitHost); cachingConnectionFactory.setPort(rabbitPort); cachingConnectionFactory.setUsername(rabbitUName); cachingConnectionFactory.setPassword(rabbitPassword); return cachingConnectionFactory; &#125; @Bean public AmqpAdmin amqpAdmin()&#123; return new RabbitAdmin((connectionFactory())); &#125; @Bean public AmqpTemplate rabbitTemplate()&#123; RabbitTemplate rabbitTemplate = new RabbitTemplate(connectionFactory()); rabbitTemplate.setMessageConverter(messageConverter()); return rabbitTemplate; &#125;&#125;生产者测试类如下：12345678@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration("classpath:applicationContext.xml")public class AmqpTest &#123; @Autowired private RabbitTemplate rabbitTemplate;&#125;消费者配置默认如下：12345678910111213141516171819202122232425262728293031323334353637383940414243@EnableRabbit@Configurationpublic class RabbitConfiguration &#123; @Value("$&#123;rabbit.hostname&#125;") private String rabbitHost; @Value("$&#123;rabbit.port&#125;") private int rabbitPort; @Value("$&#123;rabbit.username&#125;") private String rabbitUName; @Value("$&#123;rabbit.password&#125;") private String rabbitPassword; @Bean public ConnectionFactory connectionFactory()&#123; CachingConnectionFactory cachingConnectionFactory = new CachingConnectionFactory(); cachingConnectionFactory.setHost(rabbitHost); cachingConnectionFactory.setPort(rabbitPort); cachingConnectionFactory.setUsername(rabbitUName); cachingConnectionFactory.setPassword(rabbitPassword); return cachingConnectionFactory; &#125; /** * 使用注解式驱动方法监听 * @return */ @Bean public SimpleRabbitListenerContainerFactory rabbitListenerContainerFactory() &#123; SimpleRabbitListenerContainerFactory factory = new SimpleRabbitListenerContainerFactory(); factory.setConnectionFactory(connectionFactory()); factory.setConcurrentConsumers(3); factory.setMaxConcurrentConsumers(10); return factory; &#125; @Bean public AmqpAdmin amqpAdmin()&#123; return new RabbitAdmin((connectionFactory())); &#125;&#125;默认交换机如果不指定交换机，只是指定了一个队列，那么该默认绑定到RabbitMQ上的一个默认交换机，类型为direct，并且其routingKey就是队列名，配置如下(无论配置在生产者还是消费者都可以，或者两者都配置也可以，如果不配置的话消费者可能会报没有找到队列的错误)：123456@Beanpublic Queue defultQueue()&#123; //默认durable为true，exclusive为false，auto-delete为false return new Queue("default-queue");&#125;消费者监听传统会使用这种方式：1234567@Componentpublic class DefaultListener implements MessageListener &#123; @Override public void onMessage(Message message) &#123; System.out.println(new String(message.getBody())); &#125;&#125;但是我这里使用注解驱动的方式来监听，这样就可以使用方法级别来监听队列了，避免建立大量的类：1234567891011@Componentpublic class Myservice &#123; /** * 监听默认队列 * @param data */ @RabbitListener(queues = "$&#123;default-queue&#125;") public void processDefault(String data)&#123; System.out.println("default-queue"+"===&gt;"+data); &#125;&#125;并且这里的@RabbitListener里的queues属性还可以使用spring $取值的形式或者spEL表达式来取值。注意：使用注解驱动的方式需要在任一配置类中加上@EnableRabbit注解，上文中消费者配置类中已经加上。在生产者中测试类中，新建一个单元测试：12345@Testpublic void sendToDefaultQueue()&#123; //使用默认交换机 rabbitTemplate.convertAndSend("default-queue","默认队列");&#125;为消费者添加一个tomcat或者jetty，启动，此时进入控制台，可以看到Queues页面表格多了一个default-queue队列：其中features一栏中，D代表开启了持久化。同时在Exchanges页面表格中，可以看到多了一个(AMQP default)名字的交换机。运行单元测试，消费者打印出：”default-queue===&gt;默认队列”Fanout交换机该类型交换机指定routingKey会无效，所以消息会发送到所有与该交换机绑定的队列上。在消费者或者生产者增加配置：12345678910111213141516171819202122232425262728//声明一个可以持久化的fanout交换机@Beanpublic Exchange testFanoutExchange()&#123; return ExchangeBuilder.fanoutExchange("joy.fanout.exchange").durable(true).build();&#125;//声明第一个队列@Beanpublic Queue testFanoutQueue1()&#123; Queue queue = new Queue("queue1",true); return queue;&#125;//将第一个队列绑定到fanout交换机上@Beanpublic Binding testFanoutBuilding()&#123; return BindingBuilder.bind(testFanoutQueue1()).to(testFanoutExchange()).with("queue-1").noargs();&#125;//声明第二个队列@Beanpublic Queue testFanoutQueue2()&#123; return new Queue("queue2", true);&#125;//将第二个队列绑定到fanout交换机上@Beanpublic Binding testFanoutBuilding1()&#123; return BindingBuilder.bind(testFanoutQueue2()).to(testFanoutExchange()).with("queue-2").noargs();&#125;消费者的MyService类中新增两个方法消费消息：12345678910111213141516171819/** * 监听第一个队列 * @param data */@RabbitListener(bindings = @QueueBinding(value = @Queue(value = "queue1",durable = "true"), exchange = @Exchange(value = "joy.fanout.exchange",type = ExchangeTypes.FANOUT,durable = "true"),key = "queue-1"))public void process1(String data)&#123; System.out.println("fanout-queue1"+"===&gt;"+data);&#125;/** * 监听第二个队列 * @param data */@RabbitListener(bindings = @QueueBinding(value = @Queue(value = "queue2",durable = "true"), exchange = @Exchange(value = "joy.fanout.exchange",type = ExchangeTypes.FANOUT,durable = "true"),key = "queue-2"))public void process2(String data)&#123; System.out.println("fanout-queue2"+"===&gt;"+data);&#125;这里在监听的方法上使用bingdings属性注解可以避免因队列不存在而报错，换句话说，这些注解的作用其实就是创建队列、交换机以及绑定队列和交换机的rountingKey，有了这些注解其实也可以不用上面的配置。生产者测试类中新增单元测试，并运行：12345678@Testpublic void sendToFanoutExchange()&#123; //自定义交换机以及与其绑定的对列名 rabbitTemplate.setExchange("joy.fanout.exchange"); rabbitTemplate.setRoutingKey("queue-1"); rabbitTemplate.convertAndSend("我是谁？我在哪？我要干什么？");&#125;消费者打印出：fanout-queue2===&gt;我是谁？我在哪？我要干什么？ fanout-queue1===&gt;我是谁？我在哪？我要干什么？ 此时无论指定routingKey为什么都会发送到所有绑定到该fanout类型交换机的队列上，就和广播一样。Direct交换机最好理解的交换机，发送消息时指定routingKey，交换机根据该routingKey发送到绑定时bindingKey与该路由键一致的队列上。配置如下：12345678910111213141516171819202122//声明一个direct类型的交换机@Beanpublic Exchange testDirectExchange()&#123; return ExchangeBuilder.directExchange("joy.direct.exchange").durable(true).build();&#125;//将第三个队列绑定到direct交换机上@Beanpublic Binding testDirectBinding1()&#123; return BindingBuilder.bind(directQueue()).to(testDirectExchange()).with("queue-3").noargs();&#125;//声明第四个队列@Beanpublic Queue directQueue1()&#123; return new Queue("queue4");&#125;//将第四个队列绑定感到direct交换机上@Beanpublic Binding testDirectBinding2()&#123; return BindingBuilder.bind(directQueue1()).to(testDirectExchange()).with("queue-4").noargs();&#125;或者在消费者注解指定，如果在配置中配置了，这里就可以直接使用用@RabbitListener(queues=&quot;队列名&quot;)的方式指定了：12345678910111213141516171819/** * 监听第三个队列 * @param user */ @RabbitListener(bindings = @QueueBinding(value = @Queue(value = "queue3",durable = "true"), exchange = @Exchange(value = "joy.direct.exchange",durable = "true"), key = "queue-3")) public void process3( User user)&#123; System.out.println("direct-queue3"+"===&gt;"+user.toString()); &#125; /** * 监听第四个队列 * @param user */ @RabbitListener(bindings = @QueueBinding(value = @Queue(value = "queue4",durable = "true"), exchange = @Exchange(value = "joy.direct.exchange",durable = "true"),key = "queue-4")) public void process4( User user) &#123; System.out.println("direct-queue4===&gt;"+user.toString()); &#125;这里和前面不同的一点是，这里是直接在方法参数里接收一个对象，如果需要这么做，那么该对象需要实现java的Serializable接口，并且指定一个messageConverter。拿常用的Json格式举例：首先需要在生产者中调整配置：1234567891011@Beanpublic AmqpTemplate rabbitTemplate()&#123; RabbitTemplate rabbitTemplate = new RabbitTemplate(connectionFactory()); rabbitTemplate.setMessageConverter(messageConverter()); return rabbitTemplate;&#125;@Beanpublic MessageConverter messageConverter()&#123; return new Jackson2JsonMessageConverter();&#125;然后调整消费者的配置：1234567891011121314151617181920/** * 使用注解式驱动方法监听 * @return */@Beanpublic SimpleRabbitListenerContainerFactory rabbitListenerContainerFactory() &#123; SimpleRabbitListenerContainerFactory factory = new SimpleRabbitListenerContainerFactory(); factory.setConnectionFactory(connectionFactory()); factory.setConcurrentConsumers(3); factory.setMaxConcurrentConsumers(10); //添加消息转换器 factory.setMessageConverter(messageConverter()); return factory;&#125;@Beanpublic MessageConverter messageConverter()&#123; return new Jackson2JsonMessageConverter();&#125;新增单元测试方法并执行：1234567891011@Testpublic void sendToDirectExchange()&#123; User user = new User(); user.setName("刘会俊"); user.setAge(24); //发送direct消息对象 rabbitTemplate.convertAndSend("joy.direct.exchange", "queue-3", user); user.setName("刘半仙"); user.setAge(124); rabbitTemplate.convertAndSend("joy.direct.exchange", "queue-4", user);&#125;消费者打印：direct-queue3===&gt;User{name=&apos;刘会俊&apos;, age=24} direct-queue4===&gt;User{name=&apos;刘半仙&apos;, age=124} Topic交换机在该类型的交换机中，约定routingKey和bindingKey由以”.”分隔的字符串组成，并且可以使用”“和”#”进行模糊匹配，其中\表示匹配一个单词，#表示匹配多个单词。消费者新增两个监听：1234567891011@RabbitListener(bindings = @QueueBinding(value = @Queue(value = "queue5",durable = "true"), exchange = @Exchange(value = "joy.topic.exchange",type = ExchangeTypes.TOPIC,durable = "true"),key = "51.#")) public void process5(User user)&#123; System.out.println("51.#===&gt;"+user.toString()); &#125; @RabbitListener(bindings = @QueueBinding(value = @Queue(value = "queue6",durable = "true"), exchange = @Exchange(value = "joy.topic.exchange",type = ExchangeTypes.TOPIC,durable = "true"),key = "*.WEB.#")) public void process6(User user)&#123; System.out.println("*.WEB.#===&gt;"+user.toString()); &#125;其中第一个监听的队列queue5匹配规则是以51.开头，后面有多个字符串或0个字符串；而第二个监听的队列queue6匹配规则是第一部分有一个单词，第二部分为”WEB”字符串的队列。生产者增加单元测试：1234567891011 @Testpublic void sendToTopicExchange()&#123; rabbitTemplate.setExchange("joy.topic.exchange"); User user = new User(); user.setName("刘二柱"); user.setAge(18); rabbitTemplate.convertAndSend("51.APP.TS",user); user.setName("刘一手"); user.setAge(20); rabbitTemplate.convertAndSend("51.WEB.TS",user);&#125;预期结果是：刘二柱会被发送到queue5，刘一手会发送到queue5和queue6。运行结果为：51.#===&gt;User{name=&apos;刘二柱&apos;, age=18} *.WEB.#===&gt;User{name=&apos;刘一手&apos;, age=20} 51.#===&gt;User{name=&apos;刘一手&apos;, age=20} 延迟队列和死信队列可以通过设置队列的ttl属性，或者发送消息时的消息属性expiration来实现延迟队列。当消息在ttl或者expiration时间没有消费时，则会进入死信队列（DLX），每一个队列实际上会有一个死信交换机属性，当我们给某个队列设置了死信交换机，并且给该交换机绑定了死信队列时，正常队列中没有消费者监听或者超时的消息都会经过死信交换机进入死信队列。配置正常队列以及对应的死信队列：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354 //声明一个正常队列，并添加定时时间和死信交换器路由@Beanpublic Queue normalQueue()&#123; Map&lt;String, Object&gt; args = new HashMap&lt;&gt;(); args.put("x-message-ttl", 10000); args.put("x-dead-letter-exchange", "joy.dead.direct.exchange"); args.put("x-dead-letter-routing-key", "dead-queue"); Queue normalQueue = new Queue("normal-queue",true,false,true,args); return normalQueue;&#125;//声明一个死信队列@Beanpublic Queue deadQueue()&#123;return new Queue("dead-queue",true);&#125;//声明一个正常交换机@Beanpublic Exchange normalExchange()&#123; return ExchangeBuilder.directExchange("joy.normal.direct.exchange").durable(true).build();&#125;//声明一个私心交换机@Beanpublic Exchange deadExchange()&#123; return ExchangeBuilder.directExchange("joy.dead.direct.exchange").durable(true).build();&#125;//声明一个正常绑定关系@Beanpublic Binding normalBinding()&#123; return BindingBuilder.bind(normalQueue()).to(normalExchange()).with("normal-queue").noargs();&#125;//将死信队列和死信交换机绑定上@Beanpublic Binding deadBinding()&#123; return BindingBuilder.bind(deadQueue()).to(deadExchange()).with("dead-queue").noargs();&#125; //声明一个正常队列1,绑定死信交换机和队列参数@Beanpublic Queue normalQueue1()&#123; Map&lt;String, Object&gt; args = new HashMap&lt;&gt;(); args.put("x-dead-letter-exchange", "joy.dead.direct.exchange"); args.put("x-dead-letter-routing-key", "dead-queue"); Queue normalQueue = new Queue("normal-queue1",true,false,true,args); return normalQueue;&#125;//声明一个正常绑定关系@Beanpublic Binding normalBinding1()&#123; return BindingBuilder.bind(normalQueue1()).to(normalExchange()).with("normal-queue1").noargs();&#125;当然也可以在消费者监听的@Queue注解里新增参数argument，这里不再赘述，与上面的配置基本类似。当然，不光可以给队列设置ttl，也可以给消息设置expiration超时，所以上面又设置了一个normal-queue1，这个队列同样绑定了死信，auto-delete为true，并且没有设置ttl。消费者增加一个死信的监听器：12345678 /** * 监听死信队列消息 * @param user */@RabbitListener(queues = "dead-queue")public void process7(User user)&#123; System.out.println("dead-queue===&gt;"+user.toString());&#125;增加单元测试：123456789101112131415161718 @Testpublic void sendToNormalExchange()&#123; rabbitTemplate.setExchange("joy.normal.direct.exchange"); User user = new User(); user.setName("刘三胖"); user.setAge(18); rabbitTemplate.convertAndSend("normal-queue",user); user.setName("刘二丫"); user.setAge(18); rabbitTemplate.convertAndSend("normal-queue1",user,message -&gt; &#123; message.getMessageProperties().setExpiration("10000"); return message; &#125;); user.setName("刘狗剩"); user.setAge(19); rabbitTemplate.convertAndSend("normal-queue1",user);&#125;启动项目，会发现控制台中Queues页面多了两个队列如图：其中AD表示自动删除，TTL表示队列设置了存活时间，DLX表示绑定了死信交换机，DLK表示死信交换机绑定了routingKey。预期结果：normal-queue的监听器由于设置了10s超时，所以10s以后，死信监听器监听到消息；normal-queue1中的刘二丫由于给消息设置了过期，所以10s以后死信队列也会收到消息；而刘狗剩则会一直待在队列中。运行结果：dead-queue===&gt;User{name=&apos;刘三胖&apos;, age=18} dead-queue===&gt;User{name=&apos;刘二丫&apos;, age=18} 这两条信息恰好是10s打印的，而狗剩那条消息，则永远的留在了normal-queue1中，可以查看控制台，此处就不再贴图。参考本文Github代码地址：https://github.com/liuhuijun11832/spring-rabbit-demo.git参考：《RabbitMQ实战指南》 朱忠华 著；《Spring AMQP官方文档》https://docs.spring.io/spring-amqp/docs/1.7.14.BUILD-SNAPSHOT/reference/html/ 。]]></content>
      <categories>
        <category>编程技术</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构和算法-线性表]]></title>
    <url>%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95-%E7%BA%BF%E6%80%A7%E8%A1%A8.html</url>
    <content type="text"><![CDATA[简介线性表：数据与数据之间只存在简单的前后关系的数据结构，例如数组、链表、栈、队列；非线性表：数据与数据之间存在多种关系，例如图、堆、二叉树。数组数组：一组内存连续的数据结构，用于存储一组同一类型的数据。数组的访问速度快，因为使用了下标（偏移量），所以访问效率高，能够进行随机（任意）访问。访问原理为：数组首地址+偏移量*数据大小；时间复杂度：使用随机访问的时间复杂度为O(1)；新增和删除操作：需要调整其他元素，例如要新增一个元素n到下标i的位置，则需要调整i以后的元素，最好情况是新增到最后一位，此时时间复杂度是O(1)，最差情况是添加到第一位，则需要调整整个数组所有元素，此时时间复杂度是O(n)，那么平均时间复杂度是(1+…+n)/n=O(n)，删除操作也与之类似。优化方案：可以不用每一次删除都调整其他所有元素位置，将每次需要删除的元素记录（标记）起来，当数据空间不足以存储新数据时，再清除所有记录的元素（类似于jvm的标记清除算法）。二维数组：例如m*n，则a[i][j]的内存地址为：数组首地址+(i*n+j)*数据大小。关于数组下标从0开始的原因，通常认为有两个原因：由于C语言是从0开始，其他语言为了减少程序员学习成本，都模仿的C语言；还有就是偏移量如果从1开始，那么找地址时就是：首地址+（偏移量-1）* 数据大小，会多一次减法操作，影响性能。Java中，数组和ArrayList的应用场合：容器：业务操作，对性能没有极端要求的场景；数组：对性能有要求，或者需要存储基本数据类型的场景。链表链表不需要连续的内存空间，数据之间的内存可以是零散的。链表包含单链表，循环链表，双向链表。单链表：链表中每一个节点包含两个部分，数据和下一节点指针（next），头节点包含基地址，尾节点指向一个空地址NULL；循环链表：在单链表的基础上，尾节点的下一节点指针指向了头节点；双向链表：链表中每一个节点包含三个部分，数据、上一节点指针（prev）和下一节点指针；访问操作：需要从头节点开始查找，复杂度为O(n)；删除和插入操作：找到需要删除的节点，将该节点的上一节点的next指向该节点的下一节点，删除操作本身的时间复杂度是O(1)，主要的时间耗费是在查找节点上。对于双向链表，虽然花费的空间大一些，但是在删除或者插入节点的时候，能够直接获取到判断操作位置的前一个节点（空间换时间）。例如，删除一个节点分为两种情况：删除与给定节点数据相等的节点q，此时需要从链表第一个节点开始找并比较数据是否相等，直到找到p-&gt;next=q为止，然后将上一节点指针指向被删除节点的下一个节点；删除给定的指针所指向的节点q，此时已知需要删除的数据，如果直接删除该节点，那么还需要遍历找到该节点的上一节点，但是使用双向链表的时候，就无需遍历，根据被删除节点的前置指针就能找到上一节点，即通过q-&gt;prev的到p，然后将p-&gt;next指向r，并将r-&gt;prev指向p。链表不能像数组一样充分利用CPU缓存，因为CPU在内存中读取数组数据时，读取的并不是某一个数据，而是一个数据块，即读取下标为i的数据会一起读取i+n的数据块，下次查找数据时就能够首先查询缓存，弥补了读取内存带来的速度差的缺陷。实际项目中需要根据场合来使用对应的数据结构。栈操作受限的线性表，一种先入后出的数据结构，只支持入栈（push）和出栈（pop）。时间复杂度：由于入栈和出栈操作的都是栈顶元素，所以为O(1)；空间复杂度：由于入栈操作和出栈操作时只需要一个额外的空间存储操作的元素，所以是O(1)；栈是一种抽象的数据结构，链表和数组是一种实际存在于内存中的数据结构。所以栈的实现可以是数组和链表，如果是数组实现的就叫顺序栈，链表实现的叫链式栈。入栈操作分析：对于动态可扩容的顺序栈，入栈时需要判断空间是否可以存储入栈元素，最好时间复杂度就是O(1)，如果需要扩容，那么就需要移动原来的n个元素，最坏时间复杂度就是O(n)，如果均摊到每一次入栈，就是每一次入栈只需要一次O(1)的push到栈顶的操作加上一次数据移动操作，所以摊还时间复杂度也是O(1)。应用场景：1.浏览器的前进后退定义两个栈，一个保存后退页面back stack ，另一个保存前进页面forward stack。从a页面进入到b页面时，将a放到back stack，从b到c页面，就将c放入back stack，如果需要点击后退按钮，则将c放入forward stack，从back stack取出b渲染页面，然后再点击前进按钮，则将b再次放入back stack，将c从forward stack中取出来。2.简单运算定义两个栈，一个保存操作数，一个保存操作符。从左到右遍历2+3*4-5/5，遇到数字就压入操作数栈，遇到操作符就与操作符栈顶元素比较，当遇到的操作符优先级小于操作符栈顶的操作符时，从操作数栈取出两个数字执行操作，将算得的结果压入操作数栈，继续比较，算的结果以后清空栈。3.函数调用栈每一个函数都是一个栈帧，当调用函数时则将被调用函数压进栈里，处于栈顶。4.括号匹配扫到左括号时放入栈里，扫到右括号则从栈里取出栈顶元素判断是否是一对，直到栈中元素匹配完成，如果能够恰好匹配上，栈中最后会没有元素。函数调用采用栈这种数据结构，是因为函数调用时很符合前后函数先入后出德思想。队列操作受限的线性表，一种先入先出的数据结构，只支持入队（enqueue）和出队（dequeue）操作，同样是一种抽象数据结构，如果通过数组实现称之为顺序队列，如果通过链表实现，则称之为链式队列。时间复杂度：链式队列入队和出队的时间复杂度都是O(1)，顺序队列入队时，可能会触发数据搬移（队列头有元素出队），所以最好时间复杂度时O(1)，最坏时间复杂度度时O(n)，由于入队时触发一次数据搬移后剩下的入队时间复杂度都是O(1)，所以摊还时间复杂度也是O(1)；空间时间复杂度：O(1)；1.循环队列循环顺序队列的首（head）和尾（tail）是相连的，成一个环状，因此入队时不需要进行数据搬移，直接将tail往后移一位即可，直到数组空间满；2.阻塞队列阻塞队列同样有head和tail两个位置标记首尾，如果队列为空时，会阻塞出队操作，直到队列中有元素放入；3.并发队列在入队和出队操作上加上同步关键字，或者使用顺序队列，通过cas操作实现；循环队列最重要和最难的部分就是在于判断队列的空和满的条件。参考本节相关的学习代码参考github：https://github.com/liuhuijun11832/algorithm]]></content>
      <categories>
        <category>数据结构/算法</category>
      </categories>
      <tags>
        <tag>数据结构/算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构和算法-复杂度分析]]></title>
    <url>%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95-%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90.html</url>
    <content type="text"><![CDATA[简述复杂度：数据结构和算法中的复杂度有两种，渐进时间复杂度（asymptotic time complexity），描述的是代码执行时间随着数据规模的增长而增长的趋势，简称时间复杂度；渐进空间复杂度（asymptotoc space complexity），描述的是代码使用空间随着数据规模的增长而增长的趋势，简称空间复杂度。通常情况下，复杂度使用大O表示法来表示：O(n)，O(logn)等等。大O表示法T(n)=O(f(n)) n表示的就是数据规模，T(n)表示代码执行时间，f(n)表示每行代码执行次数总和。例如：1234567int find(int n)&#123; int sum = 0;//1unit_time int i = 0;//1unit_time for(; i &lt; n ; i++)&#123;//n unit_time sum += i; //n unit_time &#125;&#125;假定执行一行代码所需时间为unit_time，则f(n)=2*unit_time+2n*unit_time=2(n+1)*unit_time，因此T(n)=O(2n+2)，当n非常大时，系数和常数对于T(n)的影响就微乎其微了，所以通常系数和常数不计入表示法，因此上述代码的时间复杂度为：T(n)=O(n)，空间复杂度也是同理，见代码：12345678910111213void print(int n) &#123; int i = 0;//1 unit_space int[] a = new int[n];// n unit_space for (i; i &lt;n; ++i) &#123; a[i] = i * i; &#125; for (i = n-1; i &gt;= 0; --i) &#123; print out a[i] &#125;&#125;复杂度分析时间复杂度分析分析方法1：只关注循环次数最多或者循环嵌套最多的代码循环就是O(n)，再嵌套就是O(n²)，三层循环就是O(n³)；2：加法法则如果一个算法里两段代码的时间规模n一样，则T(n)=T1(n)+T2(n)=max(O(f(n))+O(g(n)))=O(max(f(n),g(n)))；如果一个算法里两段代码的时间规模不一样，分别为n和m，则T(m+n)=T1(m)+T2(n)=O(f(m))+O(f(n))=O(m+n)；3：乘法法则嵌套代码的复杂度等于每一层嵌套的复杂度乘积T(n)=T1(n)*T2(n)=O(f(n))*O(g(n))=O(f(n)*g(n))。常见复杂度1：O(1)多项式量级，常数阶，只要没有进行递归或者循环，普通的语句或者判断语句的复杂度都是O(1)，它并不是表示代码的具体执行时间，而是随着数据的增长，代码的执行时间并没有明显的增长，即不管代码多长，执行次数都是1次。2：O(n)多项式量级，线性阶，单层循环常见;3：O(logn) O(nlogn)多项式量级，该对数阶的推导可以参考下面代码：1234i=1;while (i &lt;= n) &#123; i = i * 2;&#125;每次都是乘以2，直到i的值大于n，每一次i的值分别是：2¹ 2² 2³ ... 2^x，最后一项的值为n，则x=log₂n，O(f(n))=O(log₂n)，千万记住，f(n)的意思就是代码执行次数。同理，将上述代码改为i = i * 3 时的大O表示法为O(log₃n)，根据对数换底公式：logan * lognb = logab，所以凡是对数阶的表示法都可以变为logm² * log₂n的形式，其中m为常数，由于上面所说常数项不计，因此所有对数阶都是O(logn)。O(nlogn)则是在上述基础上再加上一个外层循环。4：O(n²)多次方阶，常见于嵌套循环或者递归调用。5：O(m+n) O(m n)*该复杂度常见于有多种数据规模的算法，算法的时间复杂度取决于多个代码段。6：指数阶和阶乘阶O(2^n)或者O(n!)属于非多项式量级，该复杂度的算法性能很差，所以不再考虑。各种算法的性能图表如下：空间复杂度分析空间复杂度常用的有O(1)、O(n)、O(n²)等等，由于比较简单，没有太多需要赘述。扩展时间复杂度还有最好时间复杂度(best case time complexity)，最坏时间复杂度(worst case time complexity)，平均时间复杂度(average case time complexity)和均摊时间复杂度(amortized time complexity)。123456789// n 表示数组 array 的长度int find(int[] array, int n, int x) &#123; int i = 0; int pos = -1; for (; i &lt; n; ++i) &#123; if (array[i] == x) pos = i; &#125; return pos;&#125;由于不同的操作会导致复杂度的不同，所以上述代码不同场景会有不同复杂度。顾名思义，最好时间复杂度就是指在最理想的场景下的时间复杂度，只需要执行一次就可以找到需要的数据，此时时间复杂度为O(1)；最不理想的场景下，元素不在数组中，所以导致要遍历所有元素，此时时间复杂度为O(n)；而平均时间复杂度的分析，首先假设元素在数组中和不在数组中的概率分别为1/2，那么出现每个位置的的概率都是1/n，所以出现在第一个位置的代码执行次数是1 * 1/n，第二个位置的代码执行次数为2 * 1/n，而不在数组中代码执行次数为n，依此类推：O((1\*1/n+2\*1/n+ ... + n \* 1/n) \* 1/2 + n\*1/2) = O(n(n+1)/2\*1/2n+n/2)=O((3n+1)/4)=O(n) 由于低阶、常数、系数都可以不计，所以平均时间复杂度也是O(n)，所以平均时间复杂度严格来说可以称之为平均加权复杂度或者期望时间复杂度，至于均摊时间复杂度，借助下面代码进行展示：123456789101112131415161718// array 表示一个长度为 n 的数组// 代码中的 array.length 就等于 nint[] array = new int[n];int count = 0;void insert(int val) &#123; if (count == array.length) &#123; int sum = 0; for (int i = 0; i &lt; array.length; ++i) &#123; sum = sum + array[i]; &#125; array[0] = sum; count = 1; &#125; array[count] = val; ++count;&#125;对于大部分情况，数据一次插入，只有插入到最后一位时会执行遍历相加的操作并放到第一位，因此对于这种连续的低时间复杂度操作，其中只有少数高复杂度的操作的，分析的方式就是尝试将高复杂度的操作分摊到低复杂度操作上。一般情况下，能够分摊复杂度的算法的均摊时间复杂度都等于最好时间复杂度。]]></content>
      <categories>
        <category>数据结构/算法</category>
      </categories>
      <tags>
        <tag>数据结构/算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构和算法-开篇记]]></title>
    <url>%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95-%E5%BC%80%E7%AF%87%E8%AE%B0.html</url>
    <content type="text"><![CDATA[简述程序员的长久发展，离不开内功，对于高手来说，技术和框架的应用是一种招式，而数据结构和算法是内功，修炼到绝顶时无招胜有招。工作将近两年的时间里，工作的时间加上业余时间，我几乎已经接触并使用过市面上很多常用的框架和技术，从前端的Ajax/JQ，到Android，再到后端Java的SSM、Spring Boot/Spring Cloud，最后到服务端的Linux、Shell、Nginx、Redis等。随着水平的提升和眼界的扩展，我越来越迫切的感受到数据结构、算法和源码层面的知识匮乏，所以计划将数据结构和算法完整而系统地学习一遍。学习资料和方法学习的主要参考资料如下（暂定）：极客时间课程《数据结构和算法之美》《算法》（第四版）红皮；《数据结构和算法：Java语言描述》。其中，以极客时间课程为引导，第二和第三项为参考和深入；主要的数据结构有：数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie树；主要算法有：递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法。学习方法：原理学习+实战演练+刷题；时间和主要内容规划：第一周：2019.4.29-2019.5.5：大O表示法，时间复杂度和空间复杂度分析；第二周：2019.5.6-2019.5.12：数组、链表、栈、队列；第三周：2019.5.13-2019.5.19：递归、排序；第四周：2019.5.20-2019.5.26：二分查找、跳表；第五周：2019.5.27-2019.6.2：散列表、哈希算法；第六周：2019.6.3-2019.6.9：二叉树、红黑树、递归树；第七周：2019.6.10-2019.6.16：堆和图，堆排序图的查找；第八周：2019.6.17-2019.6.23：字符串匹配；第九周：2019.6.24-2019.6.30：Trie树，AC自动机，贪心算法；第十周：2019.7.1-2019.7.6：回溯算法，动态规划；第十一周：2019.7.7-2019.7.13：拓扑排序、最短路径、位图；第十二周：2019.7.14-2019.7.20：概率统计、向量空间、B+树；第十三周：2019.7.21-2019.7.27：搜索、索引、并行算法；第十四周：2019.7.28-2019.8.4：算法实战解析。每周末写一遍算法学习笔记，并且手写当周学习的算法和数据结构，希望百日能通关数据结构和算法大关。]]></content>
      <categories>
        <category>数据结构/算法</category>
      </categories>
      <tags>
        <tag>数据结构/算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android学习笔记三-界面开发]]></title>
    <url>%2FAndroid%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B8%89-%E7%95%8C%E9%9D%A2%E5%BC%80%E5%8F%91.html</url>
    <content type="text"><![CDATA[简介笔记记载的内容有：常用的几大界面和布局，并仿写一个简单的聊天界面。布局介绍LinearLayout该布局内元素都是线性排列，如果在标签里指定了android:orientation=&quot;vertical&quot;，则所有元素都是纵向排列的。默认值是horizontial，即横向排列。横向排列时，内部元素的layout_width就不能设置为match_parent，因为该值会使得元素占满一行；由于元素的横向长度不确定，所以此时元素的对齐方式layout_gravity只能为垂直对齐。对于android:layout_gravity和android:layout，前者用于指定控件在布局中的对齐方式，后者为控件内的文字等在控件中的对齐方式。LinearLayout里也有一个重要属性android:layout_weight，可以解决手机屏幕的适配问题，LinearLayout会将布局里的所有元素的anroid:layout_weight的值相加，然后根据每个元素所占比例和布局的orientation排列进行水平或者垂直切分，如果不设置anroid:layout_weight值的控件和使用该属性的控件混合使用，使用wrap_content，则使用wrap_content会单独计算，其余的等比切分。RelativeLayout相对布局内的控件排列比较随意，相对定位顾名思义会有一个参照定位点，例如android:layout_alignParentTop，android:layout_alignParentLeft等分别表示相对父布局的顶部，相对父布局的右边，或者android:layout_above=@id/button，android:layout_toRightOf=@id/button分别表示在id为button的的上方，在id为button的右边。FrameLayout帧布局，这种布局默认摆放在布局的左上角。PercentLayout百分比布局是新增的布局，需要在app的build.gradle文件的dependencies闭包下添加compile &#39;com.android.support.percent:28.0.0&#39;，此时在布局文件里就可以使用如下方式来使用了：123456789101112&lt;android.support.percent.PercentFrameLayout xmlns:android="http://schemas.android.com/apk/res/android" xmlns:app="http://schemas.android.com/apk/res-auto" android:layout_width="match_parent" android:layout_height="match_parent"&gt; &lt;Button android:id="@+id/button" android:layout_gravity="right|top" app:layout_widthPercent="50%" app:layout_highPercent="50%" /&gt;&lt;/android.support.percent.PercentFrameLayout&gt;自定义控件环境：Android Studio 3.4Windows 10调试机：一加 6 Android 9app/build.gradle如下：1234567891011121314151617181920212223242526272829303132333435363738apply plugin: 'com.android.application'android &#123; compileSdkVersion 27 defaultConfig &#123; applicationId "com.joy.practice" minSdkVersion 15 targetSdkVersion 27 versionCode 1 versionName "1.0" testInstrumentationRunner "android.support.test.runner.AndroidJUnitRunner" javaCompileOptions &#123; annotationProcessorOptions &#123; includeCompileClasspath = true &#125; &#125; &#125; buildTypes &#123; release &#123; minifyEnabled false proguardFiles getDefaultProguardFile('proguard-android-optimize.txt'), 'proguard-rules.pro' &#125; &#125; compileOptions &#123; sourceCompatibility JavaVersion.VERSION_1_8 targetCompatibility JavaVersion.VERSION_1_8 &#125;&#125;dependencies &#123; implementation fileTree(dir: 'libs', include: ['*.jar']) iimplementation 'com.android.support:appcompat-v7:27.1.1' implementation 'com.android.support:recyclerview-v7:27.1.1' implementation 'com.android.support.constraint:constraint-layout:1.1.3' testImplementation 'junit:junit:4.12' androidTestImplementation 'com.android.support.test:runner:1.0.2' androidTestImplementation 'com.android.support.test.espresso:espresso-core:3.0.2' implementation 'org.projectlombok:lombok:1.18.6'&#125;模仿ios做一个具有返回和编辑按钮的标题栏，首先新建一个标题栏的布局文件，并在res下新建一个drawable-xhdpi目录，然后将需要的title_bg.png,back_bg.png,edit_bg.png复制进去，布局如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;LinearLayout xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot; android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;wrap_content&quot; android:background=&quot;@drawable/title_bg&quot;&gt; &lt;!--标题栏布局--&gt; &lt;Button android:id=&quot;@+id/title_back&quot; android:layout_width=&quot;wrap_content&quot; android:layout_height=&quot;wrap_content&quot; android:layout_gravity=&quot;center&quot; android:layout_margin=&quot;5dp&quot; android:text=&quot;back&quot; android:textColor=&quot;#fff&quot; android:background=&quot;@drawable/back_bg&quot; /&gt; &lt;TextView android:id=&quot;@+id/title_text&quot; android:layout_width=&quot;0dp&quot; android:layout_weight=&quot;1&quot; android:layout_height=&quot;wrap_content&quot; android:layout_gravity=&quot;center&quot; android:gravity=&quot;center&quot; android:text=&quot;title&quot; android:textColor=&quot;#fff&quot; android:textSize=&quot;24sp&quot; /&gt; &lt;Button android:id=&quot;@+id/title_edit&quot; android:layout_width=&quot;wrap_content&quot; android:layout_height=&quot;wrap_content&quot; android:layout_gravity=&quot;center&quot; android:layout_margin=&quot;5dp&quot; android:text=&quot;edit&quot; android:textColor=&quot;#fff&quot; android:background=&quot;@drawable/edit_bg&quot; /&gt;&lt;/LinearLayout&gt;dp一般用来表示空间大小和间距。然后新建一个类去实现标题栏的一些点击功能：12345678910111213141516public class TitleLayout extends LinearLayout &#123; public TitleLayout(Context context, @Nullable AttributeSet attrs) &#123; super(context, attrs); //动态加载标题栏布局 第一个参数是要加载的布局，第二个是root，即父布局 LayoutInflater.from(context).inflate(R.layout.title, this); Button backButton = findViewById(R.id.title_back); Button editButton = findViewById(R.id.title_edit); backButton.setOnClickListener(view -&gt; &#123; ((Activity) getContext()).finish(); &#125;); editButton.setOnClickListener(view -&gt; &#123; Toast.makeText(getContext(), "点击了编辑按钮", Toast.LENGTH_SHORT).show(); &#125;); &#125;&#125;最后需要在主活动里引入自定义布局：1234567891011121314151617&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;LinearLayout xmlns:android="http://schemas.android.com/apk/res/android" xmlns:tools="http://schemas.android.com/tools" android:orientation="vertical" android:layout_width="match_parent" android:layout_height="match_parent" tools:context=".MainActivity"&gt; &lt;!--使用引入布局文件的方式引入--&gt; &lt;!--&lt;include layout="@layout/title" /&gt;--&gt; &lt;!--使用自定义控件方式引入--&gt; &lt;com.joyinclude.TitleLayout android:layout_width="match_parent" android:layout_height="wrap_content"&gt; &lt;/com.joyinclude.TitleLayout&gt;&lt;/LinearLayout&gt;这样就实现了返回键销毁当前Activity，编辑键能够打印文字。列表ListView首先把需要展示的水果图复制到drawable-xhdpi目录里，并创建listview的布局文件activity_list_view.xml：1234567891011121314151617181920&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;LinearLayout xmlns:android="http://schemas.android.com/apk/res/android" android:orientation="vertical" android:layout_width="match_parent" android:layout_height="match_parent"&gt; &lt;com.joyinclude.TitleLayout android:layout_width="match_parent" android:layout_height="wrap_content"&gt; &lt;/com.joyinclude.TitleLayout&gt; &lt;!--listview的简单用法--&gt; &lt;ListView android:id="@+id/list_view" android:layout_width="match_parent" android:layout_height="wrap_content"&gt; &lt;/ListView&gt;&lt;/LinearLayout&gt;新建一个实体类分别表示水果名和图片id：123456789101112public class Fruit &#123; private String name; private int imageId; public Fruit(String name, int imageId) &#123; this.name = name; this.imageId = imageId; &#125; //get和set方法省略&#125;添加一个适配器用于进行水果名和图片的展示：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class FruitAdapter extends ArrayAdapter&lt;Fruit&gt; &#123; private int resourceId; class ViewHolder&#123; private ImageView imageView; private TextView nameView; &#125; public FruitAdapter(@NonNull Context context, int textViewResourceId, @NonNull List&lt;Fruit&gt; objects) &#123; super(context, textViewResourceId, objects); resourceId = textViewResourceId; &#125; /** * 该方法在每一个子项加载到屏幕内时使用 * @param position * @param convertView * @param parent * @return */ @NonNull @Override public View getView(int position, @Nullable View convertView, @NonNull ViewGroup parent) &#123; //获取当前item实例 Fruit fruit = getItem(position); View view; ViewHolder viewHolder; //重用view，避免每次加载子项时都重复加载布局 if(convertView == null)&#123; view = LayoutInflater.from(getContext()).inflate(resourceId, parent, false); viewHolder = new ViewHolder(); viewHolder.imageView = view.findViewById(R.id.fruit_image); viewHolder.nameView = view.findViewById(R.id.fruid_name); //将viewHolder存在view中 view.setTag(viewHolder); &#125;else&#123; view = convertView; viewHolder = (ViewHolder) view.getTag(); &#125; //使用内部类持有imageview和textview，放在view中，避免每次重新findviewbyid //ImageView fruitImage = view.findViewById(R.id.fruit_image); viewHolder.imageView.setImageResource(fruit.getImageId()); //TextView fruitName = view.findViewById(R.id.fruid_name); viewHolder.nameView.setText(fruit.getName()); return view; &#125;&#125;界面展示代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class ListViewActivity extends AppCompatActivity &#123; private String[] data = &#123;"Apple","Banana","Orange","Watermelon", "pear","Grape","Pineapple","Strawberry","Cherry","Mongo", "Apple","Banana","Orange","Watermelon", "pear","Grape","Pineapple","Strawberry","Cherry","Mongo"&#125;; private List&lt;Fruit&gt; fruitList = new ArrayList&lt;&gt;(); @Override protected void onCreate(@Nullable Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); ActionBar actionBar = getSupportActionBar(); if (actionBar != null) &#123; actionBar.hide(); &#125; setContentView(R.layout.activity_list_view);// ArrayAdapter&lt;String&gt; adapter = new ArrayAdapter&lt;&gt;(ListViewActivity.this, android.R.layout.simple_list_item_1, data); ListView listView = findViewById(R.id.list_view); initFruitList(); FruitAdapter adapter = new FruitAdapter(ListViewActivity.this, R.layout.list_item, fruitList); listView.setAdapter(adapter); listView.setOnItemClickListener(((adapterView,view,i,l) -&gt; &#123; Fruit fruit = fruitList.get(i); Toast.makeText(ListViewActivity.this, fruit.getName(), Toast.LENGTH_SHORT).show(); &#125;)); &#125; private void initFruitList()&#123; for (int i = 0; i &lt; 2; i++) &#123; Fruit apple = new Fruit("Apple",R.drawable.apple_pic); fruitList.add(apple); Fruit banana = new Fruit("Banana",R.drawable.banana_pic); fruitList.add(banana); Fruit orange = new Fruit("Orange",R.drawable.orange_pic); fruitList.add(orange); Fruit watermelon = new Fruit("Watermelon",R.drawable.watermelon_pic); fruitList.add(watermelon); Fruit pear = new Fruit("Pear",R.drawable.pear_pic); fruitList.add(pear); Fruit grape = new Fruit("Grape",R.drawable.grape_pic); fruitList.add(grape); Fruit pineapple = new Fruit("Pineapple",R.drawable.pineapple_pic); fruitList.add(pineapple); Fruit strawberry = new Fruit("Strawberry",R.drawable.strawberry_pic); fruitList.add(strawberry); Fruit cherry = new Fruit("Cherry",R.drawable.cherry_pic); fruitList.add(cherry); Fruit mongo = new Fruit("Mongo",R.drawable.mango_pic); fruitList.add(mongo); &#125; &#125;&#125;效果如图：RecyclerViewRecyclerView是一个效率更高，并且功能更加强大的滚动控件，需要在app/build.gradle的dependencies闭包里添加支持：1implementation 'com.android.support:recyclerview-v7:27.1.1'注意：在API 26以后，build.gradle依赖里的compile改成了implementation，testCompile改成了testImplementation。同时，如果想要使用lombok的时候，android闭包下的defaultConfig里还需要加入12&gt; javaCompileOptions &#123; annotationProcessorOptions &#123; includeCompileClasspath = true &#125; &#125;&gt;首先创建一个简单的纵向布局activity_cycler_view.xml：1234567891011121314151617&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;LinearLayout xmlns:android="http://schemas.android.com/apk/res/android" android:orientation="vertical" android:layout_width="match_parent" android:layout_height="match_parent"&gt; &lt;com.joyinclude.TitleLayout android:layout_width="match_parent" android:layout_height="wrap_content"&gt; &lt;/com.joyinclude.TitleLayout&gt; &lt;android.support.v7.widget.RecyclerView android:id="@+id/cycler_view" android:layout_width="match_parent" android:layout_height="match_parent"&gt;&lt;/android.support.v7.widget.RecyclerView&gt;&lt;/LinearLayout&gt;并创建与之对应的活动：12345678910111213141516171819202122232425262728293031323334353637383940414243public class CyclerViewActitivy extends AppCompatActivity &#123; private List&lt;Fruit&gt; fruitList = new ArrayList&lt;&gt;(); @Override protected void onCreate(@Nullable Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_cycler_view); ActionBar actionBar = getSupportActionBar(); if (actionBar != null) actionBar.hide(); initFruitList(); RecyclerView recyclerView = findViewById(R.id.cycler_view); LinearLayoutManager linearLayoutManager = new LinearLayoutManager(this); recyclerView.setLayoutManager(linearLayoutManager); FruitCyclerAdapter fruitCyclerAdapter = new FruitCyclerAdapter(fruitList); recyclerView.setAdapter(fruitCyclerAdapter); &#125; private void initFruitList()&#123; for (int i = 0; i &lt; 2; i++) &#123; Fruit apple = new Fruit("Apple",R.drawable.apple_pic); fruitList.add(apple); Fruit banana = new Fruit("Banana",R.drawable.banana_pic); fruitList.add(banana); Fruit orange = new Fruit("Orange",R.drawable.orange_pic); fruitList.add(orange); Fruit watermelon = new Fruit("Watermelon",R.drawable.watermelon_pic); fruitList.add(watermelon); Fruit pear = new Fruit("Pear",R.drawable.pear_pic); fruitList.add(pear); Fruit grape = new Fruit("Grape",R.drawable.grape_pic); fruitList.add(grape); Fruit pineapple = new Fruit("Pineapple",R.drawable.pineapple_pic); fruitList.add(pineapple); Fruit strawberry = new Fruit("Strawberry",R.drawable.strawberry_pic); fruitList.add(strawberry); Fruit cherry = new Fruit("Cherry",R.drawable.cherry_pic); fruitList.add(cherry); Fruit mongo = new Fruit("Mongo",R.drawable.mango_pic); fruitList.add(mongo); &#125; &#125;&#125;创建RecyclerView中每一行数据中，文字和图片的布局为水平：1234567891011121314151617181920&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;LinearLayout xmlns:android="http://schemas.android.com/apk/res/android" android:layout_width="match_parent" android:layout_height="wrap_content"&gt; &lt;!--垂直滚动的布局--&gt; &lt;ImageView android:id="@+id/fruit_image" android:layout_width="wrap_content" android:layout_height="wrap_content" /&gt; &lt;TextView android:id="@+id/fruit_name" android:layout_width="wrap_content" android:layout_height="wrap_content" android:layout_gravity="center_vertical" android:layout_marginLeft="10dp"/&gt;&lt;/LinearLayout&gt;并且创建对应的数据适配器：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public class FruitCyclerAdapter extends RecyclerView.Adapter&lt;FruitCyclerAdapter.ViewHolder&gt; &#123; private List&lt;Fruit&gt; fruitList; @NonNull @Override public ViewHolder onCreateViewHolder(@NonNull ViewGroup parent, int viewType) &#123; //传统纵向滚动布局 View view = LayoutInflater.from(parent.getContext()).inflate(R.layout.list_item, parent, false); //创建viewHolder，将父view传入并对子项每个元素绑定点击事件 ViewHolder viewHolder = new ViewHolder(view); viewHolder.imageView.setOnClickListener(event -&gt; &#123; int position = viewHolder.getAdapterPosition(); Fruit fruit = fruitList.get(position); Toast.makeText(view.getContext(), "iamge:"+fruit.getName(), Toast.LENGTH_SHORT).show(); &#125;); viewHolder.textView.setOnClickListener(event -&gt; &#123; int posotion = viewHolder.getAdapterPosition(); Fruit fruit = fruitList.get(posotion); Toast.makeText(view.getContext(), "name:" + fruit.getName(), Toast.LENGTH_SHORT).show(); &#125;); return viewHolder; &#125; @Override public void onBindViewHolder(@NonNull ViewHolder holder, int position) &#123; //对子项每个元素进行赋值 Fruit fruit = fruitList.get(position); holder.imageView.setImageResource(fruit.getImageId()); holder.textView.setText(fruit.getName()); &#125; @Override public int getItemCount() &#123; //告诉父布局一共有多少元素 return fruitList.size(); &#125; static class ViewHolder extends RecyclerView.ViewHolder&#123; ImageView imageView; TextView textView; public ViewHolder(View itemView) &#123; super(itemView); //获取垂直滚动元素 imageView = itemView.findViewById(R.id.fruit_image); textView = itemView.findViewById(R.id.fruit_name); &#125; &#125; public FruitCyclerAdapter(List&lt;Fruit&gt; fruitList) &#123; this.fruitList = fruitList; &#125;&#125;运行软件效果如图：点击图片和文字能够输出不同的文字，ListView实现方式则是直接注册的OnItemClickListener，无法对每一个item里的每一个元素做出响应，虽然也可以实现，但是比较复杂。相比之下RecylerView对于每一个item的操作都是注册到view上的。RecyclerView还可以实现横向滚动的列表，此时每一个item里面的元素就是垂直摆放了，调整list_item.xml的代码：12345678910111213141516171819202122232425&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;LinearLayout xmlns:android="http://schemas.android.com/apk/res/android" android:orientation="vertical" android:layout_width="100dp" android:layout_height="wrap_content"&gt; &lt;!--横向滚动的布局--&gt; &lt;ImageView android:id="@+id/fruit_image" android:layout_width="wrap_content" android:layout_height="wrap_content" android:layout_gravity="center_horizontal" /&gt; &lt;TextView android:id="@+id/fruit_name" android:layout_width="wrap_content" android:layout_height="wrap_content" android:layout_gravity="center_horizontal" android:layout_marginTop="10dp"/&gt;&lt;/LinearLayout&gt;使用center_vertical将图片和文字都水平居中，并且使用layout_marginTop让文字和图片之间保持10dp的间距。然后修改CyclerViewActivity里的代码，调整LinearLayoutManager里的orientation属性为水平：1234LinearLayoutManager linearLayoutManager = new LinearLayoutManager(this);//设置横向滚动linearLayoutManager.setOrientation(LinearLayoutManager.HORIZONTAL);recyclerView.setLayoutManager(linearLayoutManager);效果如下：还可以实现瀑布滚动效果，首先调整list_item.xml：1234567891011121314151617181920212223242526&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;LinearLayout xmlns:android="http://schemas.android.com/apk/res/android" android:orientation="vertical" android:layout_width="match_parent" android:layout_height="wrap_content" android:layout_margin="5dp" &gt; &lt;!--瀑布流布局--&gt; &lt;ImageView android:id="@+id/fruit_image" android:layout_width="wrap_content" android:layout_height="wrap_content" android:layout_gravity="center_horizontal" /&gt; &lt;TextView android:id="@+id/fruit_name" android:layout_width="wrap_content" android:layout_height="wrap_content" android:layout_gravity="left" android:layout_marginTop="10dp"/&gt;&lt;/LinearLayout&gt;每一项布局设定为match_parent用于自动适配，layout_margin保证每个水果之间有一定间距，文本用于居左对齐，因为待会要进行名称改造，名称比较长时就能看到瀑布的效果了。修改活动类里的代码：123RecyclerView recyclerView = findViewById(R.id.cycler_view);StaggeredGridLayoutManager staggeredGridLayoutManager = new StaggeredGridLayoutManager(3, StaggeredGridLayoutManager.VERTICAL);recyclerView.setLayoutManager(staggeredGridLayoutManager);初始化数据时生成随机长度水果名称:12345678910111213141516171819202122232425262728293031323334private void initFruitList()&#123; for (int i = 0; i &lt; 2; i++) &#123; Fruit apple = new Fruit(getRandomLengthName("Apple"),R.drawable.apple_pic); fruitList.add(apple); Fruit banana = new Fruit(getRandomLengthName("Banana"),R.drawable.banana_pic); fruitList.add(banana); Fruit orange = new Fruit(getRandomLengthName("Orange"),R.drawable.orange_pic); fruitList.add(orange); Fruit watermelon = new Fruit(getRandomLengthName("Watermelon"),R.drawable.watermelon_pic); fruitList.add(watermelon); Fruit pear = new Fruit(getRandomLengthName("Pear"),R.drawable.pear_pic); fruitList.add(pear); Fruit grape = new Fruit(getRandomLengthName("Grape"),R.drawable.grape_pic); fruitList.add(grape); Fruit pineapple = new Fruit(getRandomLengthName("Pineapple"),R.drawable.pineapple_pic); fruitList.add(pineapple); Fruit strawberry = new Fruit(getRandomLengthName("Strawberry"),R.drawable.strawberry_pic); fruitList.add(strawberry); Fruit cherry = new Fruit(getRandomLengthName("Cherry"),R.drawable.cherry_pic); fruitList.add(cherry); Fruit mongo = new Fruit(getRandomLengthName("Mongo"),R.drawable.mango_pic); fruitList.add(mongo); &#125;&#125;private String getRandomLengthName(String name)&#123; Random random = new Random(); int length = random.nextInt(20) + 1; StringBuilder stringBuilder = new StringBuilder(); for (int i = 0; i &lt; length; i++) &#123; stringBuilder.append(name); &#125; return stringBuilder.toString();&#125;效果如下：界面最佳实践环境：Android Studio 3.4Windows 10调试机：一加 6 Android 9创建一个项目，其中app/build.gradle如下：123456789101112131415161718192021222324252627282930313233apply plugin: 'com.android.application'android &#123; compileSdkVersion 28 defaultConfig &#123; applicationId "com.joy.practice" minSdkVersion 15 targetSdkVersion 28 versionCode 1 versionName "1.0" testInstrumentationRunner "android.support.test.runner.AndroidJUnitRunner" &#125; buildTypes &#123; release &#123; minifyEnabled false proguardFiles getDefaultProguardFile('proguard-android-optimize.txt'), 'proguard-rules.pro' &#125; &#125; compileOptions &#123; sourceCompatibility JavaVersion.VERSION_1_8 targetCompatibility JavaVersion.VERSION_1_8 &#125;&#125;dependencies &#123; implementation fileTree(dir: 'libs', include: ['*.jar']) implementation 'com.android.support:appcompat-v7:28.0.0' implementation 'com.android.support:recyclerview-v7:28.0.0' implementation 'com.android.support.constraint:constraint-layout:1.1.3' testImplementation 'junit:junit:4.12' androidTestImplementation 'com.android.support.test:runner:1.0.2' androidTestImplementation 'com.android.support.test.espresso:espresso-core:3.0.2'&#125;在android studio里，可以对某个png右击，然后点击creat 9-patch file，即可以对图片进行定制，例如聊天气泡是可以随着文字的增多而进行拉伸的，如图：其中四周的黑色边即代表需要拉伸的部分，然后将该图片放到res/drawable-xhdpi目录里。创建聊天界面布局：1234567891011121314151617181920212223242526272829303132333435363738394041&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;LinearLayout xmlns:android="http://schemas.android.com/apk/res/android" android:orientation="vertical" android:layout_width="match_parent" android:layout_height="match_parent" android:background="#d8e0e8"&gt; &lt;com.joy.practice.TitleLayout android:layout_width="match_parent" android:layout_height="wrap_content"&gt; &lt;/com.joy.practice.TitleLayout&gt; &lt;android.support.v7.widget.RecyclerView android:id="@+id/msg_view" android:layout_width="match_parent" android:layout_height="0dp" android:layout_weight="1"&gt;&lt;/android.support.v7.widget.RecyclerView&gt; &lt;LinearLayout android:layout_width="match_parent" android:layout_height="wrap_content"&gt; &lt;EditText android:id="@+id/input_text" android:layout_weight="1" android:layout_width="0dp" android:layout_height="wrap_content" android:hint="type something here" android:maxLines="2" /&gt; &lt;Button android:layout_width="wrap_content" android:layout_height="wrap_content" android:text="Send" android:textAllCaps="false" android:id="@+id/send" /&gt; &lt;/LinearLayout&gt;&lt;/LinearLayout&gt;每一条聊天消息的布局：1234567891011121314151617181920212223242526272829303132333435363738&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;LinearLayout xmlns:android="http://schemas.android.com/apk/res/android" android:orientation="vertical" android:layout_width="match_parent" android:layout_height="wrap_content" android:padding="10dp"&gt; &lt;LinearLayout android:id="@+id/left_layout" android:layout_width="wrap_content" android:layout_height="wrap_content" android:layout_gravity="left" android:background="@drawable/message_left"&gt; &lt;TextView android:id="@+id/left_msg" android:layout_width="wrap_content" android:layout_height="wrap_content" android:layout_gravity="center" android:layout_margin="10dp" android:textColor="#fff" /&gt; &lt;/LinearLayout&gt; &lt;LinearLayout android:id="@+id/right_layout" android:layout_width="wrap_content" android:layout_height="wrap_content" android:layout_gravity="right" android:background="@drawable/message_right"&gt; &lt;TextView android:id="@+id/right_msg" android:layout_width="wrap_content" android:layout_height="wrap_content" android:layout_margin="10dp" /&gt; &lt;/LinearLayout&gt;&lt;/LinearLayout&gt;其中title-layout就是上节中有回退和编辑按钮的标题栏，新建一个基类活动用于隐藏系统自带标题栏，以后其他类都可以继承这个基类。123456789public class BaseActivity extends AppCompatActivity &#123; @Override protected void onCreate(@Nullable Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); ActionBar actionBar = getSupportActionBar(); if(actionBar != null) actionBar.hide(); &#125;&#125;消息实体类：12345678910111213141516171819202122232425262728293031public class Msg &#123; public static final int TYPE_RECEIVED = 0; public static final int TYPE_SENT = 1; private String content; private int type; public Msg(String content, int type) &#123; this.content = content; this.type = type; &#125; public String getContent() &#123; return content; &#125; public void setContent(String content) &#123; this.content = content; &#125; public int getType() &#123; return type; &#125; public void setType(int type) &#123; this.type = type; &#125;&#125;创建工具类判断是否是空字符串：1234567public class StringUtils &#123; public static boolean isEmpty(String str)&#123; return str == null || str.length() == 0; &#125;&#125;创建一个主活动：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class MainActivity extends BaseActivity &#123; private List&lt;Msg&gt; msgList = new ArrayList&lt;&gt;(); private EditText inputText; private Button send; private RecyclerView msgRecyclerView; private MsgAdapter msgAdapter; @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); initMsg(); inputText = findViewById(R.id.input_text); send = findViewById(R.id.send); msgRecyclerView = findViewById(R.id.msg_view); LinearLayoutManager layoutManager = new LinearLayoutManager(this); msgRecyclerView.setLayoutManager(layoutManager); msgAdapter = new MsgAdapter(msgList); msgRecyclerView.setAdapter(msgAdapter); send.setOnClickListener(view -&gt; &#123; String content = inputText.getText().toString(); if (StringUtils.isEmpty(content)) &#123; Toast.makeText(msgRecyclerView.getContext(), "不可发送空白消息", Toast.LENGTH_SHORT).show(); &#125; else &#123; Msg msg = new Msg(content, Msg.TYPE_SENT); msgList.add(msg); //发送消息插入通知 msgAdapter.notifyItemInserted(msgList.size() - 1); //将新元素插入到队尾 msgRecyclerView.scrollToPosition(msgList.size() - 1); inputText.setText(""); &#125; &#125;); &#125; private void initMsg() &#123; Msg msg1 = new Msg("我爱萌儿", Msg.TYPE_SENT); msgList.add(msg1); Msg msg2 = new Msg("我也爱你", Msg.TYPE_RECEIVED); msgList.add(msg2); Msg msg3 = new Msg("我想娶你", Msg.TYPE_SENT); msgList.add(msg3); &#125;&#125;效果如图：]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis和Zookeeper分布式锁实现]]></title>
    <url>%2FRedis%E5%92%8CZookeeper%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AE%9E%E7%8E%B0.html</url>
    <content type="text"><![CDATA[简述锁是一种同步机制，保证了多线程的有序竞争和运行，而在分布式的场景下，两个应用程序同样会有对于公共变量的访问和操作行为，对于分布式锁，常用的有三种方案：数据库方式，使用select * from table where column = para for update加排他锁;中间件缓存，例如redis的setnx+lua脚本或者set key value ps milliseconds nx;zookeeper临时节点。分布式锁要满足以下几个条件：互斥；不死锁；容错；唯一解锁。Redis本机环境：Windows 版RedisIDE：IDEA 2019.1.1Jedis引入pom:12345&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt;&lt;/dependency&gt;要注意的是，尽量保证加锁和释放锁时的原子操作，以及value的唯一性和value与会话的匹配：1234567891011121314151617181920212223242526272829303132333435363738394041424344public class RedisPool &#123; private static final String LOCK_SUCCESS = "OK"; private static final String SET_IF_NOT_EXISTS = "NX"; private static final String SET_WITH_EXPIRE_TIME = "PX"; private static final Long RELEASE_SUCCESS = 1L; /** * @description 获取分布式锁 * @param jedis * @param lockKey * @param requestId * @param expireTime * @return */ public static boolean tryGetDistributedLock(Jedis jedis,String lockKey,String requestId,int expireTime)&#123; /** * lockKey作为key,requestId作为value用于区分加锁的请求，可以使用不重复的字符串例如UUID或者GUID * NX表示该key不存在时才会进行set操作 * PX表示设置过期时间，具体值由最后一个int值决定 * jedis.setnx()没有提供直接设置超时的操作，如果锁没有释放会导致死锁 * 这里尽量使用一行操作来set，如果多个操作无法保证原子性 */ String result = jedis.set(lockKey, requestId, SET_IF_NOT_EXISTS, SET_WITH_EXPIRE_TIME, expireTime); return LOCK_SUCCESS.equals(result); &#125; /** * @description 释放锁 * @param jedis * @param lockKey * @param requestId * @return */ public static boolean releaseDistributedLock(Jedis jedis,String lockKey,String requestId)&#123; //将所有的释放和获取操作交由一行Lua脚本操作完成，保证原子操作 //eval命令执行Lua代码的时候，Lua代码将被当成一个命令去执行，并且直到eval命令执行完成，Redis才会执行其他命令 //如果使用先get lockKey的值，然后比对requestId的方式判断是否同一请求，可能导致删除的是其他requestID String script = "if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end"; Object result = jedis.eval(script, Collections.singletonList(lockKey), Collections.singletonList(requestId)); return RELEASE_SUCCESS.equals(result); &#125;&#125;Redisson使用Jedis只能满足单机redis的场景，对于redis集群，如果出现类似于主备切换等场景，可能会导致锁丢失。Redis的作者提出了Redlock的实现：获取当前unix时间，单位为millisecond；假如有5个redis节点，使用相同的key和具有唯一性的value获取锁；客户端使用当前时间减去第一步里的时间就是获取锁的时间，只有当N/2+1的节点都获取到锁并且使用时间小于失效时间时表示获取成功；如果获取锁超时或者没有获取到锁，应该在所有的节点进行解锁操作。Redlock类似于Reetrantlock，Redisson封装了Redlock算法，使用eval执行lua脚本。Redisson提供了几种集群模式：单机SingleServer，ClusterServer，Maste/SlaveServer，SentinelServer：引入pom:12345&lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson&lt;/artifactId&gt; &lt;version&gt;3.10.6&lt;/version&gt;&lt;/dependency&gt;代码：123456789Config config = new Config();//本机只有一个redis所以使用单机模式config.useSingleServer().setAddress("redis://127.0.0.1:6379");Redisson redisson = (Redisson) Redisson.create(config);RLock lock = redisson().getLock("test");lock.lock(60000L, TimeUnit.SECONDS);lock.unlock();Zookeeper本机环境：Zookeeper 3.4.10IDE：IDEA 2019.1.1首先启动zk，然后启动zkCli，创建一个父节点：1234[zk: localhost:2181(CONNECTED) 9] create /LOCKS 00Created /LOCKS[zk: localhost:2181(CONNECTED) 10] ls /LOCKS[]Zookeeper引入zk原生jar包，还有辅助的lombok包：1234567891011&lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.10&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.8.16&lt;/version&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt;zookeeper分布式锁的原理是：客户端在父节点下创建临时子节点，然后获取所有子节点，判断当前创建的临时节点是否是最小节点，如果是最小节点即表示获取锁，如果不是最小节点则监听当前节点的前一个节点，如果监听到前一节点删除则当前客户端获取到锁*。使用临时节点可以避免死锁，这里使用countDownLatch限制当前只有一个客户端连接zk：12345678910111213141516171819202122public class ZookeeperClient &#123; private static int sessionTimeout = 5000; public static ZooKeeper getInstance() throws IOException, InterruptedException &#123; final CountDownLatch countDownLatch = new CountDownLatch(1);//countDpwnlatch表示需要等待的线程数，直到该数值变为0才会真正执行任务 ZooKeeper zooKeeper = new ZooKeeper("127.0.0.1:2181", sessionTimeout , new Watcher() &#123; @Override public void process(WatchedEvent watchedEvent) &#123; if(watchedEvent.getState() == Event.KeeperState.SyncConnected)&#123; countDownLatch.countDown(); &#125; &#125; &#125;); countDownLatch.await(); return zooKeeper; &#125; public static int getSessionTimeout()&#123; return sessionTimeout; &#125;&#125;然后需要一个监听器监听前一节点是否删除：1234567891011121314public class LockWatcher implements Watcher &#123; private CountDownLatch countDownLatch; public LockWatcher(CountDownLatch countDownLatch) &#123; this.countDownLatch = countDownLatch; &#125; @Override public void process(WatchedEvent watchedEvent) &#123; if (watchedEvent.getType() == Event.EventType.NodeDeleted) &#123; countDownLatch.countDown(); &#125; &#125;&#125;获取锁的代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071@Slf4jpublic class DistributedLock &#123; /** * zookeeper分布式锁原理： * 节点有序性：节点可以设置为有序的，例如node-1,node-2等 * 临时节点：超时以后自动删除避免死锁 * 事件监听：节点变化时客户端可以收到 */ private static final String ROOT_LOCK = "/LOCKS"; private ZooKeeper zooKeeper; private int sessionTimeout; private String lockId; private final static byte[] data = &#123;1, 2&#125;; private CountDownLatch countDownLatch = new CountDownLatch(1); public DistributedLock() throws IOException, InterruptedException &#123; this.zooKeeper = ZookeeperClient.getInstance(); this.sessionTimeout = ZookeeperClient.getSessionTimeout(); &#125; public boolean tryGetDistributedLock() &#123; try &#123; //这里的四个参数分别是：路径，保存内容，权限，临时有序节点 lockId = zooKeeper.create(ROOT_LOCK + "/", data, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL); log.info("当前线程:&#123;&#125; 创建节点,id=&#123;&#125;", Thread.currentThread().getName(), lockId); List&lt;String&gt; childrenList = zooKeeper.getChildren(ROOT_LOCK, true); childrenList.sort(String::compareTo); for (int i = 0; i &lt; childrenList.size(); i++) &#123; childrenList.set(i, ROOT_LOCK + "/" + childrenList.get(i)); &#125; String first = childrenList.get(0); if (lockId.equals(first)) &#123; log.info("当前线程:&#123;&#125; 获取锁成功,节点为:&#123;&#125;", Thread.currentThread().getName(), lockId); return true; &#125; //获取当前节点前的节点集合 List&lt;String&gt; lessThanLockIDList = childrenList.subList(0, childrenList.indexOf(lockId)); if (!lessThanLockIDList.isEmpty()) &#123; String preLockID = lessThanLockIDList.get(lessThanLockIDList.size() - 1); //监听上一节点变化,如果删除在监听器里会将countDownLatch减1，这样就能执行挂起的客户端 zooKeeper.exists(preLockID, new LockWatcher(countDownLatch)); //使用countDownLatch闭锁来挂起当前线程直到lockWatcher监听到上一节点的变化countDown了或者超时sessionTimeout以后 countDownLatch.await(sessionTimeout, TimeUnit.MILLISECONDS); log.info("当前线程:&#123;&#125; 获取锁成功,节点为:&#123;&#125;", Thread.currentThread().getName(), lockId); &#125; return true; &#125; catch (Exception e) &#123; log.error("获取锁异常",e); &#125; return false; &#125; public boolean releaseDistributedLock()&#123; log.info("当前线程:&#123;&#125; 将要释放锁:&#123;&#125;", Thread.currentThread().getName(), lockId); try &#123; zooKeeper.delete(lockId, -1); log.info("当前线程:&#123;&#125; 释放锁:&#123;&#125; 成功", Thread.currentThread().getName(), lockId); return true; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (KeeperException e) &#123; e.printStackTrace(); &#125; return false; &#125;&#125;测试类：123456789101112131415161718192021222324public static void main(String[] args) &#123; final CountDownLatch countDownLatch = new CountDownLatch(10); Random random = new Random(); for (int i = 0; i &lt; 10; i++) &#123; new Thread(() -&gt; &#123; DistributedLock distributedLock = null; try &#123; distributedLock = new DistributedLock(); countDownLatch.countDown(); countDownLatch.await(); distributedLock.tryGetDistributedLock(); Thread.sleep(random.nextInt(500)); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; if (distributedLock != null) &#123; distributedLock.releaseDistributedLock(); &#125; &#125; &#125;).start(); &#125;&#125;执行方法可以看到结果：123456789101112131415161717:55:03.680 [Thread-0] INFO com.joy.lock.zookeeper.DistributedLock - 当前线程:Thread-0 创建节点,id=/LOCKS/000000015717:55:03.680 [Thread-7] INFO com.joy.lock.zookeeper.DistributedLock - 当前线程:Thread-7 创建节点,id=/LOCKS/000000016317:55:03.680 [Thread-5] INFO com.joy.lock.zookeeper.DistributedLock - 当前线程:Thread-5 创建节点,id=/LOCKS/000000015617:55:03.680 [Thread-3] INFO com.joy.lock.zookeeper.DistributedLock - 当前线程:Thread-3 创建节点,id=/LOCKS/000000015417:55:03.680 [Thread-2] INFO com.joy.lock.zookeeper.DistributedLock - 当前线程:Thread-2 创建节点,id=/LOCKS/000000016117:55:03.680 [Thread-8] INFO com.joy.lock.zookeeper.DistributedLock - 当前线程:Thread-8 创建节点,id=/LOCKS/000000015517:55:03.680 [Thread-1] INFO com.joy.lock.zookeeper.DistributedLock - 当前线程:Thread-1 创建节点,id=/LOCKS/000000016217:55:03.680 [Thread-6] INFO com.joy.lock.zookeeper.DistributedLock - 当前线程:Thread-6 创建节点,id=/LOCKS/000000015917:55:03.680 [Thread-4] INFO com.joy.lock.zookeeper.DistributedLock - 当前线程:Thread-4 创建节点,id=/LOCKS/000000016017:55:03.680 [Thread-9] INFO com.joy.lock.zookeeper.DistributedLock - 当前线程:Thread-9 创建节点,id=/LOCKS/000000015817:55:03.691 [Thread-3] INFO com.joy.lock.zookeeper.DistributedLock - 当前线程:Thread-3 获取锁成功,节点为:/LOCKS/000000015417:55:03.929 [Thread-3] INFO com.joy.lock.zookeeper.DistributedLock - 当前线程:Thread-3 将要释放锁:/LOCKS/000000015417:55:03.935 [Thread-8] INFO com.joy.lock.zookeeper.DistributedLock - 当前线程:Thread-8 获取锁成功,节点为:/LOCKS/000000015517:55:03.936 [Thread-3] INFO com.joy.lock.zookeeper.DistributedLock - 当前线程:Thread-3 释放锁:/LOCKS/0000000154 成功17:55:04.106 [Thread-8] INFO com.joy.lock.zookeeper.DistributedLock - 当前线程:Thread-8 将要释放锁:/LOCKS/000000015517:55:04.108 [Thread-8] INFO com.joy.lock.zookeeper.DistributedLock - 当前线程:Thread-8 释放锁:/LOCKS/0000000155 成功//...省略后面日志Curator当然apache已经封装好了分布式锁的实现，需要引入Curator的jar包：1234567891011&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-framework&lt;/artifactId&gt; &lt;version&gt;2.12.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;2.12.0&lt;/version&gt;&lt;/dependency&gt;Java代码比较简单：12345678910111213141516171819202122232425262728@Slf4jpublic class CuratorDistributedLock &#123; private static final String ZK_ADDRESS = "127.0.0.1:2181"; private static final String ROOT_LOCK = "/LOCKS"; static CuratorFramework client = CuratorFrameworkFactory.newClient(ZK_ADDRESS, new RetryNTimes(10, 500)); static InterProcessMutex lock = new InterProcessMutex(client, ROOT_LOCK); public static void tryGetDistributedLock() &#123; try &#123; if (lock.acquire(10 * 10000, TimeUnit.MILLISECONDS)) &#123; log.info("当前线程:&#123;&#125;获取锁",Thread.currentThread().getName()); Thread.sleep(5000L); CuratorDistributedLock.releaseDistributedLock(); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; public static void releaseDistributedLock() throws Exception &#123; log.info("当前线程:&#123;&#125;释放锁",Thread.currentThread().getName()); lock.release(); &#125;&#125;测试类如下：123456789101112131415public static void main(String[] args) &#123; final CountDownLatch countDownLatch = new CountDownLatch(3); client.start(); for (int i = 0; i &lt; 3; i++) &#123; new Thread(() -&gt; &#123; countDownLatch.countDown(); try &#123; countDownLatch.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; CuratorDistributedLock.tryGetDistributedLock(); &#125;).start(); &#125; &#125;日志如下：12345618:04:55.467 [Thread-2] INFO com.joy.lock.zookeeper.CuratorDistributedLock - 当前线程:Thread-2获取锁18:05:00.468 [Thread-2] INFO com.joy.lock.zookeeper.CuratorDistributedLock - 当前线程:Thread-2释放锁18:05:00.478 [Thread-1] INFO com.joy.lock.zookeeper.CuratorDistributedLock - 当前线程:Thread-1获取锁18:05:05.479 [Thread-1] INFO com.joy.lock.zookeeper.CuratorDistributedLock - 当前线程:Thread-1释放锁18:05:05.484 [Thread-3] INFO com.joy.lock.zookeeper.CuratorDistributedLock - 当前线程:Thread-3获取锁18:05:10.485 [Thread-3] INFO com.joy.lock.zookeeper.CuratorDistributedLock - 当前线程:Thread-3释放锁在程序运行中，可以在zkcli中执行ls /LOCKS随时看临时子节点的存在。参考https://blog.csdn.net/qq_26857649/article/details/82383853阿飞的博客：https://mp.weixin.qq.com/s/XoXcqpehhXSQlRxgCBtDcwhttps://mp.weixin.qq.com/s/PnlPgqfVXqJmN26vvGp5MA]]></content>
      <categories>
        <category>编程技术</category>
      </categories>
      <tags>
        <tag>分布式锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自定义spring-boot-starter]]></title>
    <url>%2F%E8%87%AA%E5%AE%9A%E4%B9%89spring-boot-starter.html</url>
    <content type="text"><![CDATA[简述随着Spring Boot的流行，身为一个Java程序员怎么可以不会使用Spring-Boot-Starter呢？Spring Boot的自动装配原理是其核心注解@EnableAutoConfiguration里的@Import导入AutoConfigurationImportSelector.class，从而通过该类中SpringFactoriesLoader.loadFactoryNames方法扫描具有META-INF/spring.factories的jar包实现自动装配。代码演示需要引入如下依赖：12345678910111213&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-autoconfigure&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;/dependencies&gt;注意：spring boot版本不一致可能会导致问题。首先定义一个配置类用于接收配置的参数类，“joy.hello”是prefix的值，代表获取joy.hello的值放入该类：123456789101112131415@ConfigurationProperties("joy.hello")public class HelloServiceProperties &#123; private static final String MSG = "world"; private String msg = MSG; public String getMsg() &#123; return msg; &#125; public void setMsg(String msg) &#123; this.msg = msg; &#125;&#125;接下来模拟一个能自动装配的bean：12345678910111213141516public class HelloService &#123; private String msg; public void sayHello()&#123; System.out.printf("hello,%s",this.msg); &#125; public String getMsg() &#123; return msg; &#125; public void setMsg(String msg) &#123; this.msg = msg; &#125;&#125;该类的作用其实可以理解为RedisTemplate一类的bean。最后一步，也是最重要的一步，就是开启配置类并且指定其初始化条件：12345678910111213141516171819@Configuration@EnableConfigurationProperties(HelloServiceProperties.class)@ConditionalOnClass(HelloService.class)@ConditionalOnProperty(prefix = "joy.hello",value = "enabled",matchIfMissing = true,h)public class HelloServiceAutoConfiguration &#123; @Autowired private HelloServiceProperties helloServiceProperties; @Bean @ConditionalOnMissingBean(HelloService.class) public HelloService helloService()&#123; HelloService helloService = new HelloService(); helloService.setMsg(helloServiceProperties.getMsg()); return helloService; &#125;&#125;首先，@Configuration表示会将该类作为一个spring的配置类，@EnableConfigurationProperties会开启对注解配置bean的支持，不然@ConfigurationProperties会报错。@ConditionalOnClass表示当项目中存在HelloService.class的时候才会自动装配，@ConditionalOnProperty表示去判断joy.hello.enabled的值，如果为空，则返回true(matchIfMissing控制)，如果不为空，则会去和havingValue的值比较，如果相当返回true否则为false。最后，我们需要注册到META-INF/spring.factories里，内容如下：org.springframework.boot.autoconfigure.EnableAutoConfiguration=\ com.joy.autoconfigure.HelloServiceAutoConfiguration将项目打成jar包，新建一个spring boot项目，引入我们自定义的starter，然后在配置文件里即可定义joy.hello.msg的值：123joy: hello: msg: liuhuijun启动该spring boot的启动类：12345678910111213141516@SpringBootApplicationpublic class MyBlogApplication implements CommandLineRunner &#123; @Autowired HelloService helloService; public static void main(String[] args) &#123; SpringApplication.run(MyBlogApplication.class, args); &#125; @Override public void run(String... args) throws Exception &#123; helloService.sayHello(); &#125;&#125;即可看到我们配置的值。总结官方推荐：如果是spring官方包，推荐命名为spring-boot-starter-xxx的形式；如果是第三方包，推荐命名为xxx-spring-boot-starter的形式，例如：mybatis-spring-boot-starter。类似mybatis等的自动装配，跟上面代码类似：12345678910111213141516171819202122232425262728293031@Configuration@ConditionalOnClass(&#123;SqlSessionFactory.class, SqlSessionFactoryBean.class&#125;)@ConditionalOnBean(&#123;DataSource.class&#125;)@EnableConfigurationProperties(&#123;MybatisProperties.class&#125;)@AutoConfigureAfter(&#123;DataSourceAutoConfiguration.class&#125;)public class MybatisAutoConfiguration &#123; private static final Logger logger = LoggerFactory.getLogger(MybatisAutoConfiguration.class); private final MybatisProperties properties; private final Interceptor[] interceptors; private final ResourceLoader resourceLoader; private final DatabaseIdProvider databaseIdProvider; private final List&lt;ConfigurationCustomizer&gt; configurationCustomizers; public MybatisAutoConfiguration(MybatisProperties properties, ObjectProvider&lt;Interceptor[]&gt; interceptorsProvider, ResourceLoader resourceLoader, ObjectProvider&lt;DatabaseIdProvider&gt; databaseIdProvider, ObjectProvider&lt;List&lt;ConfigurationCustomizer&gt;&gt; configurationCustomizersProvider) &#123; this.properties = properties; this.interceptors = (Interceptor[])interceptorsProvider.getIfAvailable(); this.resourceLoader = resourceLoader; this.databaseIdProvider = (DatabaseIdProvider)databaseIdProvider.getIfAvailable(); this.configurationCustomizers = (List)configurationCustomizersProvider.getIfAvailable(); &#125; @PostConstruct public void checkConfigFileExists() &#123; if (this.properties.isCheckConfigLocation() &amp;&amp; StringUtils.hasText(this.properties.getConfigLocation())) &#123; Resource resource = this.resourceLoader.getResource(this.properties.getConfigLocation()); Assert.state(resource.exists(), "Cannot find config location: " + resource + " (please add config file or check your Mybatis configuration)"); &#125; &#125; //...省略大部分方法 &#125;]]></content>
      <categories>
        <category>编程技术</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java实体类转Json的小技巧]]></title>
    <url>%2FJava%E5%AE%9E%E4%BD%93%E7%B1%BB%E8%BD%ACJson%E7%9A%84%E5%B0%8F%E6%8A%80%E5%B7%A7.html</url>
    <content type="text"><![CDATA[简介Google的Gson和Alibaba的FastJson都是常用的用于将实体类或者容器转化为json字符串的工具包，但是这两个工具包都有一个共同的小问题，默认情况下，对于bean里为null的字段，转为json以后会直接丢失不显示。但是有的时候为了方便前端，有时候想当String类型的字段为null时，返回给前端一个空串。Gson首先使用gson的方式来实现，我们需要写一个adapter继承gson的typeadapter来实现我们的转换逻辑。12345678910111213141516171819202122public class StringNullAdpater extends TypeAdapter&lt;String&gt; &#123; @Override public String read(JsonReader reader) throws IOException &#123; if (reader.peek() == JsonToken.NULL) &#123; reader.nextNull(); return ""; &#125; return reader.nextString(); &#125; @Override public void write(JsonWriter writer, String value) throws IOException &#123; // 这里就是序列化为Json字符串的逻辑 if (value == null) &#123; writer.value(""); return; &#125; writer.value(value); &#125;&#125;FastJsonfast的方式较为简单：JSON.toJSONString(pvLog, SerializerFeature.WriteNullStringAsEmpty,SerializerFeature.PrettyFormat)，利用toJSONString的重载方法，通过添加SerializerFeature的枚举参数来实现，枚举具体类型部分参考如下：WriteMapNullValue, //保留值为null的字段 WriteEnumUsingToString, //将枚举类型使用toString()方法输出 WriteNullListAsEmpty, //将空list输出为[] WriteNullStringAsEmpty, //保留null String为输出为&quot;&quot; WriteNullNumberAsZero, //将null Number输出为0 WriteNullBooleanAsFalse, //将null Boolean输出为false SkipTransientField, //不转换瞬态变量（即不参与序列化） SortField, //排序字段 WriteTabAsSpecial, //将tab制表符做转义输出 PrettyFormat, //格式化json数据，更美观地查看 WriteClassName, //序列化时写入类信息 WriteDateUseDateFormat,//是否格式化时间 总结对于spring mvc的项目，我们可以自定义配置Json转换器xxxHttpMessageConverter使得我们加了@ResponseBody的接口可以避免null字段丢失。]]></content>
      <categories>
        <category>编程技术</category>
      </categories>
      <tags>
        <tag>随记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式-单例模式]]></title>
    <url>%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F.html</url>
    <content type="text"><![CDATA[定义Ensure a class has only one instance,and provide a global point of access to it.保证一个类只有一个实例并且提供给目标去访问它。通过给单例类声明一个私有的构造函数，使得其他类无法去对它实例化，只允许自己进行实例化。类图和代码单例模式比较简单，只需要保证在外部不能被实例化，并且在多线程场景下，在多个线程同时获取单例的时候不会返回多个实例。通用代码如下：1234567891011public class Singleton &#123; private static Singleton singleton = new Singleton(); private Singleton() &#123; &#125; public static Singleton getInstance()&#123; return singleton; &#125;&#125;通常情况下，这种方式也被称为“饿汉式”，意思为会首先创建好，无论需不需要。当然还有一种懒汉式：123456789public class Singleton &#123; private static Singleton singleton = null; private Singleton() &#123; &#125; public static Singleton getInstance()&#123; if(singleton == null) singleton = new Singleton(); return sintleton; &#125; &#125;不过懒汉式并不推荐使用，因为假如有两个线程同时进入了getInstance方法，判断singleton为空，那么两个线程各自创建一个实例，就不满足单例模式了。用的最广泛的，就是双重检查锁的方式了，懒加载、效率高、线程安全：12345678910111213141516171819public class Singleton &#123; private static Singleton singletonInstance = null; private Singleton() &#123; &#125; public Singleton getInstance()&#123; if (singletonInstance == null) &#123; synchronized (this)&#123; if(singletonInstance == null)&#123; singletonInstance = new Singleton(); &#125; &#125; &#125; return singletonInstance; &#125;&#125;当然还可以内部类的方式，JVM的类加载机制保证了线程安全，并且延迟加载：12345678910111213public class Singleton &#123; private Singleton() &#123; &#125; public static Singleton getInstance()&#123; return InnerSingleton.INSTANCE; &#125; private static class InnerSingleton&#123; private final static Singleton INSTANCE = new Singleton(); &#125;&#125;在《Java Effective》里还有一种写法，即用枚举的方式，原理和内部类是类似的，只不过不像内部类一样懒加载。1234567891011public enum Singleton &#123; INSTANCE; public void test()&#123; System.out.println("hello"); &#125; public static void main(String[] args) &#123; Singleton.INSTANCE.test(); &#125;&#125;]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式-策略模式]]></title>
    <url>%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F.html</url>
    <content type="text"><![CDATA[定义Define a family of algorithms,encapsulate each one,and make them interchangeable.定义一组算法将每个算法封装起来，并且使他们之间可以互换。策略模式同样可以用来解决责任链模式中一堆if else的问题。类图和代码抽象出一个策略接口声明一个需要做的算法操作，以及一个上下文context用于执行算法。这里我模拟一个原来项目中用到的操作：前端传入订单和支付方式，后端调用对应的策略向微信，支付宝或者银联提供的接口调用支付。为了简化操作，这里的订单我使用支付金额描述（实际项目中订单金额应通过后台系统进行计算），也去除了调用预支付下单接口的操作。策略接口：12345public interface IPayStrategy &#123; void doPay(int money);&#125;分别写策略去实现：123456public class AliPay implements IPayStrategy &#123; @Override public void doPay(int money) &#123; System.out.println("调用了支付宝支付接口，支付"+money+"元"); &#125;&#125;其他微信、银联支付与之类似。策略上下文，用于支付策略的执行：1234567891011121314151617181920public class StrategyContext &#123; private IPayStrategy iStrategy; public StrategyContext(IPayStrategy iStrategy) &#123; this.iStrategy = iStrategy; &#125; public IPayStrategy getiStrategy() &#123; return iStrategy; &#125; public void setiStrategy(IPayStrategy iStrategy) &#123; this.iStrategy = iStrategy; &#125; public void exec(int money)&#123; iStrategy.doPay(money); &#125;&#125;到这里为止，类图中画的这么多就基本完成了，但是很明显有一个问题：由于上下文中只负责调用托管的策略中的支付方法，所以我们还需要创建策略并托管给上下文。所以这里我打算使用一个策略枚举保存策略的种类，使用最简单的工厂方法创建一个策略，这样就避免了我们的业务模块和算法模块有太多的耦合。策略枚举如下：1234567891011121314151617181920public enum StrategyEnums &#123; ALI("ali"), WEIXIN("wx"), UNION("union"); StrategyEnums(String value) &#123; this.value = value; &#125; private String value; public String getValue() &#123; return value; &#125; public void setValue(String value) &#123; this.value = value; &#125;&#125;工厂方法根据枚举类型创建策略：1234567891011121314151617181920public class StrategyFactory &#123; public static IPayStrategy createStrtegy(StrategyEnums strategyEnums)&#123; IPayStrategy IPayStrategy = null; switch (strategyEnums)&#123; case ALI: IPayStrategy = new AliPay(); break; case WEIXIN: IPayStrategy = new WeixinPay(); break; case UNION: IPayStrategy = new UnionPay(); break; default: &#125; return IPayStrategy; &#125;&#125;可能有人会觉得这里同样有大量的case或者if else，但是我的理解是：必要的细节逻辑还是要有的，但是要在业务代码中隐藏起来，细节交由承担该职责的类来处理。现在创建策略和执行策略的上下文都已经完成了，现在我们需要做的步骤是：根据支付参数获得支付枚举，再利用支付枚举创建对应策略，然后委托给上下文执行这个策略。通常情况下，我们的支付参数很可能是一个标志，而不是一个枚举，所以很多情况下我们可能需要一个util或者helper类帮助我们将标志转化为枚举，假如前端传入的是字符串类型参数，工具类可以是：123456789101112public class PayEnumsConvertUtil &#123; StrategyEnums[] strategyEnums = StrategyEnums.values(); public StrategyEnums convert(String type)&#123; for (StrategyEnums strategyEnum : strategyEnums) &#123; if(strategyEnum.getValue().equals(type)) return strategyEnum; &#125; return null; &#125; &#125;可以将标志到枚举的过程放入到门面类中，使得调用方只需要调用，而无需处理任务细节，这里我再加上一个门面模式的类：1234567891011121314public class HandlerFaced &#123; public void pay(PayModel payModel)&#123; StrategyEnums strategyEnum = PayEnumsConvertUtil.convert(payModel.getPayType()); IPayStrategy strategy = StrategyFactory.createStrtegy(strategyEnum); StrategyContext strategyContext = new StrategyContext(strategy); strategyContext.exec(payModel.getMoney()); &#125;&#125;调用方调用就很简单了：1234567891011public class Controller &#123; public static void main(String[] args) &#123; HandlerFaced handlerFaced = new HandlerFaced(); PayModel payModel = new PayModel("ali", 5); handlerFaced.pay(payModel); &#125;&#125;执行结果调用了支付宝支付接口，支付5元 借助Spring策略模式同样可以借助Spring来装一波。首先将所有实现类加上@Component注解（@Service也行，本质差不多）并为注解中value赋值：1234567@Component("ali")public class AliPay implements IPayStrategy &#123; @Override public void doPay(int money) &#123; System.out.println("调用了支付宝支付接口，支付"+money+"元"); &#125;&#125;其他银联支付策略和微信支付策略类似。接下来，我们无需门面类进行委托调用，只需要注入上下文类执行pay方法即可：12345678910111213141516171819202122@Componentpublic class StrategyContext &#123; private final Map&lt;String, IPayStrategy&gt; stringMap = new ConcurrentHashMap&lt;&gt;(); //会自动注入@component里写的字符串作为key，类型为IpayStrategy的beanMap。因为spring里的bean工厂本质上也就是一个ConcurrentHashMap @Autowired public StrategyContext(Map&lt;String,IPayStrategy&gt; stringStringMap) &#123; this.stringMap.clear(); //存入声明的map里 stringStringMap.forEach((k,v) -&gt; this.stringMap.put(k,v)); &#125; public void pay(PayModel payModel)&#123; if(payModel.getPayType() != null &amp;&amp; payModel.getPayType().length() &gt; 0) //将传进来的支付类型作为key，取得对应bean执行即可，在业务中该字符串通常会约定好 stringMap.get(payModel.getPayType()).doPay(payModel.getMoney()); &#125;&#125;测试类如下：12345678910111213141516171819@RunWith(SpringRunner.class)@SpringBootTestpublic class DemoApplicationTests &#123; @Autowired private StrategyContext strategyContext; @Test public void strategyTest()&#123; PayModel payModel = new PayModel("union",10); strategyContext.pay(payModel); PayModel payModel1 = new PayModel("weixin", 20); strategyContext.pay(payModel1); &#125;&#125;执行结果：调用了银联支付接口，支付10元 调用了微信支付接口，支付20元 总结优点：算法自由切换；避免代码臃肿；扩展性良好，很符合开闭原则；缺点：类数量膨胀。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql-数据可靠性保证]]></title>
    <url>%2FMysql-%E6%95%B0%E6%8D%AE%E5%8F%AF%E9%9D%A0%E6%80%A7%E4%BF%9D%E8%AF%81.html</url>
    <content type="text"><![CDATA[说明这篇笔记记载一下mysql中对于数据的保障机制，我们都知道mysql的redo log和binlog的存在保证了数据的完整性和恢复机制。而undo log没有日志文件，只是一个逻辑日志，本质上undo log也是要借助redo log实现持久化保护。binglog写入机制binlog的写入机制容易理解，主要有这几步骤：每一个mysql线程都有自己的binlog cache，这个阶段就是将binlog cache write到磁盘页缓存page cache，但是共用同一份binlog文件；将page cache中的数据fsync到物理磁盘文件中，这个时候才是真正占磁盘IOPS。主要是通过sync_binlog这个参数来控制：sync_binlog=0：每次提交事务都只write，而不fsync；sync_binlog=1：每次提交事务都会执行fsync；sync_binlog&gt;N：每次wirite，但是累积到N个事务才会fsync。redo log写入机制redo log的写入机制听起来也和binglog差不多，即：redo log存在于进程的物理内存中，名为redo log buffer，首先会将redo log buffer write到磁盘页缓存page cache；fsync到磁盘文件中。cache和buffer看起来很类似，但是实际上作用是不一样的，cache一般用于读缓存，buffer一般用于写加速。redo log的写入策略可以通过innodb_flush_log_at_trx_commit来控制：它有三种可能的取值：0：每次事务提交时都只把redo log留在buffer中；1：每次事务提交都将redo log进行持久化，并且在prepare阶段就会进行一次持久化；2：每次事务提交都只是将redo log写到page cache。innodb有一个后台线程，每隔1秒都会执行上面两个步骤（定时轮询）。没有提交的事务的redo log也有可能随着其他正在提交事务的redo log写到磁盘（并行提交）。redo log buffer占用空间到达innodb_log_buffer_size一半的时候也会触发write。整体时序线上一般会采取“双1”配置，即sync_binlog和innodb_flush_log_at_trx_commit都是1，此时，binglog和redo log的整体执行时序是这样的：redo log prepare:write - binlog cache:write - redo log prepare:fsync - binlog cache fsync - redo log commit: write也就是说在redo prepare阶段的redo log就已经进行了一次持久化操作。前面曾经说过redo log文件是一个环形的，每个write point都会有一个日志逻辑序列号（LSN），它是单调递增的，每次写入redo log都会在LSN上加redo log长度，提交第一个事务的时候，它会将小于LSN（因为提交第一个事务的时候可能其它事务的redo log会继续增长LSN）的事务一起进行fsync。这种组提交的方式可以尽可能节约磁盘的IOPS，也就有了上面的时序，放在binlog cache的write后面来拖时间。同样binlog也能够实现组提交，但是由于redo log prepare:fsync的时间一般比较快，所以binlog的组提交不是非常明显，可以通过binlog_group_commit_sync_delay和binlog_group_commit_sync_no_delay_count来提升组提交效果，前一个参数表示延迟多少微秒执行fsync，后一个参数表示累积多少次以后执行fsync，两个条件互为或的关系。总结MySql如果出现IO瓶颈，可以考虑以下三种方法：binlog_group_commit_sync_delay和binlog_group_commit_sync_no_delay_count减少binlog写盘次数，但是会增加语句响应时间，没有丢失数据的风险；将sync_binlog设置为大于1的值，这样有可能导致丢失部分binlog；将innodb_flush_log_at_trx_commit设置为2，这样有可能会丢失数据。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>MySql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式-责任链模式]]></title>
    <url>%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%B4%A3%E4%BB%BB%E9%93%BE%E6%A8%A1%E5%BC%8F.html</url>
    <content type="text"><![CDATA[定义Avoid coupling the sender of a request to its receiver by giving more than one object a chance to handle the request.Chain the receiving objects and pass the request along the chain until an object handles it.通过给不止一个接收者处理某个请求的机会来避免请求的发送者和接收者之间的耦合。将所有的接受者链起来，然后将请求在链上传递直到有一个接收者去处理它。之所以首先提到这个模式，是因为我刚开始接触到的有印象的就是责任链模式。而它的用途也比较广泛，举个比较常见的例子，经常会看到一种下面这种代码：12345678910//接口列表 if (SystemConfig.ECJSON_FPMXXX_CX.equals(restEntity.getGlobalInfo().getInterfaceCode())) &#123;//发票明细查询 respEntity = restService.fpmxxxcx(content,restEntity); &#125; else if (SystemConfig.ECJSON_ZXYHSL_CX.equals(restEntity.getGlobalInfo().getInterfaceCode())) &#123;//在线户数查询 respEntity = restService.zxyhcx(restEntity,InterfaceCode); &#125; else if (SystemConfig.ECJSON_AZKPSL_CX.equals(restEntity.getGlobalInfo().getInterfaceCode()))&#123;//安装开票户数 respEntity = restService.azkpyhscx(restEntity,content); &#125; else if(SystemConfig.ECJSON_YKPJE_CX.equals(restEntity.getGlobalInfo().getInterfaceCode()))&#123;//月开票金额 &#125; //......后面忽略了很大一部分的if else，这种代码不仅看起头皮发麻，而且耦合高，如果新增新的接口，必然在这个高层需要新增if else，违背了开闭原则，这时候就可以用责任链去优化，不仅灵活而且耦合度更低。类图和代码对于这些业务的接收者即不同接口编码的处理者，我们可以抽象出一个AbstractHandler，其中主要的有这几点：对外用于处理请求的processRequire；需要子类具体实现业务的response；子列表明自己处理的业务标志。这里模拟一个场景：用户随时会提意见，可能是跟产品经理要求增加功能；可能是要求程序员优化代码，可能是要求UI修改一下图片样式等。类图如下：抽象处理父类代码如下：12345678910111213141516171819202122232425262728293031public abstract class AbstractHandler &#123; public static String CODE_REQUIRE = "code"; public static String UI_REQUIRE = "ui"; public static String FUNC_REQUIRE = "func"; //下一个节点 private AbstractHandler nextHandler; //请求的业务类型 private String requireType; public AbstractHandler(String type) &#123; this.requireType = type; &#125; public void setNextHandler(AbstractHandler nextHandler) &#123; this.nextHandler = nextHandler; &#125; //模板方法处理请求，不允许子类重写 public final void processRequire(IRequirement requirement)&#123; if(this.requireType.equals(requirement.getType())) this.response(requirement); else if (this.nextHandler != null) this.nextHandler.processRequire(requirement); else System.out.println("无法处理该请求:"+requirement.getRequest()); &#125; //子类自己实现自己的业务 protected abstract void response(IRequirement requirement);用户提需求的一个抽象：12345678910public interface IRequirement &#123; //表明过来的需求类型 public String getType(); //需求内容 public String getRequest();&#125;然后分别定义几个部门里的技术支持人员：1234567891011121314151617/** * @Description: 程序员 * @Author: 刘会俊 * @Date: 2019-03-22 13:36 */public class Coder extends AbstractHandler &#123; public Coder() &#123; super(AbstractHandler.CODE_REQUIRE); &#125; @Override protected void response(IRequirement requirement) &#123; System.out.println("程序员拿到需求为："+requirement.getRequest()+",正在处理！"); &#125;&#125;其他如产品经理或者UI设计师也类似。然后模拟用户可能会提的需求种类：12345678910111213141516/** * @Description: 代码优化需求 * @Author: 刘会俊 * @Date: 2019-03-22 13:51 */public class CoderRequirment implements IRequirement &#123; @Override public String getType() &#123; return AbstractHandler.CODE_REQUIRE; &#125; @Override public String getRequest() &#123; return "优化一下代码！！！"; &#125;&#125;其他UI需求，或者产品需求也同上类似。再建立一个映射类，每次调用只需要在映射类里找到责任链第一个节点，并组装链返回即可：12345678910111213class MappingHandler&#123; public static AbstractHandler findHandler()&#123; AbstractHandler coder = new Coder(); AbstractHandler ui = new Ui(); AbstractHandler product = new Product(); product.setNextHandler(coder); coder.setNextHandler(ui); return product; &#125;&#125;在高层的控制层就可以很轻松地调用了，它不需要知道是谁处理的和处理细节，传入参数就能拿到返回值：12345678910111213141516171819202122232425262728293031/** * @Description: 控制层 * @Author: 刘会俊 * @Date: 2019-03-22 13:45 */public class Controller &#123; public static void main(String[] args) &#123; AbstractHandler product = MappingHandler.findHandler(); IRequirement coderRequire = new CoderRequirment(); IRequirement functionRequire = new FunctionRequirement(); IRequirement unkonwnRequire = new IRequirement() &#123; @Override public String getType() &#123; return "unknown"; &#125; @Override public String getRequest() &#123; return "未知请求"; &#125; &#125;; product.processRequire(coderRequire); product.processRequire(functionRequire); product.processRequire(unkonwnRequire); &#125;&#125;打印结果：程序员拿到需求为：优化一下代码！！！,正在处理！ 产品经理获得需求为：增加一个功能！！！，正在处理中 无法处理该请求:未知请求 借助Spring借助于Spring，我们还可以玩出更炫酷的花样。我们都知道链节点的增多会导致每个请求不同的递归调用、判断会耗费很多的判断时间，但是如果此时假如能有个容器，通过循环容器里的AbstractHandler找到每个子类的处理等级，将处理等级同请求类型比对，成功即可具体操作业务，这样效率会高很多，这时候Spring 的酷炫玩法就来了：AbstractHandler的代码基本保持一致，但是setNextHandler这个方法就可以不用了，需要新增一个getRequireType来作为模板方法获取当前子类的处理类型：12345678910111213141516171819202122232425public abstract class AbstractHandler &#123; public static String CODE_REQUIRE = "code"; public static String UI_REQUIRE = "ui"; public static String FUNC_REQUIRE = "func"; private AbstractHandler nextHandler; private String requireType; public String getRequireType() &#123; return requireType; &#125; public AbstractHandler(String type) &#123; this.requireType = type; &#125; //处理请求 public final void processRequire(IRequirement requirement)&#123; this.response(requirement); &#125; //返回响应 protected abstract void response(IRequirement requirement);&#125;将所有子类纳入Spring容器的管理，加上注解即可：12345678910111213@Componentpublic class Coder extends AbstractHandler &#123; public Coder() &#123; super(AbstractHandler.CODE_REQUIRE); &#125; @Override protected void response(IRequirement requirement) &#123; System.out.println("程序员拿到需求为："+requirement.getRequest()+",正在处理！"); &#125;&#125;Product和Ui两个类同理。123456789101112131415161718192021222324252627282930313233@Componentpublic class HandlerMapping implements InitializingBean, ApplicationContextAware &#123; //spring容器上下文 private ApplicationContext applicationContext; //存放业务处理的容器 List&lt;AbstractHandler&gt; abstractHandlerList = new ArrayList&lt;&gt;(); //spring容器会在加载完毕执行这个方法，在这里会读取到AbstractHandler.class类型的bean的名字数组进行循环，然后从beanfactory里根据类名取出来对应的bean放入业务容器 @Override public void afterPropertiesSet() throws Exception &#123; String[] abstractHandlers = BeanFactoryUtils.beanNamesForTypeIncludingAncestors(applicationContext, AbstractHandler.class); for (String abstractHandlerName : abstractHandlers) &#123; abstractHandlerList.add((AbstractHandler) applicationContext.getBean(abstractHandlerName)); &#125; &#125; //获取spring 容器上下文 @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; this.applicationContext = applicationContext; &#125; //映射，循环获取业务逻辑代码，根据代码返回对应的处理器 public AbstractHandler mapping(IRequirement requirement)&#123; if ( abstractHandlerList.size() &gt; 0) &#123; for (AbstractHandler abstractHandler : abstractHandlerList) &#123; if (abstractHandler.getRequireType().equals(requirement.getType()))&#123; return abstractHandler; &#125; &#125; &#125; return null; &#125;&#125;测试类：1234567891011121314151617181920@RunWith(SpringRunner.class)@SpringBootTestpublic class DemoApplicationTests &#123; @Autowired private HandlerMapping handlerMapping; @Test public void contextLoads() &#123; IRequirement coderRequirment = new CoderRequirment(); AbstractHandler coderHandler = handlerMapping.mapping(coderRequirment); coderHandler.processRequire(coderRequirment); IRequirement funcRequirment = new FunctionRequirement(); AbstractHandler funcHandler = handlerMapping.mapping(funcRequirment); funcHandler.processRequire(funcRequirment); &#125;&#125;执行结果：程序员拿到需求为：优化一下代码！！！,正在处理！ 产品经理获得需求为：增加一个功能！！！，正在处理中 总结优点：将请求和处理分开，甚至不需要处理细节；扩展方便，以后新增业务只需要新增一个业务类型，接入链即可，结合spring甚至只需要新增业务类，耦合度大大降低；缺点：链如果太长会导致性能问题；链太长不利于调试。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019第一思]]></title>
    <url>%2F2019%E7%AC%AC%E4%B8%80%E6%80%9D.html</url>
    <content type="text"><![CDATA[关于技术和大部分选择从事与计算机这一行的不同，我对计算机技术很感兴趣。一开始选择从事软件开发，就是觉得炫酷，而如果追朔到10年以前，那时候的我第一次接触计算机，对于这种电子设备充满了浓重的兴趣，而后又听闻坊间对于“黑客”的传说，于千里之外盗取账户于无形之间，只觉得这一行神秘而酷到爆炸。然而这一切的兴趣都在接触到电子游戏以后被屏蔽隐藏，甚至于到大学之时，对于计算机技术的兴趣有一点萌芽之时，也只是勉强学了一点计算机方面的基础知识，坚持学了一段时间Android，却在最终没有做出一点成果就放弃了，改投入了Java web的怀抱，在一个末流二本，甚至连我这种能够主动去学习技术的人都少的可怜。学Java Web大概是让我真正进入了技术的大门，我开始自主探索我以前完全未知的领域，当然在16年的时候，我还在网易云课堂上报名了一门《Web安全》的微专业课，稍微学习了一点“白帽子”挖洞的技巧，证书我现在都还留着。为什么说稍微呢？因为可能是觉得不甘心，还想往安全方向试一试，权当弥补自己年少时错过的遗憾，事实证明，还是往一个方向专心发展才是正道。尤其近些年，后端技术栈的要求堪比全栈。2017年毕业以后，我进入一个自我提升飞快的时期，我看了很多很多技术书籍，记载了很多技术方面的笔记。甚至还在一家创业公司负责搭建了一套SOA体系的框架，最后的CI/CD环境也是我搭建并在公司推广的，效果很显著，身边的同时说有了那一套东西，开发效率和发布效率至少比原来省时一半以上。很不幸的是，这个项目，或者说这个公司并没有撑下去，老板欠了钱不发，公司也宣布倒闭，仲裁要不回钱，我倾注了大量心血多少次为之熬夜的项目也没有成长到最终形态。2018年底，我无奈进入了当前的公司，项目结构稳定，处于迭代状态。国企的工作是相对轻松的，然而对于我这种有轻微代码洁癖的人来说，这里的代码简直是惨不忍睹，人微言轻，我自知不能改变什么，所以我选择静下心了好好学习，好好沉淀，将来能够厚积薄发。前段时间，我一度陷入了迷茫时期，我变得毫无目标，也毫无动力。在广度和深度中我纠结不定，我不知道是系统学习一种知识就好，还是平时注意积累一些零散的知识点，我的技术增长进入停滞期。在知识星球（一款APP）中，我看到有人提出了和我类似的疑问，星主（芋艿）说了一句话：“我们是技术人，只要不停提升技术，自然会有很多机会。技术人只要踏踏实实的，平时遇到一些问题去刨根问底，用问题的这个点带动一个知识面，等工作年限到了，也就是一方技术大牛了。”大概是这种意思。是啊，我何必纠结哪种方式比较好，技术越问越探究越明白。你若盛开，蝴蝶自来。关于生活我一直坚信一句话：成功的人并不是那种每天每日每夜忙的不可开交的人，而是将工作和生活平衡的很好的人。我的生活从刚踏入社会就一直处于一种单调的两点一线的路线中。我总告诉自己现在穷，多省钱，挣钱才是王道，所以很少出去玩。但是实际上，我最大的愿望就是自己能够逛遍祖国乃至世界上的大好河山。我宅了将近两年，甚至连北京5-10块钱门票的一些公园都没去过。可能我确实太懒，太没有追求，太不懂享受，所以会被女孩子嫌弃。琴弦还是2017年装的伊利克斯，以前会的很多吉他指弹都忘得差不多，却没有再想起来重新练一遍，毕竟那些曲子，就是自己当年花费很大力气练的，那是多么宝贵的一个财富，那是青春留下的仅存的记忆。行不大于言，带来的后果就是失去别人的信任。多出去走走吧，你可以看到家里看不到的风景，调整好身心状态，带着更充足的劲头去钻研技术；约上一二好友，带上野餐垫，背上吉他，去沐浴春光暖阳，好友无需太多，不然总有一个人会尴尬；接受自然的洗礼，脱去混迹于社会而蒙上的浮躁不安，脚踏实地，一步一个脚印。脚印在哪？在我的博客小站里，在练的每一首吉他曲目中，也在一张张记载时光的照片里。最后一点点技术人靠一技之长，有工作十年依然碌碌无为的老人，也有大学没毕业就技术精湛的新同学。但是毕竟大部分人都是普通人，不要去羡慕别人，只当作目标即可；也不要去轻视别人，他总有他的优点。我是个最普通的人，我的职业是程序员，我有坚持、热爱、想法。把坚持做到极致，把想法落到实地，把热爱化成动力。“Take control of your life and work.”]]></content>
      <categories>
        <category>生活思考</category>
      </categories>
      <tags>
        <tag>思考</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式-开篇记]]></title>
    <url>%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%BC%80%E7%AF%87%E8%AE%B0.html</url>
    <content type="text"><![CDATA[前言之所以开了一个写设计模式的系列，是因为在上家公司之时曾经用过其中的几种，而今将近半年时间过去，由于当初理解的不深入，导致现在已经忘了很多。技能这个东西总是越练越熟的，在我的理解中，语言是交流的工具，例如Java，C等各种计算机语言是我们与计算机交流的一种工具；算法是交流的逻辑和套路；数据结构是语言的组织方式；网络是远程的联系方式。如果把我们写的一个项目当成是一个人对计算机发表的演讲，那么设计模式就是演讲里的奇技淫巧，使我们的项目结构更清晰，扩展更加容易，人与机器皆大欢喜。UML类图由于笔记中会有一些类图，所以这里记载一下类图之间的关系。图片来源于https://www.cnblogs.com/pangjianxin/p/7877868.html（原图出处我也不知道，如有侵权请联系我删除）各种不同组件之间的关系如上图，其中组合和聚合容易混淆：组合的关系比较强，例如翅膀是鸟不可分割的一部分，翅膀离开鸟就毫无意义；聚合的关系稍微弱一些，例如大雁在一起成了雁群，但是脱离雁群依然有自己的生命。关联和依赖同样如此，不同气候下人的肤色不一样；但人都需要大气和水，所以人气候是关联关系，但是人依赖大气和水。设计原则总纲：开闭原则开闭原则是接下来说的几种设计原则的总纲，它的定义为：Software entities like classes,modules and functions shoud be open for extension but closed for modifications.简单来说，就是“对修改关闭，对扩展开放”。举个例子：我们原来的交易系统总共有三种订单类型：商城订单，代金券订单，商户买单订单。三种业务对应的业务类型编码是不一样的，按照普通的方式来写，我们是这种方式： 1234567if("mallOrder".equals(type))&#123; businessService.doMallBusiness();&#125;else if("voucherOrder".equals(type))&#123; businessService.doVoucherBusiness();&#125;else&#123; //......&#125;现在如果商城的商品出现打折，通常的做法就是修改doMallBusiness()里面的方法，结算时加入折扣的计算，这种做法的问题在于：所有功能已经通过测试的稳定代码会变得不稳定，乃至重新测试，而通常来说，我们一个类都只有一个测试类，每个类里的测试方法至少有三种：业务逻辑测试、边界测试、异常测试。对于业务复杂的方法可能测试会更多，如果修改了原有代码，需要改的测试方法同样会有很多，甚至会有遗漏的，结果严重会影响到线上程序崩溃。开闭原则的优点：提高模块复用性，模块粒度越小越容易被复用；提高可维护性，使用扩展代替修改；面向对象开发的需求。单一职责原则Single Responsibility Principle，简称SPR。There should never be more than one reason for a class to change.这里将引起变化的原因代替职责作为衡量一个接口或者类设计的是否优秀的标准，我对此的理解是，如果一个接口或者类修改，只对其实现类或者子类有影响，那么就说这个接口或者类就是符合单一职责原则的。但是现实项目中最难划分的就是类的职责，需要根据项目和环境来区别对待。我们不能因为用设计原则而用，而需要根据业务场景类设计，也不需要一味死守设计模式而不知变通，最推荐的就是接口的设计做到单一职责，类的设计尽量做到只有一个原因引起变化。里氏替换原则Liskov Subsitution Principle，LSP。if for each object o1 of type S there is an object o2 of type T such that for all programs P defined in terms of T,the behavior of P is unchanged when o1 is substited for o2 then S is a subtype of T.如果每一个类型为S的对象o1，都有类型为T的对象o2，使得以T定义的程序P在所有的对象o1都代换成o2时，程序P的行为没有发生变化，那么说S为T的子类型。也就是说：父类能够出现的地方，子类也能够出现。依赖倒置原则Dependence Inversion Prindiple，DIP。High level modules should not depend upon low level.Both should depend upon abstractions.Abstractions should not depend upon details.Details should depend upon abstractions.高层模块不应该依赖低层模块，两者都应该依赖抽象。抽象不应该依赖细节，细节应该依赖抽象。传统思维的依赖就是需要用什么就使用什么对象，而依赖倒置就是不直接依赖对象，而是依赖对象的抽象。接口隔离原则Clients should not be forced to depend upon interfaces that they dont`s use;The dependency of one class to another one should depend on the smallest possible interface.建立单一接口，不要建立臃肿庞大的接口，提供给每个模块的都应该是单一接口，提供给几个模块就应该有几个接口。和单一职责的区别是：单一指责是站在类本身的角度来看，按照职责划分；而接口隔离是站在依赖方来看，有几个模块依赖，就应该有几个接口。迪米特法则Law of Demeter(Lod)，也称之为最少只是原则(Least Knowledge Principle,LKP)，一个类应该对要耦合或者要调用的类知道的最少。即，一个类只跟直接的朋友类通信，什么叫朋友类？出现在成员变量、方法的输入输出参数中的类成为成员朋友类总结设计模式是为了让软件的模块之间的耦合程度降到最低，提供模块的可重用性和可维护性。它是前辈们的经验总结，而不是一种强制的要求，一切脱离实际业务的设计都是耍流氓。软件在设计之初，不可能面面俱到，扩展性设计也可能不是那么全面，必要的重构还是需要的，设计模式也不是万能的，用的好才是利器，用不好只会徒增复杂度。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySql-间隙锁和临键锁]]></title>
    <url>%2FMySql%E9%94%81-%E9%97%B4%E9%9A%99%E9%94%81%E5%92%8C%E4%B8%B4%E9%94%AE%E9%94%81.html</url>
    <content type="text"><![CDATA[说明mysql的innodb引擎中有七种锁：S锁（Share Lock）共享锁，所有类似于select * from t where id = 1 lock in share mode或者update t set c = c+1 where id = 1的形式，行级锁；X锁（Exclusive Lock）排他锁,所有select * from t where id = 1 for update的形式。行级锁；IS锁，意向共享锁，在获取S锁之前加的锁，表级锁；IX锁，意向排他锁，在获取X锁之前加的锁，表级锁；Record Lock记录锁，行级锁的真正实现；Gap Lock间隙锁，锁住一个范围；Next-key Lock临键锁，Gap Lock+Record Lock的组合；笔记记载的内容是在版本5.7.24和8.0.13验证通过，以后其他版本的MySql的加锁策略可能会变化。“临键锁”称呼来源于“架构之路”公众号。加锁策略加锁锁住的是什么？索引注意：MySql只有在RR的隔离级别下才有gap lock和next-key lock。原则1：加锁的基本单位是Next-key Lock（左开右闭区间）；原则2：查找到的对象才会加锁；优化1：索引上的等值查询，给唯一索引加锁的时候，会退化为行锁；优化2：索引上的等值查询，向右遍历最后一个值不满足等值条件时，next-key lock会退化为间隙锁。一个不合理的地方：唯一索引上的范围查询会访问到不满足条件的第一个值为止。案例分析建表语句：12345678910CREATE TABLE `t` ( `id` int(11) NOT NULL, `c` int(11) DEFAULT NULL, `d` int(11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `c` (`c`)) ENGINE=InnoDB;insert into t values(0,0,0),(5,5,5),(10,10,10),(15,15,15),(20,20,20),(25,25,25);idcd000555101010151515202020252525案例一：唯一索引等值查询123456789--session Abegin;update t set d = d + 1 where id = 7;--session Binsert into t values (8,8,8);--session Cinsert t set d = d + 1 where id = 10;上面开启了三个会话分别执行了三个动作。分析：原则1：加锁区间为：(5,10]；原则2：id=7的不存在，所以这一行没有锁；优化1：id=7的行没有锁，不满足优化1；优化2：id=7，与(5,10]的最后一个条件不相等，退化为gap lock。综上：所以session A加了gap lock(5,10)，session B会阻塞，C会成功。案例二：非唯一索引等值查询123456789--session Abegin;select id from t where c = 5 lock in share mode;--session Bupdate t set d = d + 1 where id = 5;--session Cinsert into t values (7,7,7);分析：原则1：索引C加了next-key lock(0,5];原则2:c=5存在，所以索引c=5加锁；优化1：由于索引覆盖（不访问id索引就可以拿到id的值），虽然C=5索引加锁，但是id=5的索引实际并没有加锁，不满足优化1；优化2：非唯一索引需要向右继续查找，直到10，所以加上next-key lock(5,10],由于10不满足c=5的条件，所以next-key lock退化为gap lock(5,10)。所以session B的操作会成功，C会失败。如果想避开索引优化，可以使用select id from t where c = 5 for update，在加锁时会直接锁住主键索引，或者查询一些其他字段。案例三：唯一索引范围查询12345678910--session Abegin;select * from t where id&gt;=10 and id&lt;11 for update;--session Binsert into t values (8,8,8);insert into t values (13,13,13);--session Cupdate t set d = d + 1 where id = 15;分析：原则1：next-key lock(5,10]和(10,15];原则2：查找过程中找到了id为10这一行，加了行锁；优化1：由于给唯一索引加锁，所以next-key lock(5,10]退化为id=10的行锁;优化2：不满足等值查询的条件；所以上面操作的结果是session B的第一个插入操作会成功，第二个插入操作会阻塞；session C的操作会阻塞。案例四：非唯一索引范围查询123456789--session abegin;select * from t where c &gt;= 10 and c &lt; 11 for update;--session binsert into t values (8,8,8);--session cupdate t set d = d + 1 where id = 15;分析：原则1：next-key lock(5,10]和(10,15]；原则2：由于查找到10，所以对10加锁；优化1：由于不是唯一索引，因此(5,10]不会退化；优化2：由于不是等值查询，所以(10,15]不会退化；所以上面的操作是session b阻塞，session c也阻塞。案例五：唯一索引范围锁bug对应上面加锁策略中的不合理之处。123456789--session abegin;select * from t where id &gt; 10 and id &lt;= 15 for update;--session bupdate t set d = d + 1 where id = 20;--session cinsert into t values (16,16,16);分析：原则1：范围查询next-key lock(10.15];原则2：搜索到id=15这一行，所以这一行数据要加锁；优化1：非等值查询，不满足优化1；有话2：唯一索引，不满足优化2；由于id是唯一索引，所以理论来说没必要再往后搜索，但是实际上还有一个next-key lock(15,20];所以session b会锁住，session c也会锁住。案例六：非唯一索引存在”相等值“首先插入一条数据：1mysql&gt; insert into t values(30,10,30);数据库测试有两条c=10的数据了。即：idcd000555101010151515202020252525301030此时索引C的状态是：{5-5}-{10-10}-{10-30}-{15,15}-……执行SQL如下：12345678910--session abegin;-- delete的加锁规则和for update是一样的delete from t where c = 10;--session binsert into t values (12,12,12)--session cudpate t set d = d + 1 where c = 15;分析：next-key lock(5,10];c=10这一行加锁；非唯一索引，不满足退化条件；满足条件，向右查询第一个不等的值即c=15，加上next-key lock(10,15]，由于15!=10，所以退化为gap lock(10,15);所以上述操作是session b阻塞，c成功。案例七：limit加锁123456--session abegin;delete from t where c = 10 limit 2;--session binsert into t values(12,12,12);分析：同案例六，但是在优化2的时候，由于limit 2的存在，所以在遍历到(30,10,30)这一行的时候就停止遍历了，所以session b的结果是成功。案例八：死锁12345678910111213--session abegin;select id from t where c = 10 lock in share mode;--session bupdate t set d = d + 1 where c = 10;--session ainsert into t values(8,8,8);--session bERROR 1213(40001);Deadlock found and tring to get lock ; try restarting transaction;分析：session a:next-key lock(5,10];c = 10加锁；不满足优化1；满足优化2，加上next-key lock(10,15]并退化为gap lock(10,15)。session b:获取gap lock(5,10)成功，再获取c = 10的record lock时进入等待；session a:插入c = 8的行被死锁，a b进入互相等待。这个案例说明：next-key lock是由gap lock和record lock组成的，而且是分两部分获取的。案例九：排序对锁的影响123456--session abegin;select * from t where c &gt;= 15 and c &lt;= 20 order by c desc lock in share mode;--session binsert into values (6,6,6);分析：由于是order by c desc，所以遍历时第一个是c=20以及最右边的行:next-key(15,20](20,25]，其中(20,25]会退化为(20,25)gap lock；c=15,c=20，c=25加锁；由于不是唯一索引，所以不满足优化1；在索引c上向左遍历，知道c=10才会停止，所以next-key lock还包括(5,10]。案例十：多索引等值查询首先创建表：1234567891011121314CREATE TABLE z ( id INT PRIMARY KEY AUTO_INCREMENT, b INT, KEY b(b)) ENGINE = InnoDB DEFAULT CHARSET = utf8;INSERT INTO z (id, b)VALUES (1, 2), (3, 4), (5, 6), (7, 8), (9, 10);123456789101112131415----session aBEGIN;SELECT *FROM zWHERE b = 6 FOR UPDATE;--session bINSERT INTO z VALUES (2, 4);INSERT INTO z VALUES (2, 8);INSERT INTO z VALUES (4, 4);INSERT INTO z VALUES (4, 8);INSERT INTO z VALUES (8, 4);INSERT INTO z VALUES (8, 8);INSERT INTO z VALUES (0, 4);INSERT INTO z VALUES (-1, 4);分析：next-key lock(4,6];b=6这一行加锁；不满足；满足，加gap lock(6,8);需要牢记的是：这个锁是加在b索引上的，而索引都是有序的，所以我们很轻易得到下图：所以session b的结果是：12345678INSERT INTO z VALUES (2, 4);--successINSERT INTO z VALUES (2, 8);--blockedINSERT INTO z VALUES (4, 4);--blockedINSERT INTO z VALUES (4, 8);--blockedINSERT INTO z VALUES (8, 4);--blockedINSERT INTO z VALUES (8, 8);--successINSERT INTO z VALUES (0, 4);--自增主键如果为0会自动替换为表里最大id的下一位,所以这里实际是(10,4)，blockedINSERT INTO z VALUES (-1, 4);--success参考架构师之路：https://mp.weixin.qq.com/s/y_f2qrZvZe_F4_HPnwVjOw案例十详解参见其他博客：https://helloworlde.github.io/blog/blog/MySQL/MySQL-%E4%B8%AD%E5%85%B3%E4%BA%8Egap-lock-next-key-lock-%E7%9A%84%E4%B8%80%E4%B8%AA%E9%97%AE%E9%A2%98.html]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>MySql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nexus简单搭建私服]]></title>
    <url>%2FNexus%E7%AE%80%E5%8D%95%E6%90%AD%E5%BB%BA%E7%A7%81%E6%9C%8D.html</url>
    <content type="text"><![CDATA[简述Nexus[‘neksəs]是一个依赖管理的仓库，用于提供Maven和Gradle等构建工具的依赖源，它可以整合本地和远程的所有仓库并按照指定顺序寻找依赖，这里随手记载一下搭建过程。下载安装官网：https://www.sonatype.com/download-oss-sonatype。根据系统版本下载，本文使用的版本是3.10.0，Linux可以下载OS-X版本或者Unix版本，差别不大。上传到服务器，执行以下命令，（假设现在具有root权限，解压到的目标目录可以随意选择）。123456mkdir /home/nexustar -xzvf nexus-3.10.0-04-unix.tar.gz -C /home/nexususeradd nexuschown -R nexus /home/nexuscd /home/nexus./nexus-3.10-04/bin/nexus start命令解释：nexus不推荐使用root执行启动脚本，所以这里我们自己新增了一个用户，并且修改了nexus目录的所属用户为nexus，当然，也可以不用修改所属用户，只需要给nexus用户增加一个写入权限即可：chmod -R +w /home/nexus，或者写入777权限chmod -R 777 /home/nexus。启动可能需要5-10s，启动完成以后可以通过IP:8081端口进行访问，仓库配置登录进nexus的管理页面，用户名/密码默认为admin/admin123，然后依次点击下方图片中标出来的部分：可以看到这里的仓库有三种类型：hosted：这种类型的仓库表示的是本地服务器的仓库，也是公司自己开发的Jar包上传的地方；proxy：该类型表示远程仓库代理，即它本身是用来缓存远程仓库的；group：该类型表示是一组仓库，它可以包含hosted、proxy、group三种类型的仓库。这里我新建了三个仓库aisino，aisino-old，maven-aliyun，并且删除了原来自带的一些很多没用的仓库，只留下了maven-public(对外提供仓库)，maven-central(中央仓库)。aisino：hosted类型，用于上传公司开发的jar包的位置；aisino-old：proxy类型，用于代理原公司老私服的位置，老私服里有以前的很多元原来开发过的jar包；maven-aliyun：proxy类型，用于代理国内的阿里云仓库位置，下载速度更快。hosted类型的仓库新建即可，无特殊配置。这里提一下proxy类型的仓库，例如我配置的maven-aliyun仓库如下：在下方的Proxy配置项的remote storage一栏里填上阿里云的仓库位置：http://maven.aliyun.com/nexus/content/groups/public其他的保持默认即可。然后进入maven-public的配置，以后公司的私服都使用的该仓库，group里加入刚刚新建的几个仓库，我们的项目就可以使用自己私服的地址了：在项目或者系统的maven的安装或解压路径下的conf/settings.xml里，添加如下几行(url为maven-public里的URL):12345678&lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;nexus-aisino&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;Nexus&lt;/name&gt; &lt;url&gt;http://192.168.15.187:8081/repository/maven-public/&lt;/url&gt; &lt;/mirror&gt;&lt;/mirrors&gt;将来需要引入jar包的时候就会按照我们定义的顺序依次去仓库里寻找jar包并缓存到本地。要注意的是，health check这个选项可以关闭，在3.10的版本下开启health check进行analyze出现了insufficient trend data的问题，这个并不是报错，依然可以正常下载jar包，所以搭建好可以直接尝试一下新建一个maven项目。]]></content>
      <categories>
        <category>编程技术</category>
      </categories>
      <tags>
        <tag>随记</tag>
        <tag>Nexus</tag>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android学习笔记二-Activity]]></title>
    <url>%2FAndroid%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%BA%8C-Activity.html</url>
    <content type="text"><![CDATA[生命周期返回栈活动都是存放在返回栈（back stack）里，每个返回栈称之为一个任务（Task）。系统总是显示栈顶的活动（Activity）给用户。生命周期onCreate():组件的创建，加载布局，绑定事件；onStart():活动即将变为可见；onResume():活动处于交互状态，栈顶；onPause():活动释放一些资源和CPU占用，或者保存关键数据；onStop():活动转变为不可变状态；onDestroy():活动销毁之前调用，标记活动为销毁状态方便系统回收。onRestart():活动由不可见状态变为可见状态的过程。上面的状态可以分为三大类：完整生存期：onCreate()-onDestroy()可见生存期：onStart()-onStop()前台生存期：onResume()-onPause()代码新建一个android studio项目，除了主活动MainActivity之外，还有其他两个活动，分别命名为NormalActivity和DialogActivity。其中normal的布局为：12345678910111213&lt;LinearLayout xmlns:android="http://schemas.android.com/apk/res/android" android:orientation="vertical" android:layout_width="match_parent" android:layout_height="match_parent"&gt; &lt;TextView android:layout_width="match_parent" android:layout_height="wrap_content" android:text="this normal activity" /&gt;&lt;/LinearLayout&gt;dialog的布局为：123456789101112&lt;LinearLayout xmlns:android="http://schemas.android.com/apk/res/android" android:orientation="vertical" android:layout_width="match_parent" android:layout_height="match_parent"&gt; &lt;TextView android:layout_width="match_parent" android:layout_height="wrap_content" android:text="this is a dialog activity" /&gt;&lt;/LinearLayout&gt;然后在主活动main里面添加两个按钮，通过点击按钮来观察生命周期的变化。第一个按钮会停止当前的活动并跳转到一个新的活动，第二个按钮会在当前活动上层叠一个dialog，当前活动会暂停但是不会停止。123456789101112131415161718192021&lt;LinearLayout xmlns:android="http://schemas.android.com/apk/res/android" android:orientation="vertical" android:layout_width="match_parent" android:layout_height="match_parent"&gt; &lt;Button android:id="@+id/button1" android:layout_width="match_parent" android:layout_height="wrap_content" android:text="start normal activity" /&gt; &lt;Button android:id="@+id/button2" android:layout_width="match_parent" android:layout_height="wrap_content" android:text="start dialog activity" /&gt;&lt;/LinearLayout&gt;normal和dialog的activity里保持默认即可，在主活动里添加对按钮的响应事件：1234567891011121314151617181920212223242526272829303132public class MainlActivity extends AppCompatActivity &#123; private static final String TAG = "MainlActivity"; @Override protected void onCreate(Bundle savedInstanceState) &#123; Log.i(TAG, "onCreate: "); super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); Button startButton = findViewById(R.id.button1); Button dialogButton = findViewById(R.id.button2); startButton.setOnClickListener(new View.OnClickListener() &#123; @Override public void onClick(View view) &#123; Intent intent = new Intent(MainlActivity.this,NormalActivity.class); startActivity(intent); &#125; &#125;); dialogButton.setOnClickListener(view -&gt; &#123; Intent intent = new Intent(MainlActivity.this, DialogActivity.class); startActivity(intent); &#125;); &#125; @Override protected void onDestroy() &#123; Log.i(TAG, "onDestroy: "); super.onDestroy(); &#125; //...分别重写onStart(),onPause()等其他生命周期方法并打印日志&#125;小技巧：如果想要使用JDK 8的lambda表达式，只需要在app目录下的build.gradle里android闭包里添加如下代码即可：compileOptions { sourceCompatibility 1.8 targetCompatibility 1.8 } 执行代码，观察结果：启动时可以看到：I/MainlActivity: onCreate: I/MainlActivity: onStart: I/MainlActivity: onResume: 点击start normal activity时，控制台打印结果：I/MainlActivity: onPause: I/MainlActivity: onStop: 点击返回键：I/MainlActivity: onRestart: I/MainlActivity: onStart: I/MainlActivity: onResume: 点击start dialog activity：I/MainlActivity: onPause: 点击返回键：I/MainlActivity: onResume: 在主活动页面点击返回：onPause: onStop: onDestroy: 数据临时保存当上一个活动进入stop的生命周期时，此时由于系统内存的不足，可能会导致上一个活动被回收，假如在上一个活动里输入了一些关键数据，那此时再回到上一个活动经历的又是一个create-start-resume的过程，用户还需要重新输入一遍数据，这种用户体验无疑是很差的。这里可以将数据临时保存,onSaveInstanceState方法能够保证系统回收之前一定被执行：12345@Overrideprotected void onSaveInstanceState(Bundle outState) &#123; super.onSaveInstanceState(outState); outState.putString("tmpString", "last String");&#125;然后在onCreate中再重新取出来：123if (savedInstanceState != null) &#123; Log.i(TAG, "onCreate: "+savedInstanceState.getString("tmpString"));&#125;启动模式启动模式的配置方式为：AndroidManifest.xml文件中的activity标签内：12&lt;activity android:name=".ThirdLayoutActivity" android:launchMode="singleInstance"&gt;活动有四种启动模式：standard:每次启动一个活动都会新建一个活动，例如我在main活动上又启动了一个main活动，记做main2，又启动一个记做main3，那么返回栈从上到下依次是：main3-main2-main，同理返回也是一次出栈；singleTop:每次启动一个活动时会判断当前返回栈的栈顶是不是要启动的活动，如果是，则不会新建一个活动，直接使用当前活动；如果不是，则会新建活动；singleTask:每次启动一个活动会判断当前栈里是否存在需要创建的活动，如果存在，就将该活动压到栈顶成为，原本处于它上方的活动会依次出栈destroy；singleInstance:该模式的活动会启动一个新的返回栈来存放，当多个应用需要使用共享的活动时，可以使用该模式。实践继承-妖魔现形调试的时候或者打印日志的时候，我们通常希望能够知道当前所处的位置或者说类，并且在一个位置做某些通用操作，这里可以通过新建一个BaseActivity类来继承原来代码中的AppCompatActivity，然后让真正的活动来继承我们的BaseActivity从而实现一些统一行为：12345678910public class BaseActivity extends AppCompatActivity &#123; private static final String TAG = "BaseActivity"; @Override protected void onCreate(@Nullable Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); Log.d(TAG, getClass().getSimpleName()); &#125;&#125;这里只是简单打印一下当前所处的类。封装-天下一统当我们的activity创建的比较多的时候，如果想一次性退出，比如在某个活动界面放置一个按钮，这个按钮是销毁所有的acivity，可以通过封装一个容器类，收集所有的活动，当用户点击退出软件的按钮，所有的activity都会销毁，避免我们一直按返回。12345678910111213141516171819202122public class ActivityCollector &#123; public static List&lt;Activity&gt; activityList = new ArrayList&lt;&gt;(); public static void addActivity(Activity activity)&#123; activityList.add(activity); &#125; public static void removeActivity(Activity activity) &#123; activityList.remove(activity); &#125; public static void finishAll()&#123; activityList.forEach(activity -&gt; &#123; if (!activity.isFinishing()) &#123; activity.finish(); &#125; &#125;); activityList.clear(); &#125;&#125;然后，在BaseActivity里可以控制创建activity的时候就加入容器类，销毁就从容器类里移除：1234567891011121314151617public class BaseActivity extends AppCompatActivity &#123; private static final String TAG = "BaseActivity"; @Override protected void onCreate(@Nullable Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); Log.d(TAG, getClass().getSimpleName()); ActivityCollector.addActivity(this); &#125; @Override protected void onDestroy() &#123; super.onDestroy(); ActivityCollector.removeActivity(this); &#125;&#125;然后给退出软件的按钮添加点击事件：1234button3.setOnClickListener(view -&gt; &#123; ActivityCollector.finishAll(); android.os.Process.killProcess(android.os.Process.myPid()); &#125;);android.os.Process.killProcess可以杀掉当前进程，myPid即为当前进程号。依赖-控制反转当我们从活动1调用活动2的时候，可能需要传递一些数据，通常情况下，我们并不知道要传递多少数据以及数据类型，并且需要new一个inten然后放入数据，例如：1234String data = "hello second";Intent intent = new Intent(FirstActivity.this, SecondActivity.class);intent.putExtra("extra_data", data);startActivity(intent);但是，如果我们在活动2里就定义好一个方法用来组装数据，那活动1就只需要调用该方法，传入参数即可，而无需手动组装。SecondActivity.java:123456public static void actionStart(Context context,String para1,String para2)&#123; Intent intent = new Intent(context,SecondActivity.class); intent.putExtra("param1", para1); intent.putExtra("param2", para2); context.startActivity(intent);&#125;那么在活动1中，只需要SecondActivity.actionStart(FirstActivity.this,&quot;test&quot;,&quot;test&quot;);即可跳转到第二个活动。]]></content>
      <categories>
        <category>编程技术</category>
      </categories>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Canal基础实践]]></title>
    <url>%2FCanal%E5%9F%BA%E7%A1%80%E5%AE%9E%E8%B7%B5.html</url>
    <content type="text"><![CDATA[简述Canal是一个MySql增量日志解析组件，其原理是将自己伪装成一台MySql Slave机器发送dump请求给Master，然后Master推送binary log给Canal，Canal会解析bin log对象的byte流。Canal提供一系列接口由客户端对增量数据进行自己的业务处理。数据库配置开启binlogMySql当前版本为5.7.15，首先需要开启mysql的binlog，因为mysql默认是不开启binlog的。如何查看MySql是否开启了binlog？首先需要mysql -uroot -p进入mysql的客户端命令行，然后执行：123456789101112131415161718192021222324252627mysql&gt; show variables like 'log_%';+----------------------------------------+----------------------------------------+| Variable_name | Value |+----------------------------------------+----------------------------------------+| log_bin | ON || log_bin_basename | /usr/local/mysql/data/mysql-bin || log_bin_index | /usr/local/mysql/data/mysql-bin.index || log_bin_trust_function_creators | OFF || log_bin_use_v1_row_events | OFF || log_builtin_as_identified_by_password | OFF || log_error | /usr/local/mysql/data/mysqld.local.err || log_error_verbosity | 3 || log_output | FILE || log_queries_not_using_indexes | OFF || log_slave_updates | OFF || log_slow_admin_statements | OFF || log_slow_slave_statements | OFF || log_statements_unsafe_for_binlog | ON || log_syslog | OFF || log_syslog_facility | daemon || log_syslog_include_pid | ON || log_syslog_tag | || log_throttle_queries_not_using_indexes | 0 || log_timestamps | UTC || log_warnings | 2 |+----------------------------------------+----------------------------------------+21 rows in set (0.01 sec)log_bin为on即代表开启了binlog，basename代表日志名称和路径。如果没有开启，需要配置my.cnf文件，Linux/MAC系统下的路径为/etc/my.cnf，Windows系统下路径为C:\ProgramData\MySQL\MySQL Server 5.7\my.ini，Linux/MAC系统下如果没有这个文件，可以新建一个或者从MySql的安装目录下的support-files里找到名为my-default.cnf文件复制到/etc/下，新增以下配置：12345log-bin=mysql-bin #binlog的名称binlog-format=ROW #推荐使用二进制记录expire_logs_days=5 #日志过期时间-5天server-id=1binlog-do-db= test #可选，表示记录某个特定库的binlog，如果多个库这个配置要有多个配置用户如果想方便省事，可以跳过这步，无需为canal专门配置一个用户。这里为canal专门新增一个用户，比较安全：1234567--创建用户CREATE USER canal IDENTIFIED BY 'canal';--赋权--GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'canal'@'%';-- GRANT ALL PRIVILEGES ON *.* TO 'canal'@'%' ;--刷新权限FLUSH PRIVILEGES;扩展：grant命令用法：grant 权限 on 数据库对象 to 用户如果想更改其他用户密码：1234567891011121314update mysql.user set authentication_string=password('qingyun1') where user='root' and Host = 'localhost';flush privileges;--如果mysql提示需要安全模式启动，参考以下----首先停止服务/usr/local/mysql/bin/mysqld stop--使用安全模式启动数据库/usr/local/mysql/bin/mysqld_safe --skip-grant-tables--使用root登陆/usr/local/mysq/bin/mysql -uroot -p--修改密码--正常重启/usr/local/mysql/bin/msqld restart重启数据库，可以使用上面的命令查看是否开启binlog。查看当前的binglog文件名称以及作用的数据库：1234567mysql&gt; show master status;+------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+------------------+-------------------+| mysql-bin.000333 | 1989 | ssm_employee | | |+------------------+----------+--------------+------------------+-------------------+1 row in set (0.00 sec)Canal部署安装传送门：https://github.com/alibaba/canal/解压开，然后进入conf目录，一般情况下没有用到集群的时候，canal.propertie可以无需配置，只需配置instance.properties文件即可.12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455################################################### mysql serverId , v1.0.26+ will autoGen# canal.instance.mysql.slaveId=0# enable gtid use true/falsecanal.instance.gtidon=false# position info# 数据库地址和端口canal.instance.master.address=192.168.15.107:3306canal.instance.master.journal.name=canal.instance.master.position=canal.instance.master.timestamp=canal.instance.master.gtid=# rds oss binlogcanal.instance.rds.accesskey=canal.instance.rds.secretkey=canal.instance.rds.instanceId=# table meta tsdb infocanal.instance.tsdb.enable=true#canal.instance.tsdb.url=jdbc:mysql://127.0.0.1:3306/canal_tsdb#canal.instance.tsdb.dbUsername=canal#canal.instance.tsdb.dbPassword=canal#canal.instance.standby.address =#canal.instance.standby.journal.name =#canal.instance.standby.position =#canal.instance.standby.timestamp =#canal.instance.standby.gtid=# username/passwordcanal.instance.dbUsername=rootcanal.instance.dbPassword=123456canal.instance.connectionCharset = UTF-8canal.instance.defaultDatabaseName =# enable druid Decrypt database passwordcanal.instance.enableDruid=false#canal.instance.pwdPublicKey=MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBALK4BUxdDltRRE5/zXpVEVPUgunvscYFtEip3pmLlhrWpacX7y7GCMo2/JM6LeHmiiNdH1FWgGCpUfircSwlWKUCAwEAAQ==# table regexcanal.instance.filter.regex=# table black regexcanal.instance.filter.black.regex=# mq configcanal.mq.topic=example# dynamic topic route by table regex#canal.mq.dynamicTopic=.*,mytest\\..*,mytest2.usercanal.mq.partition=0# hash partition config#canal.mq.partitionsNum=3#canal.mq.partitionHash=test.table:id^name,.*\\..*#################################################然后可以直接到canal解压后的bin目录中执行脚本启动:sh startup.shCanal客户端接入首先引入依赖：12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.otter&lt;/groupId&gt; &lt;artifactId&gt;canal.client&lt;/artifactId&gt; &lt;version&gt;1.1.0&lt;/version&gt;&lt;/dependency&gt;直接复制官方的客户端示例代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public class SimpleCanalClientExample &#123;public static void main(String args[]) &#123; // 创建链接 CanalConnector connector = CanalConnectors.newSingleConnector(new InetSocketAddress(AddressUtils.getHostIp(), 11111), "example", "", ""); int batchSize = 1000; int emptyCount = 0; try &#123; connector.connect(); connector.subscribe(); connector.rollback(); int totalEmptyCount = 120; while (emptyCount &lt; totalEmptyCount) &#123; Message message = connector.getWithoutAck(batchSize); // 获取指定数量的数据 long batchId = message.getId(); int size = message.getEntries().size(); if (batchId == -1 || size == 0) &#123; emptyCount++; System.out.println("empty count : " + emptyCount); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; &#125; &#125; else &#123; emptyCount = 0; // System.out.printf("message[batchId=%s,size=%s] \n", batchId, size); printEntry(message.getEntries()); &#125; connector.ack(batchId); // 提交确认 // connector.rollback(batchId); // 处理失败, 回滚数据 &#125; System.out.println("empty too many times, exit"); &#125; finally &#123; connector.disconnect(); &#125;&#125;private static void printEntry(List&lt;Entry&gt; entrys) &#123; for (Entry entry : entrys) &#123; if (entry.getEntryType() == EntryType.TRANSACTIONBEGIN || entry.getEntryType() == EntryType.TRANSACTIONEND) &#123; continue; &#125; RowChange rowChage = null; try &#123; rowChage = RowChange.parseFrom(entry.getStoreValue()); &#125; catch (Exception e) &#123; throw new RuntimeException("ERROR ## parser of eromanga-event has an error , data:" + entry.toString(), e); &#125; EventType eventType = rowChage.getEventType(); System.out.println(String.format("================&amp;gt; binlog[%s:%s] , name[%s,%s] , eventType : %s", entry.getHeader().getLogfileName(), entry.getHeader().getLogfileOffset(), entry.getHeader().getSchemaName(), entry.getHeader().getTableName(), eventType)); for (RowData rowData : rowChage.getRowDatasList()) &#123; if (eventType == EventType.DELETE) &#123; printColumn(rowData.getBeforeColumnsList()); &#125; else if (eventType == EventType.INSERT) &#123; printColumn(rowData.getAfterColumnsList()); &#125; else &#123; System.out.println("-------&amp;gt; before"); printColumn(rowData.getBeforeColumnsList()); System.out.println("-------&amp;gt; after"); printColumn(rowData.getAfterColumnsList()); &#125; &#125; &#125;&#125;private static void printColumn(List&lt;Column&gt; columns) &#123; for (Column column : columns) &#123; System.out.println(column.getName() + " : " + column.getValue() + " update=" + column.getUpdated()); &#125;&#125;&#125;控制台可以看到输出：empty count : 1 empty count : 2 empty count : 3 empty count : 4 然后给数据库新增一条数据，即可在客户端看到数据变更和类型：================&gt; binlog[master-bin.000045:237902.001946:313661577] , name[test,user] , eventType : INSERT ID : 4 update=true X : 2013-02-05 23:29:46 update=true 一些问题假如出现rowChage.getRowDatasList()获得的数据集合为null或者集合中没有元素导致控制台并没有打印出以上信息（参照issues#1267以及FAQ），通常情况下是由于两种原因引起的：MySql的配置文件里的binlog-format没有配置为ROW；在canal的配置文件里，即example的instance.properties的配置规则过滤掉了数据，检查一下该规则；总结可以通过canal实现MySql到各种其他数据库的迁移。]]></content>
      <categories>
        <category>编程技术</category>
      </categories>
      <tags>
        <tag>MySql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux基础-Shell分支循环和函数]]></title>
    <url>%2FLinux%E5%9F%BA%E7%A1%80-Shell%E5%88%86%E4%B9%8B%E5%BE%AA%E7%8E%AF%E5%92%8C%E5%87%BD%E6%95%B0.html</url>
    <content type="text"><![CDATA[if语法单分支：123456789//第一种if &lt;条件表达式&gt; then 指令fi//第二种if &lt;条件表达式&gt; then 指令fi ​条件表达式可以参考第二部分的内容，第二种的相当于用分号进行了换行。双分支：123456if &lt;条件表达式&gt; then 指令1else 指令2fi《Linux基础-Shell规范和执行 》的[ -f &quot;$file&quot; ] &amp;&amp; echo 1 || echo 0就等于:123456if [ if "$file" ] then echo 1else echo 0fi ​多分支：12345678if &lt;条件表达式1&gt; then 指令1elif &lt;条件表达式2&gt; then 指令2elif ......fi ​配置邮箱和密码：123456#配置邮箱和用户名密码[root@VM_0_8_centos MyBlog]# echo -e "set from=liuhuijun_2017@163.com smtp=smtp.163.com \nset smtp-auth-user=liuhuijun_2017@163.com smtp-auth-password=123456 smtp-auth=login" &gt;&gt; /etc/mail.rc#输入测试字符串[root@VM_0_8_centos MyBlog]# echo "Hello world" &gt;&gt; test.txt#读取测试字符串并发送邮件[root@VM_0_8_centos MyBlog]# mail -s "title" liuhuijun_2017@163.com &lt; test.txt扩展：在服务器本地监控端口的命令有netstat、ss、lsof；远程监控服务器本地端口的命令有telnet、nmap、nc（可能需要安装）。123456789101112#查看3306端口的进程数netstat -lnutp|grep 3306|wc -l#查看mysql进程数netstat -lnutp|grep mysql|wc -l#ss类似ss -lnutp | grep 3306|wc -l#lsof用法lsof -i tcp:3306| wc -l#查看远端3306端口是否开通，过滤open关键字，返回1说明有该关键字，端口可通nmap 127.0.0.1 -p 3306 | grep open|wc -l#telnet需要过滤Connected关键字echo -e "\n" | telnet 127.0.0.1 3306 2&gt;/dev/null | grep Connected | wc -l函数语法1234function name()&#123; 指令 return n;&#125;其中function可以省略不写.函数的定义必须在要执行的程序前面定义或加载调用函数时，直接使用函数名即可函数执行时，会和调用它的脚本共用变量shell执行系统中各种程序的执行脚本为：系统别名-函数-系统命令-可执行文件return n是退出函数，exit n是退出shell并返回一个返回值给执行程序的当前shell如果将函数存放在独立的文件中，被脚本加载时，需要使用source带参数的函数：name 参数1 参数2case12345678910case "变量" in 值1) 指令1 ... ;; 值2) 指令2 ... ;; *) 指令3 ...esac注意缩进。while1234while &lt;条件表达式&gt;do 指令...done拓展：让shell脚本在后台运行的方法：sh 1.sh &amp;，ctrl+c：停止执行脚本或任务，ctrl+z：暂停执行脚本或任务，bg：将当前脚本或任务放到后台执行，bg可以理解为background，fg：将当前脚本放到前台执行，如果有多个任务，可以使用fg 加数字表示调出脚本任务，jobs：查看当前执行的脚本或任务，kill：关闭执行的脚本任务，即以kill % 任务编号的形式关闭脚本，这个任务编号可以通过jobs来获得。使用场景：执行守护进程，以及实现我们希望循环执行不退出的应用，或者频率小于1分钟的循环处理。for和select1234for 变量名 in 变量取值列表do 指令done ​如果”in 变量取值列表”省略，那么缺省为$@。1234for((exp1: exp2; exp3))do 指令done使用场景：有限次的循环处理1234select 变量名 [in 菜单取值列表]do 指令done如果”in 菜单取值列表”省却，那么缺省为$@。循环控制break：如果后面有正整数，表示跳出循环的层数，如果没有则跳出整个循环continue：如果后面有正整数，表示跳出到第n层继续循环，如果没有则开始下一次循环exit：后面跟正整数表示退出shell的的返回值，在下一个shell里可以通过”$?”来获取返回值return：用于在函数中作为退出函数的返回值，在下一个shell里可以通过”$?”来获取返回值数组语法1234array=(1 2 3)##推荐使用array=([1]=one [2]=two [3]=three)array[1]=a;array[2]=b;array[3]=carray=($(命令))或者array=(`命令`)数组的输出12345678##打印第二个元素（下标从0开始）echo $&#123;array[1]&#125;##打印所有元素echo $&#123;array[*]&#125;echo $&#123;array[@]&#125;##打印数组元素的个数echo $&#123;#array[@]&#125;echo $&#123;#array[*]&#125;数组赋值123456##添加或修改数组元素array[3]=four##删除数组中某个元素unset $&#123;array[1]&#125;##删除整个数组unset array]]></content>
      <categories>
        <category>编程技术</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux基础-Shell规范和执行]]></title>
    <url>%2FLinux%E5%9F%BA%E7%A1%80-Shell%E8%A7%84%E8%8C%83%E5%92%8C%E6%89%A7%E8%A1%8C.html</url>
    <content type="text"><![CDATA[Shell简述shell是一个命令解释器，通过shell解释用户命令，并调用内核（kernel），由内核调用计算机资源（硬件）对命令响应。1.Bourne Shell 包含Bourne shell（sh），Korn shell（kash），Bourne Again Shell（bash）三种类型。其中bash是各种发行版默认配置的shell。 2.C shell 包含csh，tcsh两种类型。tcsh是FreeBSD、Mac OSX等系统上的默认shell。 centos下可以通过 cat /etc/shells查看系统支持的shell，通过echo $SHELL 查看默认的shell，cat /etc/redhat-release 查看发行版本，bash --version 查看bash版本。shell规范和执行基本规范脚本第一行一般为：#! /bin/bash 或者 #! /bin/sh ，内核会根据#！幻数后的解释器来确定该用哪个程序解释这个脚本中的内容，如果不加默认就是bash。对于流程控制、分支等语句，最好先写好结构，再写内容。 执行顺序：查找环境指令ENV，该变量指定了环境文件（加载顺序通常是/etc/profile、~/.bash_profile、~/.bashrc、/etc/bashrc等），在加载了上述环境变量文件后，shell开始从上至下，从左至右地执行每一行地命令及语句，如果遇到了子脚本，就会先执行子脚本的内容，然后再返回父脚本继续执行父脚本内后续的命令及语句。 设置crond任务时，最好能在定时任务脚本中重新定义系统环境变量，否则，一些系统环境变量可能不能被加载。执行方式bash script.sh 或者 sh script.sh，启动新进程执行脚本；推荐使用。path/script.sh或者. /script.sh，启动新进程执行脚本；需要可执行权限。source script.sh或者. script.sh，在当前父进程中执行脚本，能够获取该脚本的变量值和函数返回值。sh&lt;script.sh或者cat script.sh script1.sh | sh，不常用。定义环境变量环境变量可以定义在/etc/profile、~/.bash_profile、~/.bashrc、/etc/bashrc四个文件中，加载顺序也是从前到后，类似于Java等的环境变量推荐写在/etc/profile里。规范：变量名通常大写变量可以在自身shell以及子shell中使用常用export来定义环境变量使用env默认可以显示所有的环境变量名称以及对应的值输出时使用”$变量名”，取消时使用”unset 变量名”书写crond定时任务时要注意，脚本要用到的环境变量最好先再所执行的shell脚本中重新定义如果希望环境变量永久生效，则可以将其放在用户环境变量文件或全局环境变量文件里方式：export variable=valuevariable=value;export variabledeclare -x variable=valueecho或者printf命令可以打印环境变量：echo $HOME 或者 printf &quot;$HOME\n&quot;env或者set命令可以显示当前的环境变量。定义本地变量定义在当前shell生存期的脚本中使用。方式：variable=valuevariable=”value”variable=’value’variable=$(ls)variable=`ls`variable=${variable}举个栗子:当前处在root用户家目录下：/root:key=1 $(pwd) ==&gt;key=1 /rootkey=”1 $(pwd)”==&gt;key=1 /rootkey=’1 $(pwd)’==&gt;key=1 $(pwd)key=1 pwd==&gt;key=1 /root总结：若变量为连续的数字或字符串，推荐用第一或第二种若变量内容包含空格、其他变量，推荐用第二种方式和第六种，若取其他变量推荐第六种若希望原样输出字符串，推荐使用第三种若将一个命令赋值给一个变量，可以使用第四、第五种，推荐使用第四种但是注意在用awk的时候，以上规则是不能通用的， 对于awk命令，推荐使用awk &#39;BEGIN {print &quot;&#39;$VARIABLE&#39;&quot;}&#39;，即在要取的变量外面加上单引号再加双引号的方式，这样无论变量是以上哪种方式都能保证结果的正确性，或者使用echo str | awk &#39;{print $0}‘的方式，因为echo打印规则同上面总结的是一样的。特殊变量$0：获取当前执行的shell脚本的文件名，如果执行脚本包含了路径，那么也会包括路径$n：n为正整数，如果n是大于9的数，那么需要用{}包起来，代表执行脚本时传入的第n个参数$#：获取当前shell脚本的所有参数数量$：获取所有参数，如果加上双引号，例如”$“=”$1 $2 $3……”$@：获取所有参数，不加双引号同上，如果加上双引号时，例如”$@”=”$1” “$2” “$3”……，它会将每一个参数视为独立参数，并且保留参数之间的空格$?：获取上一个指令的执行状态返回值，0成功，非零失败$$：获取当前执行shell脚本的进程号，不常用$!：获取上一个在后台工作的进程的进程号，不常用$_：获取在此之前执行的命令或者脚本的最后一个参数，不常用详情参考：man bash，然后按/，输入Special Parameters即可。关于$?：可能是上一次命令执行结果；可能是脚本exit 后面返回的结果；可能是函数return 后返回的结果。内置变量命令echoecho args功能：打印，args可以是字符串变量和变量的组合。选项：-n：不换行输出内容-e：解析转义字符如\n（换行）、\r（回车） 、\t（制表）、\b（退格）、\v（纵向制表符）evaleval args功能：当Shell程序执行到eval语句时，shell读入参数args，并将他们组合成一个新的命令，然后执行。例如：eval.sh里的内容为12[root@localhost ~]# cat noeval.sh echo \$$# ​执行下面代码，结果为$2：12[root@localhost ~]# sh noeval.sh 1 2$2\$会直接输出$，而$#取的是执行脚本传入的参数数量。所以最终结果为$2。如果使用了eval命令，则会有不同结果：12[root@localhost ~]# cat eval.sh eval "echo \$$#" ​此时结果为：12[root@localhost ~]# sh eval.sh 1 2 2 ​在上面的基础上，eval会重新解析echo $2，因此打印了第二个参数。execexec 其他命令功能：在不创建新的子进程的前提下，转取执行指定命令，指定命令执行完毕后，该进程就终止了示例：123456789[root@localhost ~]# seq 5 &gt; tmp.log[root@localhost ~]# cat exec.sh #读取tmp.logsexec &lt; tmp.logwhile read linedo echo $linedoneecho ok ​执行：1234567[root@localhost ~]# sh exec.sh 12345ok ​readread 变量名表功能：从标准输入读取字符串等信息，传跟shell程序内部定义的变量shiftshift-Shift positional parameters功能：左移参数，即$2会变成$1，$3会变成$2，同时$#也会减1，而$1会消失。示例：123456[root@localhost ~]# cat n.sh echo $1 $2if [ $# -eq 2 ];then shift echo $1fi ​执行：123[root@localhost ~]# sh n.sh 1 21 22 ​exitexit-Exit the shell功能：退出shell程序。在exit之后可以有选择地指定一个数作为返回状态。特殊扩展变量${parameter:-word}：如果parameter的变量值为空或未赋值，则会返回word字符串并替代变量的值，但是parameter依然是未赋值。用途：如果变量未定义，则返回缺省的值。1234[root@localhost ~]# echo $test[root@localhost ~]# result=$&#123;test:-unset&#125;[root@localhost ~]# echo $resultunset ​${parameter:=word}：如果parameter的变量值为空或者未赋值，并返回其值。用途：基本同上一个，但是还会给parameter赋值。123456[root@localhost ~]# echo $test[root@localhost ~]# result=$&#123;test:=unset&#125;[root@localhost ~]# echo $result unset[root@localhost ~]# echo $test unset ​${parameter:?word}：如果parameter的变量值为空或者未赋值，那么word字符串将被作为标准错误输出，否则输出变量的值。用途：用于捕捉由于变量未定义而导致的错误，并退出程序。123[root@localhost ~]# echo $test[root@localhost ~]# result=$&#123;test:?unset&#125;-bash: test: unset ​${parameter:+word}：如果parameter的变量值为空或者未赋值，则什么都不做，否则word字符串将替代变量的值。1234567[root@localhost ~]# echo $testtest[root@localhost ~]# result=$&#123;test:+unset&#125;[root@localhost ~]# echo $test test[root@localhost ~]# echo $result unset变量运算运算符,由于markdown格式显示错误，所以这里的\指代|：算术运算符意义+,-加法、减法*,/,%乘、除、取余（取模）**幂运算++,–自增、自减!,&amp;&amp;,\逻辑非（取反）、逻辑与（and）、逻辑或（or）&lt;,&lt;=,&gt;,&gt;=比较符号==,!=,=比较符号&lt;&lt;,&gt;&gt;移位运算~,\,&amp;按位取反、按位或、按位与、按位异或=,+=,-=,*=,/=,%=赋值运算 a+=1相当于a=a+1运算命令：运算操作符与运算命令意义(())用于整数运算的常用运算符，效率很高let用于整数运算，类似于(())expr可用于整数运算，但还有很多其他额外功能bcLinux下的一个计算器程序，适合整数以及小数运算$[]用于整数运算awk可以用于整数运算和小数运算declare定义变量值和属性，-i参数可以用于定义整型变量，做运算示例：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138##(())双括号运算操作[root@localhost ~]# echo $((1+1))2[root@localhost ~]# echo $((6-43))-37[root@localhost ~]# ((i=5))[root@localhost ~]# ((i=i*2))[root@localhost ~]# echo $i10[root@localhost ~]# ((a=1+2**3-4%3))[root@localhost ~]# echo $a8[root@localhost ~]# b=$((a=1+2**3-4%3))[root@localhost ~]# echo $b8[root@localhost ~]# echo $((1+2**3-4%3))8[root@localhost ~]# echo $((100*(1+100)/2))5050##比较操作1为真0为假，只适用整数[root@localhost ~]# echo $((3&lt;8))1[root@localhost ~]# echo $((3&gt;8))0[root@localhost ~]# a=8[root@localhost ~]# echo $((a++))8[root@localhost ~]# echo $((++a))10##let运算操作基本和(())相同：[root@localhost ~]# i=2[root@localhost ~]# i=i+8[root@localhost ~]# echo $ii+8[root@localhost ~]# unset i[root@localhost ~]# i=2[root@localhost ~]# let i=i+8[root@localhost ~]# echo $i10 ##expr操作[root@localhost ~]# expr 2+22+2[root@localhost ~]# expr 2 + 24[root@localhost ~]# expr 2 - 20[root@localhost ~]# expr 2 \* 24[root@localhost ~]# expr 2 / 2 1[root@localhost ~]# i=5[root@localhost ~]# i=`expr $i + 6` [root@localhost ~]# echo $i11## 判断运算一个变量是否为整数，结果为0则是，不为0则不是[root@localhost ~]# i=5[root@localhost ~]# expr $i + 6 &amp;&gt; /dev/null[root@localhost ~]# echo $?0[root@localhost ~]# i=aaa[root@localhost ~]# expr $ + 6 &amp;&gt;/dev/null[root@localhost ~]# echo $?2##判断文件类型是否为指定类型[root@localhost ~]# vim expr1.sh[root@localhost ~]# cat expr1.sh #！ /bin/shif expr "$1" : ".*\.pub" &amp;&gt; /dev/null then echo "you are using $1" else echo "pls use *.pub file"fi[root@localhost ~]# sh expr1.sh 1.pubyou are using 1.pub[root@localhost ~]# sh expr1.sh 1.pupls use *.pub file[root@localhost ~]# char="i am oldboy"##统计字符串长度[root@localhost ~]# expr length "$char"11[root@localhost ~]# echo $&#123;char&#125;|wc -L11[root@localhost ~]# echo $&#123;char&#125;|awk '&#123;print length($0)&#125;'11##打印I am oldboy linux welcome to our traning中字符数不大于6的单词[root@localhost ~]# vim word_length.sh[root@localhost ~]# cat word_length.sh for n in I am oldboy linux welcome to our trainingdo if [ `expr length $n` -le 6 ] then echo $n fidone ​[root@localhost ~]# sh word_length.sh Iamoldboylinuxtoour##awk运算操作[root@localhost ~]# echo "7.7 3.8" | awk '&#123;print $1-$2&#125;'3.9[root@localhost ~]# echo "358 113" | awk '&#123;print ($1-3)/$2&#125;'3.14159[root@localhost ~]# echo "3.9" | awk '&#123;print ($1+3)*$2&#125;'0[root@localhost ~]# echo "3 9" | awk '&#123;print ($1+3)*$2&#125;' 54##declare（同typeset）运算操作## -i可以将变量定义为整型[root@localhost ~]# declare -i A=30 B=7[root@localhost ~]# A=A+B[root@localhost ~]# echo $A37[root@localhost ~]# ##可以用read命令从标准输入中获得变量值。##read [参数] [变量名]##常用参数：-p：设置提示信息；-t：设置输入等待时间，单位默认为秒[root@localhost ~]# read -t 10 -p "please input one num:" numplease input one num:17[root@localhost ~]# read -t 10 -p "please input two num:" a1 a2please input two num:1 2[root@localhost ~]# echo $a11[root@localhost ~]# echo $a22[root@localhost ~]# cat read.sh echo -n "please input two number:"read a1 a2[root@localhost ~]# sh read.sh please input two number:1 2##下面那句作用与上面的脚本相等[root@localhost ~]# read -t 5 -p "please input two number:" a1 a2please input two number:1 2 ​条件测试综述条件测试语法说明语法1：test &lt;测试表达式&gt;test和后面的&lt;&gt;之间有一个空格语法2：[ &lt;测试表达式&gt; ]和test类似，[]和&lt;测试表达式&gt;之间至少有一个空格，推荐语法3：[[ &lt;测试表达式&gt; ]]和[]类似，与&lt;测试表达式&gt;之间至少有一个空格语法4：((&lt;测试表达式&gt;))括号和内容之间无需空格，一般用于if语句里举例：1234567#测试nginx压缩包是否存在并且是文件，如果是打印true，不是打印false[root@VM_0_8_centos ~]# test -f nginx-1.14.1.tar.gz &amp;&amp; echo true || echo falsetrue[root@VM_0_8_centos ~]# test -d nginx-1.14.1.tar.gz &amp;&amp; echo true || echo false false[root@VM_0_8_centos ~]# test -d nginx-1.14.1 &amp;&amp; echo true || echo false true详情可以查看man test获得帮助。1234567#命令类似于test 为true时执&amp;&amp;后的命令，为false时执行||后的命令[root@VM_0_8_centos ~]# [ -f nginx-1.14.1.tar.gz ] &amp;&amp; echo 11#因为前面判断为true。所以|| 后面的指令得不到执行，所以没有输出任何结果[root@VM_0_8_centos ~]# [ -f nginx-1.14.1.tar.gz ] || echo 0 [root@VM_0_8_centos ~]# [ -f nginx-1.14.1 ] || echo 0 0测试变量：1234[root@VM_0_8_centos ~]# file=nginx-1.14.1.tar.gz [root@VM_0_8_centos ~]# [ -f "$file" ] &amp;&amp; echo 11[root@VM_0_8_centos ~]# [ -f "$file" ] || echo 0例如生产环境下：系统NFS启动脚本测试：[ -f /etc/sysconfig/network ] &amp;&amp; . /etc/sysconfig/network123456789101112[ 条件1 ] &amp;&amp; &#123; 命令1 命令2 命令3&#125;#这两个等价if [ 条件1 ] then 命令1 命令2 命令3fi字符串测试操作符两个字符串是否相同、测试字符串长度是否等于0、字符串是否为null等。常用操作符说明-n “字符串”长度不为0则true，成立-z “字符串”长度为0，成立“串1” = “串2”等价于”串1”==”串2”，比较是否相等“串1”！=”串2”等价于”串1”！==”串2”，比较是否不想等字符串测试一定要把字符串加双引号之后比并且比较符号两端必须有空格整数二元比较test和[]中的符号在(())和[[]]中使用的符号说明-eq==或==也可以在test和[]中用-ne!=!=也可以在test和[]中用-gt&gt;如果&gt;在test或者[]中用需要转义\-ge&gt;=用法大体同gt-lt&lt;用法大体同gt-le&lt;=用法大体同gt比较符号两端要有空格并且尽量不要混用，例如[]中使用&lt;或[[]]中使用-ge，虽然结果可能是正确的，但是不建议]]></content>
      <categories>
        <category>编程技术</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux基础-软件安装和三剑客命令]]></title>
    <url>%2FLinux%E5%9F%BA%E7%A1%80-%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85%E5%92%8C%E4%B8%89%E5%89%91%E5%AE%A2%E5%91%BD%E4%BB%A4.html</url>
    <content type="text"><![CDATA[简述主要记录一些进阶内容。例如文本搜索命令grep，文本处理命令sed/awk，软件安装卸载，vim的高级配置等。软件卸载及安装RPM：RedHat Package Manager，红帽软件包管理器，通过一套本地数据库提供了一种更简单的软件安装管理方式。总共有两种类型，预编译包和源码包。预编译包只要在特定kernel版本下预先编译好程序（使用大多数常用编译参数），并将所需要的文件整体打包，在新主机上安装时，将文件直接复制到特定目录下即可；而二进制包需要自定义编译参数，需要先执行congfigure指令。 常用参数：123456789101112131415161718192021222324252627#安装软件-i,--install#打印详细信息-v,--verbose#打印安装过程（需要和-v一起用）-h,--hash#卸载软件-e,--erase#升级软件-U,--upgrade=&lt;packagefile&gt;+如果软件已经安装，则强行安装--replacepkge#安装测试，并不实际安装--test#忽略软件包依赖关系强行安装--nodeps#忽略软件包以及文件的冲突--force#查询参数（需要使用-q或者--query参数）#查询所有安装软件-a,--all#查询某个安装软件-p,--package#列出某个软件包所包含的所有文件-l,--list#查询某个文件的所属包-f,--file ​yum：Yellow dog Updater Modified，一个基于RPM的shell前端包管理器，能够从指定服务器上自动下载并安装或者更新软件、删除软件，最大的好处是自动解决依赖关系，RedHat和CentOS的版本为5以上的都会默认安装yum。123456789101112131415161718192021222324252627yum [options] [command] [package]#安装某个包yum install PACKAGE#安装某个软件组yum groupinstall GROUP#更新某个包yum update PACKAGE#更新某个软件组yum groupupdate GROUP#检查当前系统中需要更新的包yum check-update#显示软件源中所有可用的包yum list#显示系统已安装的包yum list installed#显示某个包的信息yum info PACKAGE#显示某个软件组的信息yum groupinfo GROUP#显示软件源宏所有的可用软件组yum grouplist#删除某个包yum remove PACKAGE#删除某个软件组yum groupremove GROUP#清除yum所生成的缓存文件yum clean ​默认情况下RedHat会因为未注册RHN而无法使用yum，删除/etc/yum.repos.d/rhel-debuginfo.repo，创建一个新的Centos-Base.repo文件，输入以下内容，注意，不同版本的内容可能不一样：123456789101112131415161718192021[base]name=CentOS-$releaseverenabled=1failovermethod=prioritybaseurl=http://mirrors.cloud.aliyuncs.com/centos/$releasever/os/$basearch/gpgcheck=1gpgkey=http://mirrors.cloud.aliyuncs.com/centos/RPM-GPG-KEY-CentOS-7[updates]name=CentOS-$releaseverenabled=1failovermethod=prioritybaseurl=http://mirrors.cloud.aliyuncs.com/centos/$releasever/updates/$basearch/gpgcheck=1gpgkey=http://mirrors.cloud.aliyuncs.com/centos/RPM-GPG-KEY-CentOS-7[extras]name=CentOS-$releaseverenabled=1failovermethod=prioritybaseurl=http://mirrors.cloud.aliyuncs.com/centos/$releasever/extras/$basearch/gpgcheck=1gpgkey=http://mirrors.cloud.aliyuncs.com/centos/RPM-GPG-KEY-CentOS-7 ​如果通过更改以上更改软件源的方式还是不行，那么需要使用rpm卸载原来的yum工具，然后重新安装CentOS的yum工具：rpm -ivh rpm-url \ rpm-url\。文本搜索命令grepgrep：Global search Regular Expression and Print out the line。Linux下非常强大的基于行的正则文本搜索工具，区分大小写。常用参数：12345678#不区分大小写-i#统计包含匹配行的行数-c#输出行号-n#反向匹配-v常用正则：. 匹配换行符以外的任意一个字符* 匹配前一个字符0次或任意多次\{n,m\} 匹配字符的重复次数至少n次，最多m次\{n,\} 匹配字符的重复次数至少n次\{n\} 匹配字符重复次数为n次^ 匹配开头字符，出现在方括号中即是取反的意思$ 匹配结束字符[] 匹配方括号内出现的任意字符\ 转义字符，用于将某语义转义为其他语义，例如^代表匹配开头，那么\^表示匹配^字符\&lt;\&gt; 匹配左右边界\d 匹配一个数字\b 匹配单词边界\B 匹配非单词边界\w 匹配数字、字母、下划线。等价于[0-9A-Za-z]\W 匹配非字母、非数字、非下划线\n 匹配一个换行符\r 匹配一个回车符\t 匹配一个制表符\f 匹配一个换页符\s 匹配任何空白字符\S 匹配任何非空白字符扩展正则表达（需要使用egrep命令）：? 匹配前一个字符0或者1次+ 匹配前一个字符1次或以上| 或() 配合|，（A|B|C），枚举一系列可能匹配的字符{} 匹配所有大括号内包含的以都好隔开的字符! 常和[]一起用，取反常用命令：12345678910111213141516171819202122232425262728293031grep '^good' test.txt #匹配test.txt文件中以good开头的行grep 'good$' test.txt #匹配以good结尾的行 grep -c '^$' test.txt #统计空行的数量grep '[Gg]ood' test.txt #匹配good或者Good的行grep '[^Gg]ood' test.txt #匹配非Good或非good的行grep 'g..d' test.txt #匹配g后面有两个字符，第四个为d的行grep '[Gg]..d' test.txt #匹配第一个字符为G或者g，第二、三位任意字符，第四个位d的行grep '[Gg][lo].d' test.txt grep 'good' test.txt #精确匹配包含这4个字符的行grep '\&lt;gold\&gt;' test.txt #匹配包含gold单词的行grep '\bgold\b' test.txt #匹配包含gold单词的行grep go*d test.txt #匹配以g开头，后面包含0或多个o，再跟一个d的单词的行grep 'g.*d' test.txt #匹配以g开头，后面有0或多个其他字符，最后一个是d单词的行grep 'gl[0-9]' test.txt #匹配以gl开头，后面紧跟任意数字的单词的行grep 'www\.baidu\.com' test.txt #匹配包含www.baidu.com的行grep 'go\&#123;2,\&#125;' test.txt #匹配g开头，至少包含2个o的单词的行grep 'go\&#123;4\&#125;' test.txt #匹配g开头，一定包含4个o的单词的行#[:alnum:] 文字数字字符#[:alpha:] 文字字符#[:digit:] 数字字符#[:graph:] 非空字符（非空格、控制字符）#[:lower:] 小写字符#[:cntrl:] 控制字符#[:print:] 非空字符（包括空格）#[:punct:] 标点符号#[:space:] 所有空白字符（新行，空格，制表符）#[:upper:] 大写字符#[:xdigit:] 十六进制数字grep ^[[:upper:]] test.txt #匹配以大写字母开头的行grep ^[[:digit:]] test.txt ​#匹配数字字符开头的行ps -ef | grep PName #将ps -ef搜寻到的进程交由grep匹配包含PName的进程文本处理工具sedsed：stream editor是一种非交互式的流编辑器，通过多种转换修改流经它的文本。默认情况下，sed并不会改变源文件本身，而只是对流经sed命令的文本进行修改，并将修改后的结果打印到标准输出中，但是-i选项会修改源文件。使用场景：常规编辑器编辑困难的文本。过于庞大的文本，比如vi一个几百兆的文件。有规律的文本修改，加快文本处理速度，比如全文替换。用法：sed [options] &#39;command&#39; file#options是set可以接收的参数 #command是sed的命令集（一共有25个） #使用-e参数和分号链接多编辑命令 #-e的作用是将下一个字符串解析为sed编辑命令 #将全局的this替换为That，将全局的line替换为LINE:sed -e &apos;s/this/That/g&apos; -e &apos;s/line/LINE/g&apos; 1.txt #上个命令等同于：sed &apos;s/this/That/g ; s/line/LINE/g&apos; 1.txt 删除12345678910111213141516#删除第一行sed '1d' 1.txt#将删除了第一行的流输入到2.txt里sed '1d' 1.txt &gt;&gt; 2.txt#删除从第1行开始的3行sed '1,3d' 1.txt#删除第一行到最后一行（清空）sed '1,$d' 1.txt#删除最后一行sed '$d' 1.txt#删除第五行以外的行sed '5!d' 1.txt#删除包含Empty的行sed '/Empty/d' 1.txt#删除空行sed '/^$/d' 1.txt替换123456789#默认情况下只替换第一次匹配到的内容sed 's/line/LINE/' 1.txt#最后一个斜杠后为替换范围，g表示全部#替换两次的line为LINEsed 's/line/LINE/2' 1.txt#替换全部的line为LINEsed 's/line/LINE/g' 1.txt #只替换开头的this为thatsed 's/^this/that/' 1.txt字符转换12#将file中的O转换为N，L转换为E，D转换为W，转换字符和被转换字符长度要相等，否则无法执行sed 'y/OLD/NEW/' file插入123456#在第二行之前插入Insertsed '2 i Insert' 1.txt#在第二行之前插入Insertsed '2 a Insert' 1.txt#在匹配行的上一行插入Insertsed '/Second/i\Insert' 1.txt读文件123456789#将/etc/passwd中的内容读出放到1.txt空行之后sed '/^$/r /etc/passwd' 1.txt#使用p命令可以进行打印，这里使用sed命令时一定要加-n参数，表示不打印没关系的行#打印出文件中指定的行sed -n '1p' 1.txt#将the替换为THE，sed实际处理了第二行，其他几行由于没有匹配所以并未真正处理，但是sed是基于流的，所以所有流过的行都打印出来了sed 's/the/THE/' 1.txt#可以使用-n只输出处理过的行sed -n 's/the/THE/p' 1.txt写文件12#将1.txt文件里的第1，2行保存到output文件里sed -n '1,2 w output' 1.txtsed脚本新建一个sed.rules文件，内容如下：1234#替换所有this为thats/this/THAT#删除空行/^$/d ​使用-f参数指定脚本应用于1.txt:sed -f sed.rules 1.txt高级替换几种空间的概念：模式空间：当前输入行的缓冲区；缓存空间（存储空间）：sed处理完的流的缓冲区。H：将模式空间的内容追加到缓存空间h：将模式空间的内容复制到存储空间，覆盖原有存储空间G：将存储空间的内容追加到模式空间g：将存储空间的内容复制到模式空间1234#读取匹配行的下一行（命令n代表下一行，参数-n代表处理过的行），再使用n命令后的编辑指令来处理该行sed '/^$/&#123;n;s/line/LINE/g&#125;' 1.txt#实现匹配a的行与匹配b的行的互换sed '/a/&#123;h;d&#125;;/b/G' Sed.txtsed常用命令：sed命令作用a在匹配行后面加入文本c字符转换d删除行D删除第一行i在匹配行之前加入文本h复制模式空间内容到存储空间H将模式空间的内容追加到缓存空间g将存储空间的内容复制到模式空间G将存储空间的内容追加到模式空间n读取下一个输入行，用下一个命令处理新的行N追加下一个输入行到模式空间并在二者间插入新行p打印匹配的行P打印匹配的第一行q退出sedr从外部文件中读取文本w追加读写文件！匹配取反s/old/new用new替换正则表达式old=打印当前行号sed常用参数：sed参数作用-e多条件编辑-h帮助信息-n不输出不匹配的行-f指定sed脚本-V版本信息-i修改源文件文本处理工具awkawk是基于列的文本处理工具，能够处理结构化的文件，也就是说都是由各种单词和空白字符组成的，这里的空白字符包括空格，制表符，以及连续的空格和制表符等。每个非空白的部分叫做域。$1表示第一个域，$0表示全部域。格式以及说明：awk [-F|-f|-v] ‘BEGIN{} //{command1; command2} END{}’ file [-F|-f|-v] 大参数，-F指定分隔符，-f调用脚本，-v定义变量 var=value &apos; &apos; 引用代码块 BEGIN 初始化代码块，在对每一行进行处理之前，初始化代码，主要是引用全局变量，设置FS分隔符 // 匹配代码块，可以是字符串或正则表达式 {} 命令代码块，包含一条或多条命令 ； 多条命令使用分号分隔 END 结尾代码块，在对每一行进行处理之后再执行的代码块，主要是进行最终计算或输出结尾摘要信息 $0 表示整个当前行 $1 每行第一个字段 NF 字段数量变量 NR 每行的记录号，多文件记录递增 FNR 与NR类似，不过多文件记录不递增，每个文件都从1开始 \t 制表符 \n 换行符 FS BEGIN时定义分隔符 RS 输入的记录分隔符， 默认为换行符(即文本是按一行一行输入) ~ 匹配，与==相比不是精确比较 !~ 不匹配，不精确比较 == 等于，必须全部相等，精确比较 != 不等于，精确比较 &amp;&amp; 逻辑与 || 逻辑或 + 匹配时表示1个或1个以上 /[0-9][0-9]+/ 两个或两个以上数字 /[0-9][0-9]*/ 一个或一个以上数字 FILENAME 文件名 OFS 输出字段分隔符， 默认也是空格，可以改为制表符等 ORS 输出的记录分隔符，默认为换行符,即处理结果也是一行一行输出到屏幕 -F&apos;[:#/]&apos; 定义三个分隔符 常用命令和功能：123456789101112131415161718192021222324打印指定域：awk '&#123;print $1,$4&#125;' Awk.txt等同于：cat Awk.txt | awk '&#123;print $1,$4&#125;'以下类似。打印全部域：awk '&#123;print $0&#125;' Awk.txt默认情况下以空白字符作为分隔符，可以指定字符为分隔符：指定"."作为分隔符：awk -F . Awk.txt使用内置变量NF统计每行的列数：awk '&#123;print NF&#125;' Awk.txt$NF表示最后一列：awk '&#123;print $NF&#125;' Awk.txt$(NF-1)代表倒数第二列：awk '&#123;print $(NF-1)&#125;' Awk.txtsubstr函数能截取指定域，substr(域，begin，end)：打印第一个域的第六个字符到最后一个字符：cat Awk.txt | awk '&#123;print substr($1,6)&#125;'打印每一行长度：cat Awk.txt | awk '&#123;print length&#125;'求列和(第三列年龄和)：cat Awk.txt | awk 'BEGIN&#123;total=0&#125;&#123;total+=$3&#125;&#123;print total&#125;'求平均年龄：cat Awk.txt | awk 'BEGIN&#123;total=0&#125;&#123;total+=$3&#125;&#123;print total/NR&#125;'vim配置优化123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147if v:lang =~ "utf8$" || v:lang =~ "UTF-8$" set fileencodings=ucs-bom,utf-8,latin1endifset nocompatible " Use Vim defaults (much better!)set bs=indent,eol,start " allow backspacing over everything in insert mode"set ai " always set autoindenting on"set backup " keep a backup fileset viminfo='20,\"50 " read/write a .viminfo file, don't store more " than 50 lines of registersset history=50 " keep 50 lines of command line historyset ruler " show the cursor position all the time" Only do this part when compiled with support for autocommandsif has("autocmd") augroup redhat autocmd! " In text files, always limit the width of text to 78 characters " autocmd BufRead *.txt set tw=78 " When editing a file, always jump to the last cursor position autocmd BufReadPost * \ if line("'\"") &gt; 0 &amp;&amp; line ("'\"") &lt;= line("$") | \ exe "normal! g'\"" | \ endif " don't write swapfile on most commonly used directories for NFS mounts or USB sticks autocmd BufNewFile,BufReadPre /media/*,/run/media/*,/mnt/* set directory=~/tmp,/var/tmp,/tmp " start with spec file template autocmd BufNewFile *.spec 0r /usr/share/vim/vimfiles/template.spec augroup ENDendifif has("cscope") &amp;&amp; filereadable("/usr/bin/cscope") set csprg=/usr/bin/cscope set csto=0 set cst set nocsverb " add any database in current directory if filereadable("cscope.out") cs add $PWD/cscope.out " else add database pointed to by environment elseif $CSCOPE_DB != "" cs add $CSCOPE_DB endif set csverbendif" Switch syntax highlighting on, when the terminal has colors" Also switch on highlighting the last used search pattern.if &amp;t_Co &gt; 2 || has("gui_running") syntax on set hlsearchendif##开启相关插件 filetype on filetype plugin on filetype indent on ##当文件在外部被修改时，自动更新该文件 set autoread ##激活鼠标 set mouse=a ##开启语法 syntax enable ##设置字体 set guifont=dejaVu\ Sans\ MONO\ 10 ##设置配色 colorscheme desert ##高亮显示当前行 set cursorline hi cursorline guibg=#00ff00 ##激活代码折叠 set foldenable ##对文中的标志进行折叠 set foldmethod=manual set foldcolumn=3 ##设置为自动关闭折叠 set foldclose=all nnoremap &lt;space&gt; @=(()foldclosed(line'.')) &lt; 0) ? 'zc' : 'zo')&lt;CR&gt; ##使用空格来替换tab set expandtab ##设置所有的tab和缩进为4哥空格 set tabstop=4 ##设定&lt;&lt;和&gt;&gt;命令移动时的宽度为4 set shiftwidth=4 ##退格键一次性删掉4个空格 set softtabstop=4 set smarttab ##关闭自动缩进 set autoindent set ai ##智能缩进 set si ##自动换行 set wrap ##设置软宽度 set sw=4 set wildmenu #显示标尺 set ruler ##设置命令行的高度 set cmdheight=1 ##显示行数 set nu set lz ##设置退格 set backspace=eol,start,indent set whichwrap+=&lt;,&gt;,h,l ##设置魔术 set magic ##关闭错误信息响铃 set noerrorbells ##显示匹配的括号 set showmatch set mat=2 ##搜索时高高亮显示搜索到的内容 set hlsearch ##搜索时不区分大小写 set ignorecase ##编码设置 set encoding=utf-8 set fileencoding=utf=8 set termencoding=utf-8 ##开启新行时使用智能自动缩进 set smartindent set cin set showmatch ##隐藏工具栏 set guioptions-=T ##隐藏菜单栏 set guioptions-=m ##显示状态栏（默认为1，表示无法显示状态栏） set laststatus=2 ##解决粘贴不换行 set pastetoggle=&lt;F9&gt; ##设置背景色 set background=dark ##设置高亮相关highlight Search ctermbg=black ctermfg=white guifg=white guibg=blackif &amp;term=="xterm" set t_Co=8 set t_Sb=^[[4%dm set t_Sf=^[[3%dmendif" Don't wake up system with blinking cursor:" http://www.linuxpowertop.org/known.phplet &amp;guicursor = &amp;guicursor . ",a:blinkon0"相关配置文件功能描述.viminfo用户使用vim的操作历史.vimrc当前用户vim的配置文件/etc/vimrc系统全局vim配置文件/usr/share/vim/vim74/colors/配色模板文件存放路径vim 常用指令：vim有三个模式，普通模式（即用vim刚刚打开某个文件时的模式）；编辑模式（按i或o键进入）；命令行模式（也叫末行模式，通常是以”:”开头，可以输入命令）[普通模式]G：光标移动道最后一行gg：光标移动到第一行，等价于1gg或1G0：数字0，表示将光标从所在位置移动到当前行的开头$：将光标所在位置移动当前行的结尾n：数字键+回车，表示将光标从当前位置向下移动n行ngg：将光标移动到n行H：将光标移动到当前窗口的第一行M：将光标移动到当前窗口的中间行L：将光标移动到当前窗口的最后一行h：和左方向键一样，光标左移一格j：下移一格k：上移一格l：右移一格/string：从光标位置开始向下搜索string?string：从光标开始向上搜索stringn：从光标位置开始向上重复前一个搜索的动作N：从光标位置开始向下重复前一个搜索的动作:g/A/s//B/g：把符合A的内容全部替换为B，斜线为分隔符，可以用@，#等替代:%/s/A/B/g：把符合A的内容全部替换为B，斜线为分隔符，可以用@，#等替代n1,n2s/A/B/gc：n1，n2为数字，表示在第n1行和第n2行间寻找A，且用B替换Yy：复制光标所在行nyy：复制从光标开始往下的n行P/p：p表示将已复制的数据粘贴到光标的下一行，P表示上一行dd：删除光标所在行ndd：删除从光标处开始的n行u：回复前一个执行过的操作.：重复前一个执行过的动作[编辑模式]i：在当前光标所在处插入文字a：在当前光标所在位置的下一个字符出插入文字I：在当前所在行的行首第一个非空格字符处插入，和A相反A：在当前所在行的行尾最后一个字符处插入，和I相反O：在当前所在行的上一行处插入新的一行o：在当前所在行的下一行处插入新行ESC：退出编辑模式，回道普通模式[命令行模式]:wq：退出并保存:wq!：退出并强制保存:q!：强制退出不保存:n1,n2, w filename：n1和n2为数字，表示将n1行到n2行的内容保存成filename这个文件:n1,n2 co n3：n1和n2为数字，表示将n1行到n2行的内容复制到n3位置下:n1,n2 m n3：表示将n1行到n2行内容挪到n3位置下:!command：暂时离开vim，到命令行里执行command命令。例如!ls /etc，此时没有退出vim:set nu：显示行号:set none：取消行号:vs filename：垂直分屏显示，同时显示当前文件和filename对应文件的内容:sp filename：水平分屏显示，同时显示当前文件和filename对应文件的内容:1+#+ESC：在可视块模式下（ctrl+v），一次性注释所选的多行:n1,n2s/#/ /gc：与上一句相反，取消注释Del：在可视块模式下，一次性删除所选内容r：在可视块模式下，一次性替换所选内容拓展：ctrl+w+n：新建分屏ctrl+w+s：新建水平分屏ctrl+w+v：新建垂直分屏vim -On file1 file2…vim -on file1 file2 …大O表示垂直分屏，小o表示水平分屏ctrl+w：切换分屏:only或者ctrl+w+o：关闭其他分屏ctrl+w+c：关闭当前分屏]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux基础-入门知识]]></title>
    <url>%2FLinux%E5%9F%BA%E7%A1%80-%E5%85%A5%E9%97%A8%E7%9F%A5%E8%AF%86.html</url>
    <content type="text"><![CDATA[概述Linux（里那科斯）是一种UNIX-like系统，其前身是minix，而minix是由一个教授由于UNIX源码被限制不方便教学而自己编写，后来由于得不到技术支持，因此Linus Torvalds开始自己编写类minix系统。目录解析“/“ : 根目录Linux文件系统的入口.也是最高级，最重要的的目录.除衍生出其它目录，还和系统的开机，还原，系统修复有的，一般要求不要把任务应用程序直接放在根目录下，如果满了，可能就登录不了了（需要注意是否日志输出在根目录下）“/bin”:基本系统所需要的命令,主要是单用户模式下，还能执行的命令。主要有cat，mv,mkdir,cp,bash ,ls“/boot”:内核和加载内核所需要的文件.grub系统引导管理器也在这个目录下,存在/boot/grub/“/dev”:在linux系统下，任何设备及接口设备，都是以文件的形式存在，设备文件存储目录.像终端.磁盘等.比较重要的有/dev/null （crontab经常把不想输出输到这里）;/dev/zero;/dev/tty;/dev/lp*;/dev/hd*;/dev/sd*“/etc”:系统的主要配置文件都放在这个目录下，一般来说，这个普通人是看不到这些文件的;这里最好也不要放可执行文件。常见的目录有如下：/etc/inittab ;/etc/init.d/;/etc/modprobe.conf ;/etc/X11/ ;/etc/fstab/ ;/etc/sysconfig/ ;/etc/init.d/开机启动脚本放在这里;/etc/xinetd.d/ super daemon启动脚本放在这里/etc/sysconfig/network/scripts/网管配置放在下面下“/home”:普通用户的目录默认存储目录.主文件夹有两种代号：~ 代表这个用户的主目录~dmtsai:代表 dmtsai的主文件夹“/lib”:库文件和内核模块存放目录.主要是开机用到，以及在/bin/;/sbin目录下命 令会调用的库函数。/lib/modules会放内核相关的模块。“/lib64”:和/lib类似，主要是64的库函数“/media”:即插即用设备的挂载点自动存放在这个目录下.像U盘,cdrom/dvd自动挂载后,就会在这个目录下.常见有/media/floppy,/media/cdrom“/mnt”:临时文件系统的挂载点目录.以前和/media一样，但有专门/media后，专门做临时挂载“/opt”:第三方软件的存放目录.什么叫第三方呢？像KDE，就是第三方的，只是集成到linux里，当然你可以放自己的东西到下面。“/proc” 是一个虚拟文件系统。放置内存中的数据，当有一个进程启动时，就有一个文件夹。比较重要的/proc/meminfo,/proc/cpuinfo可以通过这两文件查看内存和CPU情况，当然还有/proc/dma,/proc/interrupts,/proc/ioports,/proc/net/*等“/root”:Linux超级权限用户root的跟目录.单独存放，也方便在进入单用户模式的操作。“/sbin”:基本的系统维护命令,只能由超级用户使用.这些命令为开机、修复、还原系统过程所需要的。常见的命令有fdisk,fsck,ifconfig,init,mkfs“/srv”:存放一些服务器启动之后需要提取的数据.主要存放网络服务后的一些数据，如www,ftp/sys 和/proc相似，也是虚拟文件系统，主要记录内核相关，比如内核模块，内核检测的硬件信息。“/tmp”:临时文件目录,这个目录任何人可以访问，有可能需要定期清理。“/usr” 是存放可以分享与不可以动的内容，不是user的缩写，而是UNIX Software Resource 的缩写，就是UNIX操作系统的软件资源主要子目录有：/usr/X**/ X Windows数据存在于此/usr/bin/ 绝大部分用户可用命令在此/usr/include/ C/C++等的头文件与包含文件在些。如果以源码的*.tar.gz安装软件时，可能会引用下面的文件/usr/lib/ 包含应用程序函数库及目标文件，以及不被一般用户惯用的执行文件或脚 本/usr/lib64/ 与/usr/lib/相似，会对64位的/usr/local/ 本机自己安装的的软件，建议安装到这里，下面也有bin,etc,include,lib子目录，这些子目录功能大家可以想到/usr/sbin/ 非系统正常运行所需要的命令，最常见的就是网络服务器软件的daemon/usr/share/ 放共享文件的地方，基本是文本文件，可读的。子目录有/usr/share/man 在线帮助文件/usr/share/doc 软件杂项的说明文件/usr/share/zoneinfo 软件杂项的说明文件/usr/src 软件源码放在这里“/var”:存放经常变动的数据,像日志.邮件等.这个目录下的数据，需要定期清理，最好写个脚本，放在crontab里。常见的子目录：/var/cache/ 执行中的缓存文件/var/lib/ 软件本身执行的过程中，用到的数据。比如Mysql数据一般放在/var/lib/mysql/;而rpm数据则放在 /var/lib/rpm//var/lock/ 资源被锁时，放在此。有些资源只能一个程序使用，比如刻录机。/var/log/ 系统日志存在地，有可能需要定时清理/var/mail/ 系统邮件，看情况需要定时清理/var/run/ 某些程序或服务启动后，PID放在下现/var/spool/放置队列数据， 看情况需要定时清理“/lost+found” 是ext2/ext3文件系统才产生的，目的是当文件系统产生错误里，将一些丢失的片段防在这个目录下。系统解析引导过程加载BIOS（通电自检），引导系统（BIOS设定）读取MBR，运行Grub，加载初始化配置文件，启动服务，运行rc.locak，生成终端或者X Window等待登录。BIOS：每个主板都有一个自己的BIOS，启动硬件的第一步。MBR：主引导记录，BIOS会默认从硬盘的第0柱面、第0磁道、第一个扇区中读取。一个扇区=512字节，446引导程序+64地盘分区表DPT+2MBR结束位，由fWindows的disk.ext或者Linux的fdisk程序产生，不依赖操作系统。MBR记录可以修改因此可以实现多系统共存。Grub：引导操作系统程序。地址记录于MBR中，其功能是根据配置文件加载kernel镜像，并运行/sbin/init，根据/etc/inittab进行初始化工作，根据runlevel确定系统运行级别和对应服务启动脚本。引导级别引导级别在/etc/inittab文件中，但是使用systemd以后，引导级别将不再使用，而使用targets来代替，默认是：multi-user.target: analogous to runlevel 3 graphical.target: analogous to runlevel 5 一共有以下几个级别：0：关机 1：单用户模式，用于系统维护，可以在忘记root密码时进入此模式修改密码。 2：无网络链接，多用户。 3：完全多用户模式，一般使用此级别。 4：保留未使用。 5：窗口模式，多用户网络链接。 6：重启。 命令管理Linux中，一切配置皆文件。 man：&lt;order_name&gt;查看命令的帮助，如：man ls。 种类：9 常见说明 可调用的系统 函数库 设备文件 文件格式 游戏说明 杂项 系统管理员可用的命令 与内核有关的说明 man 2 reboot：查看reboot在第2章里的说明。 命令格式命令的一般格式:command [options] [arguments]说明:command:命令名。options:命令的选项，一般是一个单词或字母。有的命令有选项，有的命令没有选项。选项前面一般有“-”符号。选项是对命令参数的补充，当存在参数时才可能有选项。arguments:命令的参数，有时候选项也带参数。有的命令有参数，有的命令没有参数。[]:方括号表示可有可无的意思。[options]表示有的命令有选项，有的命令 也可能没有选项。[arguments] 表示有的命令有参数，有的命令可能没有参数。举例:(1) 没有参数的命令像 ls，pwd 都没有选项和参数。直接输入命令，回车即可执行命令。(2) 有参数没有选项的命令例如删除文件 myfile.txt 的命令，myfile.txt 就是参数:rm myfile.txt(3) 有参数也有选项的命令通过命令“rm myfile.txt”删除文件，系统会有确认提示，询问是否确定要删除。可以通过一个选项，在执行命令时不再需要确认提示，命令格式如下:rm -f myfile.txt此处的-f 就是选项，作用是进行强制删除，也就是没有确认提示。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android学习笔记一]]></title>
    <url>%2FAndroid%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B8%80.html</url>
    <content type="text"><![CDATA[基本架构Linux内核层提供各种硬件驱动，显示、音频、相机、蓝牙驱动等。系统运行时库系统特性支持，如SQLite数据库，OpenGL|ES库提供了3D绘图支持，WebKit提供浏览器内核支持。还有Android运行时环境，主要提供了一些核心库，该环境中还有Dalvik虚拟机或者ART虚拟机。应用层框架给运行于系统之上的APP提供API，系统内置软件和开发者开发的软件都是条用应用层的框架。应用层用户下载的软件就是所处该层面。四大组件Activity：活动直接与用户进行交互的界面，也就是能看到的都是处于Activity中。Service：服务可以在用户退出应用后依然保持运行，例如音乐播放。Brodcast Provider：广播接收器接受电话短信，或者厂商的消息推送等。Content Provider：内容提供器应用程序间共享，比如你下载某个软件需要读取系统电话簿中的联系人。Activity新建活动创建Activity的步骤如下：首先创建视图，即布局文件layout；给activity中加载layout；在manifest文件中注册活动。如下：创建布局：12345678910111213&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;LinearLayout xmlns:android="http://schemas.android.com/apk/res/android" android:orientation="vertical" android:layout_width="match_parent" android:layout_height="match_parent"&gt; &lt;!--定义活动1：创建活动布局--&gt; &lt;Button android:layout_width="match_parent" android:layout_height="wrap_content" android:id="@+id/button_1" android:text="点我点我"/&gt;&lt;/LinearLayout&gt;加载布局：123456789101112131415161718@Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); //创建活动2：给活动加载布局，通常情况下这里传入一个布局文件的ID，资源目录下添加的资源都会在R文件中生成一个资源ID setContentView(R.layout.first_layout); //将取出来的view类型向下转型为Button类型 final Button button = (Button) findViewById(R.id.button_1); button.setOnClickListener(new View.OnClickListener() &#123; @Override public void onClick(View v) &#123; //静态方法创造一个Toast对象，并调用show方法进行显示，第一个参数是上下文（本例子中活动本身就是一个context对象）， //第二个参数是显示的文本，第三个是显示时长，有两个内置常量可以选择 Toast.makeText(FirstActivity.this, "谢谢点击",Toast.LENGTH_SHORT).show(); //执行下面的方法会销毁活动 //finish(); &#125; &#125;); &#125;注册活动：123456789101112131415161718&lt;!--创建活动3：在manifest文件中注册活动，给主活动指定的label不仅会成为标题中的内容，也会成为启动器中显示的名称--&gt; &lt;application android:allowBackup="true" android:icon="@mipmap/ic_launcher" android:label="@string/app_name" android:roundIcon="@mipmap/ic_launcher_round" android:supportsRtl="true" android:theme="@style/AppTheme"&gt; &lt;!--外围指定包名了所以这里可以使用这种方式--&gt; &lt;activity android:name=".FirstActivity" &gt; &lt;intent-filter&gt; &lt;!--标记是一个主要的活动--&gt; &lt;action android:name="android.intent.action.MAIN"&gt;&lt;/action&gt; &lt;!--表明首先启动这个活动--&gt; &lt;category android:name="android.intent.category.LAUNCHER"&gt;&lt;/category&gt; &lt;/intent-filter&gt; &lt;/activity&gt; &lt;/application&gt;新建menu步骤：新建菜单布局文件；创建菜单；对菜单事见进行响应。新建菜单布局文件：1234567891011121314&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;menu xmlns:android="http://schemas.android.com/apk/res/android"&gt; &lt;!--定义菜单1：每个item都是一个菜单项--&gt; &lt;item android:id="@+id/add_item" android:title="Add" /&gt; &lt;item android:id="@+id/remove_item" android:title="Remove" /&gt;&lt;/menu&gt;创建菜单-在活动中重写onCreateOptionsMenu方法：1234567@Override public boolean onCreateOptionsMenu(Menu menu) &#123; //定义菜单2：使用ctrl+o进行方法重写，第一个参数是通过哪个资源文件创建菜单，第二个参数就是方法中传入的参数。 getMenuInflater().inflate(R.menu.main,menu); //显示菜单 return true; &#125;对菜单的每个item进行响应-重写onOptionsItemSelected方法：1234567891011121314@Override public boolean onOptionsItemSelected(MenuItem item) &#123; //定义菜单3：根据item的id进行响应 switch (item.getItemId()) &#123; case R.id.add_item: Toast.makeText(this, "点击了新增按钮", Toast.LENGTH_SHORT).show(); break; case R.id.remove_item: Toast.makeText(this, "点击了移除按钮", Toast.LENGTH_SHORT).show(); break; default: &#125; return true; &#125;活动交互显式intent1234567891011121314151617@Overrideprotected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); //创建活动2：给活动加载布局，通常情况下这里传入一个布局文件的ID，资源目录下添加的资源都会在R文件中生成一个资源ID setContentView(R.layout.first_layout); //将取出来的view类型向下转型为Button类型 final Button button = (Button) findViewById(R.id.button_1); button.setOnClickListener(new View.OnClickListener() &#123; @Override public void onClick(View v) &#123; Intent intent = new Intent(FirstActivity.this, SecondActivity.class); //如果添加了其他category，那么在manifest.xml文件中的intent-filter也要加上该策略 //intent.addCategory("MY_CATEGORY"); startActivity(intent); &#125; &#125;);&#125;隐式intent123456789&lt;activity android:name=".SecondActivity"&gt;&lt;!--指定action的名字，要和activity中的intent的action对应--&gt;&lt;intent-filter&gt; &lt;action android:name="activityIntent"/&gt; &lt;category android:name="android.intent.category.DEFAULT"/&gt; &lt;!--与activity中的策略对应--&gt; &lt;!--&lt;category android:name="MY_CATEGORY"/&gt;--&gt;&lt;/intent-filter&gt;&lt;/activity&gt;活动中的action名字和category名字要和manifest.xml中的一致：123456789101112131415161718@Overrideprotected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); //创建活动2：给活动加载布局，通常情况下这里传入一个布局文件的ID，资源目录下添加的资源都会在R文件中生成一个资源ID setContentView(R.layout.first_layout); //将取出来的view类型向下转型为Button类型 final Button button = (Button) findViewById(R.id.button_1); button.setOnClickListener(new View.OnClickListener() &#123; @Override public void onClick(View v) &#123; //隐式组件调用 Intent intent = new Intent("activityIntent"); //如果添加了其他category，那么在manifest.xml文件中的intent-filter也要加上该categoty，android.intent.category.DEFAULT的category会在调用的时候默认添加 //intent.addCategory("MY_CATEGORY"); startActivity(intent); &#125; &#125;);&#125;隐式intent还有其他用法，例如使用一些系统内置action，会调用浏览器打开百度主页：12345//使用action_view的actionIntent intent = new Intent(Intent.ACTION_VIEW);//使用uri.parse方法将一个网址字符串解析为一个uri对象intent.setData(Uri.parse("http://www.baidu.com"));startActivity(intent);或者新建自定义活动用来响应http数据协议：123456789&lt;!--自定义第三个活动用来响应http数据协议，注意：只有当category包含BROWSABLE类型时，acheme才可以为http--&gt; &lt;activity android:name=".ThirdLayoutActivity"&gt; &lt;intent-filter&gt; &lt;action android:name="android.intent.action.VIEW"/&gt; &lt;category android:name="android.intent.category.DEFAULT"/&gt; &lt;category android:name="android.intent.category.BROWSABLE"/&gt; &lt;data android:scheme="http"/&gt; &lt;/intent-filter&gt; &lt;/activity&gt;这样一来，当点击按钮的时候在选择列表中就可以看到自己的应用程序，当然它打开的只是第三个活动，而不能显示百度主页。还可以使用tel协议打开拨号界面：123Intent intent = new Intent(Intent.ACTION_DIAL);intent.setData(Uri.parse("tel:10086"));startActivity(intent);intent传递数据活动之间通过intent传递数据;12345//第一个活动放入数据String data = "hello second";Intent intent = new Intent(FirstActivity.this, SecondActivity.class);intent.putExtra("extra_data", data);startActivity(intent);取数据：123456789@Overrideprotected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); Intent intent = getIntent(); //可以通过getIntExtra,getStringExtra等取出数据 String extraData = intent.getStringExtra("extra_data"); Log.d(TAG, extraData); setContentView(R.layout.second_layout);&#125;intent返回数据还可以在第二个活动中给第一个活动返回数据，首先需要修改第一个活动的启动方式：123456//第一个活动放入数据String data = "hello second";Intent intent = new Intent(FirstActivity.this, SecondActivity.class);intent.putExtra("extra_data", data);//使用获取返回值的方式启动其他活动startActivityForResult(intent,1);第二个活动里放入返回数据：1234Intent resultIntent = new Intent();resultIntent.putExtra("data_return","hello first");setResult(RESULT_OK, resultIntent);finish();重写第一个活动的方法来接收返回参数：1234567891011@Overrideprotected void onActivityResult(int requestCode, int resultCode, @Nullable Intent data) &#123; //启动活动时传入的请求码 switch (requestCode)&#123; case 1: //返回数据时的响应码 Log.d(TAG, data.getStringExtra("data_return")); break; default: &#125;&#125;可以重写onBackPressed方法来当用户按下返回键的时候返回数据:1234567@Override public void onBackPressed() &#123; Intent resultIntent = new Intent(); resultIntent.putExtra("data_return","hello first"); setResult(RESULT_OK, resultIntent); finish(); &#125;]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySql-Explain随记]]></title>
    <url>%2FMySql-Explain%E9%9A%8F%E8%AE%B0.html</url>
    <content type="text"><![CDATA[简述用于记录一下mysql工作中的Explain用法，随时更新。explain作用：分析查询语句的执行计划；示例：在查询语句前面加explain即可字段说明（可能随着版本的不同，字段数量也可能不同）：id：id相同时，id是sql执行的顺序；id不同是，id越大的值越先执行；id相同的可以认为一组；select_type：SIMPLE:简单查询，不使用UNION或子查询等；PIRIMARY:包含子查询时，最外层的select被标记为PRIMARY；UNION:UNION中的第二个语句；DEPENDENT UNION:UNION中的第二个语句或外面的语句，取决于外面的查询；UNION RESULT:UNION的结果；SUBQUERY:子查询的第一条select语句（独立子查询）；DEPENDENT SUBQUERY:子查询中第一条select语句（相关子查询）；DERIVED:派生表；UNCACHEABLE SUNQUERY:一个子查询的的结果不能被缓存，必须重新评估外链接的第一行；table：表名，也有可能形式的派生表名；type：扫描类型，mysql在表中找到数据的方式；ALL：全表扫描；index：扫描索引树；range：只检索给定的行；ref：表示上述表的连接匹配条件；eq_ref：类似ref，只不过使用的索引时唯一索引；const、system：对查询进行优化，转化为一个常量。例如根据主键查询，system表示查询的表只有一行；NULL：不需要访问表或索引。possible_keys：涉及到的索引，但是不一定用到；key：mysql决定使用的索引，如果没有就是NULL，如果想强制mysql使用或者忽视possible_keys中的索引，在查询中使用FORCE INDEX、USE INDEX或者IGNORE INDEX;key_len：索引使用的字节数，可以通过该列计算查询中的使用的索引的长度。注意显示的是索引字段的最大可能长度，而不是实际使用长度；ref：表示上述表的连接匹配条件；rows：根据表统计信息以及索引选用情况估算而出需要读取多少行；extra：解决查询的详细信息：Using Where：使用了索引信息，但是并没有读到实际数据，可能还要进行回表真正读数据；Using index condition：使用了索引条件并且读取到了实际数据；Using temporary：需要使用临时表存储结果集；Using filesort：无法利用索引完成的排序操作；Using join buffer：强调了在获取链接条件时没有使用索引，并且需要连接缓冲区来存储中间结果；Impossible where：强调了where语句会导致没有符合条件的行；select tables optimizer away：仅通过使用索引，优化器可能从聚合函数结果中返回一行；Using Where；Using index：表明使用索引覆盖。]]></content>
      <categories>
        <category>编程技术</category>
      </categories>
      <tags>
        <tag>MySql</tag>
        <tag>随记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySql-实战45讲二]]></title>
    <url>%2FMySql%E5%AE%9E%E6%88%9845%E8%AE%B2%E4%BA%8C.html</url>
    <content type="text"><![CDATA[字符串索引两种方式：整个字段（消耗内存多）字段前几个字符（消耗内存少，可能会导致扫描次数变多）语法：alter table t add index index1(name);alter table t add index index2(name(n));两种不同方式的索引结构如下：上图用整个字段作为索引的结构，B+树的叶子结点之间有链指针；上图n=6时，前6个字符作为索引。第一种占用空间比较大，但是扫描次数比较少，如果一个select * from t where nam = &#39;zhangsan&#39;语句，使用第一种索引方式，找一次，然后再回表根据ID查出完整数据即可；如果使用第二种索引方式，根据最左前缀原则，在本例子中，由于第一个就是zhangsan，因此也只需要找一次，但是如果zhangsan和zhangsi换一个位置，那么第二个索引就需要找两次了。优化方案：索引长度调整为需要的长度，根据前面基础入门里的理论，索引的区分度越大越好，即不同的数据越多越好。可以使用select count(discount name) as L from t找出总共有多少条数据，然后使用：select count(distinct left(name,4)) as L1,select count(distinct(name,5)) a L2... from t。最后使用L1和L2去除以总条数，找出比例大于等于95%，损失数小于5%的字段长度将一些数据倒序存储，查询的时候可以通过where name = reverse(name);表中多加一个字段，使用crc32函数（或者其他任意哈希函数）将字符串生成的校验码存储到新加字段上（保证唯一即可），查询的时候可以根据名字字段和新加的字段作为条件。MySql执行效率波动可能是在flush脏页（即内存和磁盘中数据不一致的数据页）。发生情况：redo log空间不足，必须先将redo log中记载的对应脏页数据flush到磁盘上去；内存不足，需要淘汰一些数据页，淘汰之前需要将内存中的脏页flush到磁盘上去；系统空闲时；系统慢关闭时。所以，如果一次查询要淘汰的脏页个数太多，会导致查询响应时间明显变长；或者日志写满了导致更新全部堵住。InnoDB使用缓冲池（buffer pool）管理内存，缓冲池中的内存页要么是干净页，要么是脏页，要么就是尚未使用的。当InnoDB读入的数据页不在内存中时，就必须到缓冲池中申请一个数据页，如果没有未使用的，就必须把某个最久没使用的数据页从内存中淘汰掉，干净页可以直接释放然后复用，脏页必须先刷到磁盘才能复用。InnoDB刷脏页的控制策略：innodb_io_capacity这个参数会告诉innodb服务器的磁盘能力，建议设置成磁盘的IOPS。磁盘的IOPS可以通过fio这个工具来测试随机读写：1fio -filename=/root/1.txt -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime =10 -group_reporting -name=mytestInnnoDB根据脏页比例和redo log写盘速度会单独算出两个数字，innodb_max_dirty_pages_pct是脏页比例上限，默认是75%，假设当前脏页比例为M，首先需要根据如下公式计算一个0～100之间的数字v1：F1(M){ if M&gt;=innodb_max_dirty_pages_pct then return 100; return 100*M/innodb_max_dirty_pages_pct; } InnoDB每次写入的日志都有一个序号，当前写入的序号跟checkpoint对应的序号之间的差值假设为N。InnoDB会根据这个N算出一个范围在0～100之间的数字v2，N越大那么计算出来的值页越大。然后取v1和v2其中较大的值获得百分比数（除以100）乘以innodb_io_capcaity的数值即是innodb刷脏页的速度。优化方案：合理设置innodb_io_capacity，并且关注脏页比例不要接近75%（Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total)。查询代码参考：123select VARIABLE_VALUE into @a from global_status where VARIABLE_NAME='Innodb_buffer_pool_pages_dirty';select VARIABLE_VALUE into @b from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_total';select @a/@b;在flush的时候，脏页连同附近紧挨着的脏页会一同被刷到磁盘，并且这个作用是会蔓延的。可以通过innodb_flush_neighbors这个参数设置，推荐IOPS只有几百的机械硬盘打开这个参数，能够减少随机IO，即设置为1，使用SSD硬盘的设置为0，即不需要找邻居，只刷自己就好。表数据和表文件从mysql5.6.6以后，innodb_file_per_ table就被设置为ON，开启这个选项表示表数据存储在一个以.ibd为后缀的文件中，也推荐设置为ON，如果是在文件中，使用drop table会删除这个数据文件，如果off的话放在共享表空间中，即使表删除空间也不会回收。数据在删除的时候，会把这一行删除的数据标记为可复用，但是并不是真正缩小的空间。例如删除了ID=5的这一行，那么会标记为可复用，如果这时候插入了ID=6的记录，那么5这一行空间就不能被复用了，成为“空洞”。如果删除了整个数据页或者表，空间同样不会变小，只是说当前数据页可以任意复用而已。如果插入数据不是按照索引递增顺序插入的，同样也会造成空洞。同样，更新数据也可以理解为先删除后插入，有可能造成空洞。如果相邻两个页的利用率都不高，那么会将两个页的数据合并到其中一个页上，另一个数据也就会被标记为可复用。如果此时新建一个表，将原来产生“空洞”的表数据按照主键递增的顺序插到到新表中，就能去掉数据空洞了，提高空间利用率。alter table t engine=InnoDB就能起到这个作用，只不过这个新表不需要自己建，它会自动完成建立新表、交换表名和数据、删除旧表的操作。在mysql 5.6.6以后，引入了Online DDL，这个操作流程进行了优化：建立临时文件，扫描表A的所有数据页；用数据页中的数据生成B+树，存储到临时文件中；在前两步操作中，所有对表A的操作都会记录到redo log中；临时页建立完成后，会将redo log中对A的操作应用到临时文件中；用临时文件替换表A的数据文件。在alter语句启动的时候需要获取MDL写锁，但是真正拷贝数据的时候，写锁会退化成为读锁，这样就不会阻塞到对表的增删改操作，同时，这个读锁也会阻塞其他DDL的操作。需要补充的是，这个操作很消耗I/O和CPU资源。Online和Inplace：在5.6.6以前，拷贝数据出来的地方在server层，名为tmp_table;而引入Online以后，数据拷贝出来的地方就在innodb内部，对于server层来说，没有把数据挪到临时表，所以是一个原地操作，就是“inplace”的来源。alter table t engine=InnoDB的隐含语句为：alter table t engine = InnoDB ,ALGORITHM=inplace;对应的就是copy方式：：alter table t engine = InnoDB, ALGORITHM=copy;在重建表时，看起来inplace和online逻辑差不多，但是实际上如果是online的，那么必定是inplace的，而inplace方式不一定是online，例如给一个字段加全文索引（FULLTEXT index）或空间（SPATIAL index）索引：alter table t add FULLTEXT(column)。拓展：从5.6.6开始，alter table t engine = InnoDB（也就是recreate）；analyze table t是对索引重新进行统计，加了MDL锁；optimize table t等于recreate + analyze。COUNT()争取姿势COUNT()实战实现方式：count（）是一个聚合函数，低于返回的结果集，一行行地判断，如果count函数的参数不是NULL，累计值就加1。count(1)：遍历表，但是不取值，server层对于每一行数据都会放一个1进入，判断是不可能为空的，按行累加；count(id)：遍历表并且取值，server层拿到id后判断是不可能为空的，就按行累加；count(*)：不会把全部字段提取出来，即不取值。count（*）肯定不为null，按行累加；count(字段)：遍历表且取值，如果字段是“not null”的话，一行行地从记录里读数据，判断不能为null，按行累加；如果允许为null，执行的事耦，判断到有可能为null，还要把值取出来再判断一下。效率：count(字段)&lt;count(主键ID)&lt;count(1)约等于count(*)即：srver层要什么，引擎就给什么；InnoDB只给必要的值count()就是统计行数，mysql做了优化。如果使用count（\）还是比较慢，可以考虑将每个表总数据量数据放到redis里或者数据库里，最好是放数据库，因为插入或者删除数据时可以通过事务将数量修改同步到专门记总数量的表里，redis目前则实现不了。order bysort_buffer：mysql会为每个请求线程分配一块内存用于排序。例如，要执行一个sql：select city,name,age from t where city = &#39;hangzhou&#39; order by name limit 1000;主键id，索引city。mysql会有两种算法来进行排序：全字段排序：初始化sort_buffer，放入city，name，age三个字段，然后到city索引上读取第一个符合city=‘hangzhou’的ID，然后到ID索引上读取city，name，age的值放入sort_buffer，然后取下一个，依次循环，最后取前1000行返回给客户端；如果SET max_length_for_sort_data = 16;max_length_for_sort_data是用来标记排序的字段总的数据长度的，假如name，city，age三个字段之和大于16，那么mysql会换一种排序算法。rowid排序：初始化sort_buffer，放入name和id两个字段，首先读取city索引上第一个符合city=’hangzhou’的id，然后到ID索引上读取city，name，age的值放入sort_buffer，然后取下一个，依次循环，最后取前1000行的id到id索引上取得city，name，age的值返回给客户端。全字段排序，参加排序的是4000行，rowid排序参加排序的也是4000行，但是会多1000行去id索引树取数据的过程。可以使用如下语句查看：123456789101112/* 打开optimizer_trace,只对本线程有效 */mysql&gt; set optimizer_trace='enabled=on';/* 保存初始值*/mysql&gt; select VARIABLE_VALUE into @a from performance_schema.session_status where variable_name='Innodb_rows_read';/* 执行查询语句*/mysql&gt; select city , name ,age from test_16 where city = 'hangzhou' order by name limit 1000;/* 查看optimizer_trace结果*/mysql&gt; select * from information_schema.optimizer_trace\G;/* 保存执行之后的值*/mysql&gt; select VARIABLE_VALUE into @b from performance_schema.session_status where variable_name='Innodb_rows_read';/* 计算读取了多少行数据*/mysql&gt; select @b-@a; ​在filesort_summary里，可以看到如下结果（该表匹配数据仅有4条，懒得造数据了，所以在这里mysql会使用全表扫描，使用explain 可以看到type = all，可以使用强制索引force index(city)保证using index condition……）:rows表示匹配的数据行，examined_rows表示读取的行数，此处是5行，select @b-@a在InnoDB的条件下查询的可能是6行，因为查询optimizer_trace的时候要用到临时表，InnoDB把数据从临时表取出来时，会让Innodb_rows_read的值加1，可以将internal_tmp_disk_storage_engine设置成MyISAM。number_of_tmp_files表示使用了多少个临时文件，如果sort_buffer_size足够完成排序，那么会优先在内存中完成，所以上图为0。mysql会优先使用全字段排序，rowid由于要回表读磁盘，所以效率比较低。如果不想有Using filesort，那么可将索引city替换为联合索引(city,name)，由于索引本身保证了有序，在加上最左前缀匹配原则，效率可以进一步提高（因为不需要在sort_buffer里进行排序了），当然这种方式并不适用于select city,name,age from t where city in (&#39;hangzhou&#39;,&#39;anqing&#39;) order by name limit 1000，因为这种联合索引只能保证在’hangzhou’或者’anqing’中是有序的，所以这种in类型的就无法保证有序了。随机查询数据12345678910111213141516171819CREATE TABLE `words` ( `id` int(11) NOT NULL AUTO_INCREMENT, `word` varchar(64) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB;delimiter ;;create procedure idata()begin declare i int; set i=0; while i&lt;10000 do insert into words(word) values(concat(char(97+(i div 1000)), char(97+(i % 1000 div 100)), char(97+(i % 100 div 10)), char(97+(i % 10)))); set i=i+1; end while;end;;delimiter ;call idata();算法一：1select word from words order by rand() limit 3;缺点：需要临时表，且需要在临时表上使用rowid排序，首先扫描全表（10000行），放入临时表，然后初始化sort_buffer，并从内存临时表中取出rowid和需要参与排序的数据放入sort_buffer（10000行），排序完取出需要的rowid到内存临时表中获得需要的信息。这里的rowid就是数据的位置信息，如果没有指定主键，那么系统会自动生成一个6字节的rowid，需要注意的是，如果配置tmp_table_size的大小，一旦内存临时表大小超过该限制，那么内存临时表就会转成磁盘临时表，对于磁盘临时表的引擎，是由参数internal_tmp_disk_storage_engine来控制的。算法二：123select max(id),min(id) into @M,@N from t ;set @X= floor((@M-@N+1)*rand() + @N);select * from t where id &gt;= @X limit 1; ​特点：效率高，max(id)和min(id)都不需要扫描索引，而第三步的select也可以用索引快速定位。但是实际上，这个算法因为ID中间可能有空洞，因此选择不同行的概率不一样。算法三：123456select count(*) into @C from t;set @Y = floor(@C * rand());set @sql = concat("select * from t limit ", @Y, ",1");prepare stmt from @sql;execute stmt;DEALLOCATE prepare stmt;特点：解决了算法二里面概率不均匀的问题，由于需要扫描C+Y+1行因此执行代价比算法二要稍高。算法四：1234567select count(*) into @C from t;set @Y1 = floor(@C * rand());set @Y2 = floor(@C * rand());set @Y3 = floor(@C * rand()); select * from t limit @Y1，1； // 在应用代码里面取 Y1、Y2、Y3 值，拼出 SQL 后执行select * from t limit @Y2，1；select * from t limit @Y3，1；查询中的坑条件查询中的函数在查询语句中，即使是单表查询，如果没有用索引或者破坏了索引的有序性，也会导致查询效率极低。例如如下语句：1mysql&gt; select count(*) from tradelog where month(t_modified)=7;此时在t_modified这个字段上和主键都存在一个索引，但是由于函数破坏了索引的有序性，导致优化器放弃了走树搜索功能，但是它依然会使用索引，遍历主键索引和t_modified索引发现主键索引大小比t_modified索引小，所以依然会使用t_modified，只不过使用的是全索引扫描。就算不使用函数，使用呢select * from t where id + 1 = 10000的这种形式，优化器也会“偷懒”，不使用树搜索，不过可以改为select * from t where id = 10000 - 1。隐式类型转换假如现在表中有个orderId为varchar类型，当使用如下语句时，会触发类型转换：1mysql&gt;select * from t where orderId=1112345;使用explain可以看到，这条语句使用了全表扫描（type=all）。因为上面的语句等同于：1mysql&gt;select * from twhere CAST(orderId as signed int)=1112345隐式调用了函数操作，使得优化器放弃调用了树搜索。对于类型转换规则，参考官方文档：MySql5.7:https://dev.mysql.com/doc/refman/5.7/en/type-conversion.html由此可知：如果当索引类型为int，但是输入的条件为varchar，例如：1mysql&gt;select * from t where id = '11111';由于该字符能直接转换为int，所以不会走全表扫描，还是会走索引。隐式编码转换假如现在有两张表，一个订单表order，一个订单详情表order_detail表，order表中有一个字段order_detail_id为varchar类型，用于关联order和order_detail表。这个时候我们通过订单id去查订单详情，用的就是如下类似语句：1select od.* from order o , order_detail od where od.id=o.order_detail_id and o.id = 4;这个语句中，order为驱动表，order_detail为被驱动表，order_detail_id为关联字段。它的执行步骤是：根据订单id为4找出订单表中的一行数据；在第一步中取出的数据里拿到order_detail_id的值；根据order_detail_id去order_detail表里取出数据。如果在第三步里，两个表的字符集类型不一致，假如订单表里的order_detail_id为utf-8mb4字符集，而详情表里为utf-8字符集，那么就会触发编码转换，utf-8会向上转换为utf-8mb4，因为utf-8其实就是utf-8mb3的别名，它是mb4的子集，也就是说转换为了如下形式：1select * from order_detail where CONVERT(id USING utf8mb4)=o.order_detail_id;也就是说，如果驱动表的字符集类型大于被驱动表的字符集类型，那么会对查询条件使用函数转换导致全表扫描，如果驱动表的字符集类型小于被驱动表的字符集类型，那么函数转换就加在输入参数上，这样就可以使用索引；如下形式就可以使用索引：1select * from order_detail where id = CONVERT(order_detail_id USING utf8mn3);查询慢等MDL锁有一个线程持有MDL锁，阻塞了查询语句。例如：1234-- sessionAlock table t write;-- seeesionBselect * from t where id = 1234;查看方式：1show processlist;结果中带有Waiting for table metadata lock即代表该查询语句被MDL锁阻塞，但是持有锁的语句正处于sleep的状态；处理方式：首先需要开启performance_schema=on，如果不确定有没有开启可以使用show variables like &#39;performance_schema&#39;，在mysql的配置文件my.cnf里的mysqld下添加performance_schema=on，开启该选项大约有10%的性能损耗。然后通过以下命令查出进程id，kill即可：1select blocking_id from sys.schema_table_lock_waits;等flush通过show processlist查出来的结果里有id这个字段，可以通过这个字段查看具体信息：select * from information_schema.processlist where id=1;如果状态为waiting for table flush，表示flush操作被阻塞。通常情况下，flush操作有：123flush tables t with read lock;flush tables with read lock;指定表t代表关闭表t，如果没有指定就是关闭所有打开的表。通常情况下fush操作也是很快的，但是如果它们被阻塞了，可以在show processlist中看到，通过方法一中的命令找出pid然后kill即可。等行锁123456-- sessionAbegin;update t set c=c+1 where id =1;-- sessionBselect * from t where id = 1lock in share mode;很明显A一直未提交事务，导致当前读的sessionB阻塞。通过show processlist;可以看到session的state是statistics。如果是5.7的mysql，可以使用如下命令，mysql&gt; select * from t sys.innodb_lock_waits where locked_table=&#39;test.t&#39;\G可以看到blocking_pid，使用kill 命令杀死即可。慢查询有的时候会出现如下这种情况：123456789-- session Astart transaction with consistent snapshot;-- session B（执行100万次）update t set c = c+1 where id = 1;-- session Aselect * from t where id = 1;select * from t where id = 1 lock in share mode;上面的语句中，事务A启动时启动了一个一致性视图，然后B执行了一个100万次的增加，生成了100万次的undo log(3变成2，2变成1等等)，此时在A中再次执行一致性读查询即没有加S锁的那条语句，那么查出来的结果需要在当前结果的基础上执行100万次的redo log，得到1返回，而加了S锁的语句直接返回的当前结果。还有一种慢查询：假如此时表t中字段b为varchar(10)类型，b同时也是一个索引，其中有10万条数据都是1234567890，而此时执行：select * from t where b= &#39;1234567890aab&#39;的过程也十分慢，步骤如下：在引擎层，做字符阶段，只截出10位进行匹配；通过b索引查出符合条件的10万条数据；回表，再查出10万条完整数据；每次回表查出数据到server层发现不符合条件；返回空。mysql对幻读的处理记录一下幻读的一个场景（这是假如产生幻读的场景用以引出mysql的解决方案，实际上mysql已经解决该场景）：1234567891011121314151617--表t（id,c,d）中数据(5,5,5)，(0,0,0)-- session abegin;select * from t where d=5 for update;-- session bupdate t set d = 5 where id = 0;-- session aselect * from t where d=5 for update;-- session cinsert into t value (1,1,5)-- session aselect * from t where d = 5 for update;commit;a第一次查询的时候，只有(5,5,5)一条数据;第二次查询，有(0,0,5)(5,5,5)两条数据；第三次查询，有(0,0,5)(5,5,5)(1,1,5)三条数据。由于三次使用的都是当前读并且加上写锁，因此会出现这种幻读情况，它们会有以下问题：破坏语义：在a第一次查询的时候，只是对id等于5的那一行加了写锁，这意味着可以将b中，id=0的那一行的d改为5，破坏了a第一次查询时“对所有d=5的行加上写锁”的声明；破坏数据一致性：包括日志和数据的一致性。新加以下两行操作：123456789101112131415161718192021--表t（id,c,d）中数据(5,5,5)，(0,0,0)-- session abegin;select * from t where d=5 for update;-- session bupdate t set d = 5 where id = 0;-- 新加update t set c =5 where id = 0;-- session aselect * from t where d=5 for update;-- session cinsert into t value (1,1,5);-- 新加update t set c = 5 where id = 1;-- session aselect * from t where d = 5 for update;commit;由于a最后提交，最后实际的数据为：(0,5,100),(1,5,100),(5,5,100)，而按照我们预期结果应该是(0,5,5),(1,5,5),(5,5,100)。gap lock：为解决幻读而引入，假如插入(1,1,1)（5,5,5）(9,9,9)三条数据，那么间隙就是(负无穷，1)，(1,5)，(5,9)，(9,正无穷)这四个区间，对同一个间隙加的锁之间没有冲突，但是往间隙插入一条数据会产生冲突，只在可重复读（RR）隔离级别下有效。next-key lock：间隙锁和行锁的合称，是前开后闭区间，即(1，5]，(5，9]等。缺点：锁范围更大导致了性能下降；并发高的时候导致死锁，举例来说：会话A和会话B同时对id在(1,5)之间的间隙锁加锁，当A和B同时插入一条id为4的数据，A和B相互等待导致死锁。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>MySql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySql-实战45讲一]]></title>
    <url>%2FMySql%E5%AE%9E%E6%88%9845%E8%AE%B2%E4%B8%80.html</url>
    <content type="text"><![CDATA[基本架构一条sql语句在mysql中的执行过程：客户端-连接器-分析器-优化器-执行器-存储引擎大体来说。mysql可以分为server层和存储引擎层，连接器、分析器、优化器、执行器都属于server层。功能介绍：连接器：与客户端建立、维持连接并获取权限和管理连接分析器：实际上连接器会首先查询缓存，但是缓存一般弊大于利，所以不推荐使用，并且在mysql 8的版本里缓存直接移除了。分析器会做词法识别（即识别出要查询的列、表等）、语法分析优化器：在表里有多个索引的时候，决定使用哪个索引；以及在表关联的时候，决定各个表的连接顺序执行器：判断执行权限，然后根据表的引擎定义，去使用引擎提供的接口，一行一行去取数据，如果符合条件则将这行存在结果集中，如果不符合则跳过取下一行redo log：WAL(Write-Ahead Logging)技术的组成之一。每当有一条记录需要更新的时候，InnnoDB引擎会先把变更记录写到redo log里，并更新内存。引擎会在适当时候将该操作记录更新到磁盘。redo log大小固定，写到末尾回从开头循环写，其中有两个标记：write pos当前记录的位置，一边写一边后移，checkpoint是当前要擦除的位置，也是往后推移并循环的。如果checkpoint追上了write pos则需要擦除记录了。redo log作用：creash-safe，InnoDB保证即使数据库发生了异常重启，之前提交的记录都不会丢失。undo log：在数据修改的时候，不仅记录了redo，还记录了相对应的undo，如果因为某些原因导致事务失败或回滚了，可以借助该undo进行回滚，它没有日志文件，只是一个逻辑日志，可以理解为当delete一条数据时，undo log里记录了insert一条数据，undo log借助redo log实现持久化保护。undo log作用：提供回滚和多个行版本控制(MVCC)。binlog：binlog跟redo log主要不同之处在于不限于InnoDB，它是面向server层的，而server层可以调用不止一种类型的存储引擎。binlog是采用的追加写入的方式记录日志。它有两种模式：row格式会记录行的内容，statement格式是记录sql语句。执行过程如下：其中，红色部分表示是在执行器里做的操作，commit的时候会将prepare状态的redolog改成commit状态，更新完成。拓展：innodb_flush_log_trx_commit这个参数设置为1的时候，表示每次事务的redo log都直接持久化到磁盘；sync_binlog这个参数设置成1的时候，表示每次的事务的binlog都持久化到磁盘，能够保证mysql异常重启之后binlog不丢失。事务ACID事务的四大特性：Atomicity：原子性Consistency：一致性Isolation：隔离行Durability：持久性多个事务会导致的问题：脏读（dirty read）：事务A读取了事务B未提交的数据；幻读（phantom read）：事务A两次读取数据数量不一致；不可重复读（non-repeatable read）：事务A在执行过程中对于某一条数据的多次读取会有不同结果。隔离级别读未提交（read uncommited）：一个事务未提交时，它所做的变更就能被其他事务读取到读提交（read commited）：一个事务提交以后，它所做的变更才能被其他事务看到可重复读（repeatable read）：一个事务执行过程中看到的数据，和启动时看到的是一致的串行化（serializable）:对于同一行数据的读和写都会加锁，后续事务必须等前一个事务执行完才可以继续执行原理浅析：读提交会在每个sql语句开始执行时创建一个视图；可重复读会在每个事务开始时创建一个视图；串行化直接通过读写锁的方式避免并行访问，可以通过show variables like &#39;transaction_isolation&#39;;来查看当前数据库的隔离级别。每次更新都会在undo log里产生记录，不同事务启动时都会有不同的read-view，所看到的记录的值也可能不一样，因此同一条记录系统中可能存在多个版本，这就是数据库的多版本并发控制（MVCC）。当系统里没有比这些日志更早的read-view时，这些undo log会被删除。启动方式123begin/start transaction...commit/rollback或者set autocommit=0，这个命令会关闭自动提交事务，直到主动执行commit或者rollback或者断开连接。推荐使用set autocommit=1，这样可以使用commit提交事务或者commit work and chain提交并自动启动下一个事务。拓展：在information_schema库的innodb_trx这个表中查询超过60s的事务：12&gt; select * from information_schema.innodb_trx where time_to_sec((timediff(now(),trx_started)))&gt;60; &gt;事务隔离在可重复独隔离级别下，事务在启动的时候就会对整库生成一个快照。Mysql里有两种”视图”：view，即正常情况下create view as select ……，查询方式与查表一样consistent read view…，用于支持RC(Read Committed)和RR(Repeatable Read)隔离级别的实现快照的生成原理并不是拷贝整个库的数据，拷贝的是事务的ID，因为每个事务都会向事务系统申请，并且按照申请顺序严格递增，每一行数据都会有一个transaction id，每个事务更新数据的时候，都会生成一个新的数据版本，并且将transaction id作为该版本的事务ID，记为 row trx_id，同时旧的数据版本会保留，能够在新的数据版本中拿到它。对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：版本未提交，不可见；版本已提交，但是是在视图创建以后提交的，不可见；版本已提交，但是实在视图创建以前提交的，可见如果设置了当前读（current read），那么所查到的可以是版本未提交更新的数据，对某一行数据的更新就是使用当前读然后更新。如果select 语句加锁，例如select * froom t where id = 1 lock in share mode的话就能读到在它之前启动的事务还未提交的事务，所以对于操作频繁的数字类型数据，不推荐在代码里首先查询数据然后更改再update回去，推荐update t set k = k + n where id = 1的形式，这种就是加了读锁（S锁，共享锁），当然还可以加写（X锁，排他锁）锁，即select * from t where id = 1 for update。索引简述索引就类似于一本书的目录结构哈希表：键-值对或key-value的结构，如果多个key的的哈希值相同，在会在key的位置拉出一条链表，适用于等值查询的场景，如Memcached；有序数组：在等值查询和范围查询场景中的性能都非常优秀，适用于静态炖出引擎；二叉搜索树(B+ Tree)：每个节点的左儿子小于父节点，父节点小于右儿子。但是由于二叉很容易导致树的高度变高，所以一般数据库中使用N叉树，N取决于数据块的大小。PS：关于数据结构，明年应该会有系统的学习过程。InnoDB的索引模型在InnoDB中，表都是按照主键顺序以索引的形式存放的，这种存放形式叫索引组织表。因为InnoDB使用了B+树的索引模型，所以数据都是存储在B+树中的。每一个索引都对应一个B+树。根据叶子节点的内容，索引类型分为主键索引和非主键索引。主键索引：叶子结点存放的是整行内容，在InnoDB里也叫聚簇索引；非主键索引：叶子几结点存放的是主键索引的值，在InnoDB里也叫二级索引。查询的时候如果使用的是非主键索引，那么会首先使用非主键索引去查询主键索引的值，然后回表使用主键索引的值去查询数据，所以推荐使用主键索引查询，省去一次扫描索引树的过程。索引维护每次插入或者删除都会进行索引维护。如果插入的数据的主键值大于当前所有节点的ID，那么只需要在最大的节点的后面插入一个新记录。如果新数据的主键不是最大的而是在某两条数据的中间，那么就需要挪动比新数据大的所有数据了，还可能造成数据页页分裂，影响性能，降低空间利用率；所以在定义主键的时候推荐使用：not null primary key auto_increment。当利用率很低的时候，数据页会进行合并。拓展：主键长度越小，非主键索引占用的空间就越小（因为叶子结点存放的都是主键索引），所以推荐使用整型作为索引字段的数据类型。索引覆盖例如一个语句：select * from t where k = 6（假定表中有两个索引，一个主键索引，一个k列索引）;那么执行过程是：首先在k索引树上找到ID的值，然后再到主键索引树上找到ID对应某一行数据（回表）。而索引覆盖的意思就是：查询k索引树时，只查ID，这样就无需再进行回表操作，因为k索引树能查到ID的值。一个很常用的场景就是limit分页时的场景，当limit n m的时候，mysql的实际做法是首先查出n+m行的所有数据，然后丢弃前n行，尤其当select *的时候，mysql的执行效率非常低。而如果使用索引覆盖，即：1select a.* from t a,(select id from t limit 1000000 10) b where b.id = a.id ​关联表走一次非主键索引，只需要获取到ID，然后通过表关联根据ID条件查询完整数据。联合索引多个列联合组成一个索引的，称之为联合索引。联合索引的使用场合一般是业务中的某个高频请求，用到了多个字段作为条件。最左前缀原则：假定一个表中有一个联合索引由(a,b,c)三个字段组成，那么能够使用该索引加速检索的语句有以下三种：查询时使用了a，b，c三个字段作为检索条件；使用了a，b作为检索条件；使用了a作为检索条件作为检索条件：我目前所知是where 语句和order by语句都是可以使用索引的。如果是某个字符串类型的字段作为索引，那么最左前缀同样适用于字符串前n个字符，所以对于高频模糊查询，推荐使用’str%’+字符串索引的查询方式。符合最左前缀原则就是满足联合索引的前n个字段或者字符串索引的前n个字符的查询都可以使用索引。索引下推：mysql 5.6引入的索引下推优化（index condition pushdown）的功能。在引入索引下推优化以前，假如根据多个条件查询数据，InnoDB在查询时只会以第一个条件（第一个条件是指经过优化器优化之后的条件）去查询ID的值再回表去检索数据。引入索引下推优化以后，InnoDB在检索非主键索引时就会自动根据检索条件里索引包含的字段，说白了就是多个索引字段条件去查询ID再回表。拓展：有可能表的数据只是10G，但是索引却有30G，所以有的时候会通过重建索引来达到节省空间的目的。但是重建的索引一般是非主键索引，因为如果无论是删除主键还是创建主键，都会将整张表重建，那么重建主键索引会导致非主键索引的工作白做，所以对于重建主键索引的行为，推荐使用alter table T engine = InnoDB有类似的效果。唯一索引对于普通索引来说：查到满足条件的第一个记录后，需要查找下一个记录，直到碰到第一个不满足条件的记录；对于唯一索引来说：查到满足条件的第一个记录以后，就会立即停止查找。效率对比：差距微乎其微；原因：InnoDB是按照页来读取的，每个页默认大小是16K，差不多近千个key，在现代CPU中，这点差距可以忽略不计change buffer：当需要更新一个数据的时候，如果内存中有，那么直接更新内存；如果内存中没有，那么就存到change buffer中，等到下次数据页读入内存中的时候对旧的数据页进行操作得到新的数据页（merge）。除了访问这个数据页会触发merge以外，mysql后台会有线程定期merge，此外，在数据库正常关闭（shutdown）的时候也会触发merge。在内存中它占用的是pool buffer的空间，即内存读数据页的空间，可以通过innodb_change_buffer_max_size来动态设置百分比。使用场景：二级索引，写入频繁。如账单类，日志类，change buffer能够大幅节省随机读磁盘的IO消耗；插入语句中的change buffer：如果数据页已经读入到内存，直接更新内存；如果没有，那么在change buffer里记录一下插入语句。最后将所有这些语句记到redo log-（add (id ,value) to page,new change buffer item “add (id,value) to page”）里。查询语句中的change buffer：如果在上述插入语句后立即执行了查询，如果内存页中有，那么直接返回内存页中数据；如果没有，首先读取磁盘中的页到内存，然后merge change buffer中的内容到页中，再返回数据。redo log主要节省的是随机写磁盘的消耗（转换成顺序写），而change buffer主要节省的是随机读磁盘的IO消耗。索引优化优化器是如何选择索引的？扫描行数，临时表，是否排序。扫描行数：根据统计信息来估算记录数，这个统计信息是指索引的”区分度”，一个索引上不同的值越多，区分度就越好， 值的个数称之为”基数（cardinality）”。使用show index from t可以看到t表上索引的基数。基数的计算采用的是“采样统计”的方式计算而来，即：默认选择N个数据页，统计这些页面上的不同值，得到平均值，然后乘以这个索引的页面数，就得到了索引的基数；当变更的数据行超过1/M的时候，会自动触发重新做一次索引统计。当innodb_stats_persistent=on时：统计信息会持久化，N默认为20，M默认为10。当innodb_stats_persistent=off时：统计信息不回持久化，N默认为8，M默认为16使用explain分析时，rows表示预计扫描行数，但是有的时候，优化器可能会选择扫描行数比较多的执行计划，是因为它会把回表查找的行数页算进去，所以虽然行数比较多，但是由于是主键，省去了回表的操作。当mysql优化器选择了错误的索引导致执行比较慢时，常用的策略如下：analyze table t，该语句会重新统计索引信息，能解决单纯扫描行数计算错误的问题；select * from t force index(a) where ...，强制使用某索引；select * from t where ... order by b limit 1改为order b,a，引导mysql使用a索引，mysql使用b索引的原因是因为使用索引b可以避免排序（b本身是索引，已经是有序的），所以即使b扫描行数多也会认为代价更小，这种方式只适用于limit 1这样两种排序方式结果都返回b最小的那一行的情况；新建索引或者删掉误用的索引。锁msyql根据加锁范围，大概有全局锁、表级锁和行锁三类。全局锁加全局读锁的方法：Flush tables with read lock（FTWRL）使用场景：全库逻辑备份。与前面提到的一致性视图不一样的在于，一致性视图只适合于支持事务的存储引擎，如InnoDB可以使用mysqldump -sigle-transaction开启事务确保拿到一致性视图。而FTWRL适合于不支持事务的存储引擎，例如MyISAM。另一种全局读锁的方法：set global readonly=true，但是readonly的值可能会被用来做其他逻辑例如判断一个库使主库还是备库；而且如果客户端设置了该值，一旦客户端异常以后，数据库就会保持readonly的状态，影响会很大；但是FTWRL方式会自动释放全局读锁。表级锁表级锁分为两种：表锁，元数据锁（MDL）语法：lock tables … read/write作用：lock tables不仅限制了其他线程的读写，也限制了本线程接下来操作的对象。例如线程A执行了lock tables t1 read,t2 write；那么其他线程写t1，读写t2的都会被阻塞，并且A自己连写t1都不行，只能unlock tables之后再进行。而元数据锁无需显式启用，在进行访问一个表时会自动加上，保证表结构不会在读期间发生变更。所以在做表结构变更的时候要小心不能锁住线上查询和更新。可以考虑暂停DDL操作然后kill掉mysql里的长事务。拓展：MariaDB和AliSQL已经支持DDL的NOWAIT/WAIT n，表示不重试/重试修改字段：123&gt; ALTER TABLE T NOWAIT add column...ALTER TABLE T WAIT N add column...&gt;行锁Mysql的行锁是在引擎层由引擎层实现的，所以例如MyISAM等引擎就不支持行锁。行锁是在需要的时候才加上，也就是说在真正执行对某一行数据操作的时候才加上，并且等到事务结束时才是放。这个称之为两阶段锁协议，所以尽可能把造成锁冲突的、影响并发度的锁往后放。假设一个事务里一个持有锁时间比较长的操作再前面，直到所有操作完成才会释放锁，那会导致加锁时间比较长。死锁和死锁检测死锁：例如：12345678910#事务Abegin；update t set k = k+1 where id = 1;update t set k = k+1 where id = 2;commit;#事务Bbegin;update t set k = k+1 where id = 2;update t set k = k+1 where id = 1;commit;当事务A启动以后，事务B也启动，执行到第4行时会发现id=2这一行的锁已经属于B，而B也在等待A释放id=1的锁，这个时候两个事务就会进入死锁状态。有两种解决策略：直接进入等待，直到超时，超时时间可以通过innodb_lock_wait_timeout来设置，默认为50发起死锁检测，发现死锁后，主动回滚死锁链中某一个事务，将innodb_deadlock_detect设置为on，即可开启这个逻辑正常情况下用第二种策略比较多，其逻辑是：每当一个事务被锁住的时候，就要看看它锁依赖的线程有没有别的事务锁住，如此循环，最后判断是否出现了循环等待。如果所有事务更新的都是同一行，每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个复杂度为o(n)的操作。假如1000万个并发线程，最后的检测结果是没有死锁，但是消耗了大量CPU判断循环等待。所以这又引发了一个问题：如何解决死锁检测的性能消耗问题？确定业务不会出现死锁，直接关闭死锁检测（不推荐）控制并发度， 在数据库服务端做（在中间件做并发控制或者修改Mysql源码）]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>MySql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySql-安装部署]]></title>
    <url>%2FMySql%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2.html</url>
    <content type="text"><![CDATA[描述随手记一下mysql在linux和在mac os下的一些安装以及踩过的坑。大版本号是5.7，小版本应该没有太大影响。安装Windowsmysql在windows平台上的安装比较简单，但是最好不要在中文目录下安装比较重要的开发软件，不然出现一些问题真的没地方哭。MAC OS X默认安装位置在/usr/local/下，新版数据库没有用户自定义配置文件，可以用vim新建一个my.cnf文件，将/usr/local/mysql/suppoty-files/目录下的my-default.cnf里的内容复制到新建的my.cnf里，假如无法复制，可以在控制台按command+s打印控制台内容，复制到my.cnf里以后，将[mysqld]下添加datadir=/usr/local/mysql/data basedir=/usr/local/mysql/ character-set-server=utf8(该段代码可选，设置数据库服务端编码格式) 对于有存储微信表情的需要来说，字符编码建议设置为utf8mb4，该字符集是对utf8的的一种补充。同时在[mysqld]上添加[client]，在[client]下添加：default-character-set=utf8(设置客户端创建数据库默认的编码格式) 修改密码：set password for root@localhost=password(&#39;root&#39;)假如/etc/my.cnf文件[mysqld] 下加入了skip-grant-tables上面这个修改密码的语句就不能使用了，此时应该使用以下语句：update user set password=password(&#39;root&#39;) where user=&#39;root&#39;;字符集查询结果12345678910111213mysql&gt; show variables like '%char%';+--------------------------+--------------------------------------------------------+| Variable_name | Value |+--------------------------+--------------------------------------------------------+| character_set_client | utf8 || character_set_connection | utf8 || character_set_database | utf8 || character_set_filesystem | binary || character_set_results | utf8 || character_set_server | utf8 || character_set_system | utf8 || character_sets_dir | /usr/local/mysql-5.5.23-osx10.6-x86_64/share/charsets/ |+—————————————+--------------------------------------------------------+CentOS使用的是RPM包的方式，下载完mysql的tar包，然后解压开能看到很多mysql-community-开头的.rpm文件，使用如下命令就可以安装sudo yum install mysql-community-{server,client,common,libs}-* --exclude=&#39;*minimal*&#39; 当然要排除最小安装，然后需要找到临时密码才能进入数据库改密码：sudo grep &#39;temporary password&#39; /var/log/mysqld.log找到密码就可以使用mysql -uroot -p 登陆，然后修改密码:mysql&gt; ALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;MyNewPass4!&#39;;如果需要远程互联网访问的话，需要使用如下语句开启权限：mysql&gt; grant all on *.* to &#39;root&#39;@&#39;%&#39; identified by &#39;root&#39;；这个语句的含义是：如果用户root@%不存在，就创建这个用户，密码是root；如果用户root已经存在，就修改密码。注：除修改密码和查询结果的操作外，其他操作必须在停止数据库的情况下进行。假如忘记了数据库密码或者不知道数据库密码，可以进入/etc/my.cnf文件[mysqld] 下加入了skip-grant-tables，输入密码的时候就可以不输入直接进入。修改密码以后再取消那段语句。也可以直接使用参数启动mysql的安全模式/usr/local/mysql/bin/mysqld_safe --skip-grant-tables，执行update mysql.user set authentication_string=password(&#39;newpassword&#39;) where user=&#39;root&#39; and Host = &#39;localhost&#39;;和flush privileges;以后再以正常模式启动mysqlflush privileges使用场景：当数据表中的权限数据和内存中的权限数据不一样时，例如上文中DML语句修改了mysql用户表中的用户信息。但是在执行grant语句以后或者revoke，由于这两种语句会同时更新内存和磁盘，所以不需要flush操作。使用原则摘录自互联网《mysql 36军规》：不在数据库做运算，CPU计算必须移至业务层；控制单表数量在1000万以内，业内公认mysql单表1000万数据时树的高度在3～5，性能较好；控制列数量：控制字段数量在20个以内；平衡范式和冗余：为提高效率牺牲范式设计，冗余数据；拒绝Big sql，Big transaction，Big batch；用好数值类型：tinyint(1Byte)，smallint(2Byte)，mediumint(3Byte)，int(4Byte)，bigint(8Byte)，所以如int(1)是不合理的；字符转化为数字，例如，使用int而不是char(15)存储IP；优先使用enum或set；避免使用NULL字段，因为NULL字段很难查询，并且NULL字段的索引需要额外的空间，NULL字段的复合索引无效，所以int类型的字段可以默认为0，varchar类型的字段可以默认为空字符串；少用text/blog：varchar性能会比text和blog高很多，如果避免不了可以拆表；不在数据库里存图片；合理使用索引；字符字段必须建前缀索引；不在索引做列运算；innodb主键推荐使用自增列，字符串不应该做主键，如果不指定主键，innodb会使用唯一且非空值索引代替；不用外键，由程序保证约束；sql语句尽可能简单，一条sql只能在一个cpu运算；事务尽可能简单；避免使用函数和触发器；不使用select *；or改写为in，or的效率是n级别，in的效率是log(n)级别，in的个数控制在200以内；or改写为UNION，mysql的索引合并比较弱智：select id from t where phone=’159’ or name = ‘admin’ =&gt; select id from t where phone = ‘159’ union select id from t where phone = ‘admin’;避免负向%慎用count(*)（个人不认可）limit分页数据一旦很大，尽量使用索引覆盖；使用union all 代替union；少用链接join；使用group by分组，自动排序；使用同类型比较；使用load data 倒数比insert快约20倍；打散批量更新；性能分析：explain，show profile，mysqlsla，mysqldumpslow；show slow log；show processlist，show query_response_time(percona)常用姿势查询处理1select distinct * from t left join t1 on t1.t_id = t.id where t.city='beijing' group by 'name' having name='liuhuijun' order by birthday limit 10;如上，那么查询顺序是：from t,t1 -&gt; on t1.t_id = t.id -&gt; where t.city=’beijing’ -&gt; group by ‘name’ -&gt; having name = ‘liuhuiun’ -&gt; select -&gt; distinct *-&gt; order by birthday -&gt; limit 10from:对from子句种的左表和右表执行笛卡尔积（Cartesian product），产生虚拟表VT1；on:对虚拟表VT1进行ON筛选，只有符合t1.t_id = t.id的行才被插入虚拟表VT2；join:如果是out join类型，那么保留表中未匹配的行作为外部行添加到虚拟表VT2中，作为VT3，如果有多个连接表，那么再一次执行上面的三步操作；where:对虚拟表进行where筛选，只有符合city=’beijing’的城市才加入到VT4中；group by:根据group by对VT4记录进行分组操作，产生VT5；having:对虚拟表VT5进行having筛选，只有符合 name=’liuhuijun’的才加入到VT6中；select:选择指定的列，生成到虚拟表VT7中；distinct:去除重复数据，产生虚拟表VT8；order by:将VT8只能够的数据进行排序，产生VT9；limit:取出对应条数数据生成VT10，并返回。可以在建表时使用查询语句：123456789&lt;!-- 复制表结构和数据到新表 --&gt;CREATE TABLE new_table SELECT * FROM old_table只复制表结构CREATE TABLE new_table SELECT * FROM old_table where 1 = 2CREATE TABLE new_table LIKE old_table&lt;!-- 将旧表数据插入新表 --&gt;insert into new_table select * from old_tableinsert into new_table(column1，column2...) select (dolumn1,column2...) from old_table ​数据库备份123456789101112&lt;!--备份某数据库到文件--&gt;mysqldump -uroot -p DB_name &gt; dump_file&lt;!--备份某数据库到文件，与上面的区别在于这条语句会包含drop table if exist table_name,insert之前会有一个锁表语句lock tables talbe_name write，insert之后会有unlocl tables--&gt;mysqldump -opt -uroot -p &gt; dump_file&lt;! --从远程主机的源库传输数据到目标库，前提目标库已经存在--&gt;mysqldump --host=192.168.1.1 --opt sourceDB | mysql --host=localhost -C targetDB&lt;!--只备份结构不备份数据--&gt;mysqldump --no-data --database DB1 DB2 DB3 &gt; dump_file&lt;!--备份所有表--&gt;mysqldump --all-databases &gt; dump_file&lt;!--从dump文件恢复--&gt;mysql -uroot -p DB_name &lt; dump_file ​]]></content>
      <categories>
        <category>编程技术</category>
      </categories>
      <tags>
        <tag>MySql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker入门学习二]]></title>
    <url>%2FDocker%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E4%BA%8C.html</url>
    <content type="text"><![CDATA[Dockerfile通过dockerfile实现秒级镜像迁移。定义：定义镜像自动化构建流程的配置文件。组成：注释行加指令行。作用:快速迁移、部署；记录了镜像构建顺序和逻辑；自动化流程；提交修改时只需要提交dockerfile的修改。结构基础指令：定义新镜像的基础和性质；控制指令：指导镜像构建的核心部分，用于描述镜像在构建过程中需要执行的指令；引入指令：将外币文件引入到构建镜像内部；执行指令：为容器指定在启动时需要执行的脚本或指令；配置命令：配置网络、用户等。常见指令FROM一般情况下，我们不会从0开始搭建一个基础镜像，而是会选择一个已经存在的镜像为基础。FROM&lt;image&gt;[AS&lt;name&gt;] FROM&lt;image&gt;[:&lt;tag&gt;][AS&lt;name&gt;] FROM&lt;image&gt;[@&lt;digest&gt;][AS&lt;name&gt;] 也可以用该指令合并两个镜像的功能。RUN用于向控台发送命令。RUN&lt;command&gt; RUN[&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;] 支持反斜杠换行。ENTRYPOINT/CMD用于启动容器内的主程序。ENTRYPOINT[&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;] ENTRYPOINTcommandparam1param2 CMD[&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;] CMD[&quot;param1&quot;,&quot;param2&quot;] CMDdommandparam1param2 EXPOSE为容器暴露指定端口。EXPOSE&lt;port&gt;[&lt;port&gt;/&lt;protocol&gt;...] 两个命令大体相近，都可以为空。当两个命令同时给出时，CMD的内容会作为ENTRYPOINT定义的命令的参数。VOLUME定义数据卷目录VOLUME[&quot;/data&quot;] COPY/ADD从宿主机的文件系统里拷贝内容到镜像里的文件系统中。COPY[--chown=&lt;user&gt;:&lt;group&gt;]&lt;src&gt;...&lt;dest&gt; ADD[--chown=&lt;user&gt;:&lt;group&gt;]&lt;src&gt;...&lt;dest&gt; src和dest外可以加””。两者的区别在于：ADD能够使用URL作为src，并且识别到源文件为压缩包时自动解压。docker build &lt;path&gt;path可以为本地路径或者URL路径，但并不是dockerfile文件路径，而是构建环境目录，-f可以指定dockerfile文件位置，未指定的话默认就在环境目录下去找，-t可以指定新生成镜像的名称。ARG定义一个变量，变量只可以在build时传进来，只在当前镜像内有效。例如dockerfile如下：1234567FROM debian:stretch-slim...ARG TOMCAT_MAJORARG TOMCAT_VERSION...RUN wget -0 tomcat.tar.gz &quot;http//...$TOMCAT_MAJOR:$TOMCAT_VERSION...&quot;... ​在build时，可以这样传入参数：docker build --build-arg TOMCAT_MAJOR=8 --build-arg TOMCAT_VERSION=8.0.53 ./ENV定义一个环境变量，环境变量在所有基于此镜像的镜像内都生效，并且可以指定值。FROM debian:stretch-slim ... ARG TOMCAT_MAJOR 8 ARG TOMCAT_VERSION 8.0.53 ... RUN wget -0 tomcat.tar.gz &quot;http//...$TOMCAT_MAJOR:$TOMCAT_VERSION...&quot; ... 取值与ARG一致，使用美元符号取值符，当ARG与ENV的名字重复时，ENV会覆盖ARG，同时ENV的值也可以通过运行时选项-e或者-env传入：docker run -e &lt;key&gt;=&lt;value&gt; &lt;image&gt;。指令实战实战构建一个Spring Boot（我的博客）项目，dockerfile如下：1234FROM frolvlad/alpine-oraclejdk8:slimVOLUME /tmpCOPY MyBlog-0.0.1-SNAPSHOT.jar app.jarENTRYPOINT ["java","-jar","-Dlogging.file=/spring.log","/app.jar"]选择基础镜像含有oraclejdk8，如果不清楚，可以使用docker search oraclejdk8，复制其中一个的name作为基础镜像。同时，为容器挂载一个目录，主机的/var/lib/docker下会有一个目录挂载到/tmp目录下，根据Srping Boot官方说明：We added a VOLUME pointing to “/tmp” because that is where a Spring Boot application creates working directories for Tomcat by default. The effect is to create a temporary file on your host under “/var/lib/docker” and link it to the container under “/tmp”. This step is optional for the simple app that we wrote here, but can be necessary for other Spring Boot applications if they need to actually write in the filesystem.Spring Boot项目启动时是默认以/tmp目录作为tomcat的工作目录的，所以最好挂载一个宿主机到容器中，虽然对于这个简单项目这一步是可选的，但是对于其他Spring Boot项目可能是必须的。使用COPY或者ADD命令拷贝程序到镜像文件系统中，然后最后一步是主要指令，需要记住：第一个是命令，每多一条参数，请多一个””（双引号），不然会报Unrecognized option: -jar -Dlogging.file=/spring.log（无法识别选项）的错。最后一步：docker build ./ -t myblog开始构建镜像，记住镜像名只能小写。技巧#对于能够合并的多条指令，推荐合并。以下两种效果时一样的，但是推荐第一种 RUN apt-get update;\ apt-get istall -y --no-install-recommends $fetchDeps;\ rm -rf /var/lib/apt/lists/*; RUN apt-get update; RUN apt-get install -y --no-install-recommends $fetchDeps; RUN rm -rf /var/lic/apt/lists/* 原因在于：每一条能够对文件系统的指令执行之前，Docker都会基于上条命令的结果启动一个容器，在容器中运行这条指令的内容，之后再形成一层镜像，如此反复形成最终镜像。因此，合并以后就能提升构建效率。对于ENTRYPOINT和CMD，前者优先级高于后者，因为它常用于对容器初始化，而CMD才是启动主程序的指令，在前一篇基础知识中提过运行时重写指令，其实重写的就是CMD指令，当两者同时存在时，CMD指令会作为ENTRYPOINT指令的参数存在。例如：12345678...ENTRYPOINT ["sh","/usr/local/bin/git"]CMD ["sh","/usr"]## 以上两句等于：sh /usr/local/bin/git sh /usrENTRYPOINT /bin/ep argeCMD /bin/exec args##以上两句等于：/bin/sh -c /bin/ep arge /bin/sh -c /bin/exec args... ​注：两个指令如果不带中括号，那么默认执行方式是/bin/sh -c [中括号里参数]可以观摩Docker Hub里更多大佬们写的Dockerfile。同时Docker Hub也有各种官方镜像，例如Mysql如何在启动时传入root用户密码（初始化运行Mysql时是需要设置用户名密码的）。我们也可以共享我们的镜像，前提是将Docker Hub账号授权到GitHub或者Bitbucket来从代码库中获取。Docker Compose容器管理工具，也被称为容器编排工具。一套项目，往往是由数据库，缓存，应用组成，而在分布式架构下，每一个实例可能都有多个，所以就需要容器编排工具进行管理。Compose可以对本机上的容器进行编排。Kuberneters是由Google研发的可以对其他服务器上的容器进行管理的工具，Swarm是Docker公司研发的和K8s是类似的工具。Docker Compose并不属于Docker Engine的一部分，所以需要另外安装。而对于windows或者mac，如果装了Docker Desktop（需要开启Hyper-v）或者Docker toolbox（需要安装virtualBox引擎）都可以直接运行Docker Compose（Hyper-v和virtualBox所使用的虚拟化技术会冲突，所以只推荐装其中一种）。如果是Linux系统，可以使用如下命令安装，中间版本号可以自己选择：12curl -L https://github.com/docker/compose/releases/download/1.25.0-rc2/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-composechmod +x /usr/local/bin/docker-composeDocker Compose默认使用docker-compose.yml文件作为配置文件，如非必要不推荐改名。看一个简单的配置文件：12345678910111213141516171819202122#yml已经更新到了第几版version: '3'#核心细节部分：配置应用集群services: webapp: build: ./image/webapp ports: - "5000":"5000" volumes: - ./code:/code - logvolume: /var/log links: - mysql - redis redis: image: reids:3.2 mysql: image: mysql:5.7 enviroment - MYSQL_ROOT_PASSWORD=123volumes: logvolume: &#123;&#125;docker-compose up：运行，-d后台运行，-f修改指定配置文件，-p定义项目名称。docker-compose down：停止所有容器，并将他们删除。“随用随删，随用随启”容器编排命令docker-compose logs &lt;cointainer&gt;：查看集群中某个容器内主进程日志 docker-compose create/start/stop/ &lt;cointainer&gt; ：创建/启动/停止集群内某个容器 常用配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273version: "3"services: redis: ##直接指定镜像 image: redis:3.2 networks: - backend ## 指定驱动类型并指定子网网段 # backend： # driver: bridge ## 指定别名 # alias： # - backend.redis ##ipam: # driver: default # config: # - subnet: 10.10.1/24 volumes: ##这里的相对目录是指相对docker-compose.yml所在目录 - ./redis/redis.conf:/etc/redis.conf:ro prots: ## 需要注意的是，yml文件对于小于60的xx：xx格式会解析为时间，所以最好用双引号括起来 - "6379":"6379" ##指定redis启动时的指令，此处是为了定义启启动的配置文件 command: ["redis-server","/etc/redis.conf"] database: image: mysql:5.7 networks: - backend volumes: - ./mysql/my.cnf:/etc/mysql/my.cnf:ro - mysql-data:/var/lib/mysql ##类似于-e或者-env传递参数 environment: - MYSQL_ROOT_PASSWORD=my-secret-pw ##类似于-p指定端口映射 ports: - "3306":"3306" webapp: ##没有指定镜像，说明镜像来源于构建 build: ./webapp networks: - frotend - backend volumes: - ./webapp:/webapp depends_on: - redis - database nginx: image: nginx:1.12 networks: - frontend volumes: - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro - ./nginx/conf.d:/etc/nginx/conf.d:ro - ./webapp/html:/webapp/html depends_on: - webapp ports: - "80":"80" - "443":"443"networks: frontend; backend;volumes: mysql-data ## 以下配置表示引用外部数据卷，即docker engine里已有的数据卷 ##mysql-data: # exernal: trueDocker Compose 实战现有如下几个服务：mysql，redis，tomcat，Java war包建议性目录结构（以下都在项目目录下）：app：存放程序工程，即代码、编译结果以及相关的库、工具等；compose：定义docker compose项目；mysql：与mysql相关配置；redis：与redis相关配置tomcat：与tomcat相关配置下面的配置都是根据官网修改我们所需而来的配置。mysql配置：123456789101112131415161718192021222324252627# ./mysql/my.cnf[mysqld_safe]pid-file = /var/run/mysqld/mysqld.pidsocket = /var/run/mysqld/mysqld.socknice = 0[mysqld]skip-host-cacheskip-name-resolveexplicit_defaults_for_timestampbind-address = 0.0.0.0port = 3306user = mysqlpid-file = /var/run/mysqld/mysqld.pidsocket = /var/run/mysqld/mysqld.socklog-error = /var/log/mysql/error.logbasedir = /usrdatadir = /var/lib/mysqltmpdir = /tmpsql_mode = NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLESlc-messages-dir = /usr/share/mysqlsymbolic-links = 0redis配置：1234567891011121314151617# ./redis/redis.conf##...################################## SECURITY #################################### Require clients to issue AUTH &lt;PASSWORD&gt; before processing any other# commands. This might be useful in environments in which you do not trust# others with access to the host running redis-server.## This should stay commented out for backward compatibility and because most# people do not need auth (e.g. they run their own servers).## Warning: since Redis is pretty fast an outside user can try up to# 150k passwords per second against a good box. This means that you should# use a very strong password otherwise it will be very easy to break.#requirepass my-secret-pw##...也可以使用容器中默认的配置文件复制到宿主机以便我们在宿主机中进行操作。12345#首先需要创建一个临时容器：docker run --rm -d --name temp-tomcat tomcat:8.5#然后使用docker cp命令复制容器内的tomcat配置文件到宿主机中：docker cp temp-tomcat:/usr/local/tomcat/conf/server.xml ./server.xmldocker cp temp-tomcat:/usr/local/tomat/conf/web.xml ./web.xml如果两个参数调换位置就是将宿主机中的配置文件复制到容器的文件系统里。docker-compose.yaml:123456789101112131415161718192021222324252627282930313233343536version: "3"services: redis: image: redis:3.2 volumes: ##使用宿主机的某个配置文件作为容器内程序配置文件，方便修改 - ../redis/redis.conf:/etc/redis/redis.conf:ro ##将宿主机的某个目录挂载到容器内，保证数据不丢失 - ../redis/data:/data command: ## 指定启动命令为 redis-server /etc/redis/redis.conf，多参数写多行 - redis-server - /etc/redis/redis.conf ports: - 6379:6379 mysql: image: mysql:5.7 volumes: - ../mysql/my.cnf:/etc/mysql/my.cnf:ro ##将宿主机的某个目录挂载到容器内，保证数据不丢失 - ../mysql/data:/var/lib/mysql environment: MYSQL_ROOT_PASSWORD: my-secret-pw ports: - 3306:3306 tomcat: image: tomcat:8.5 volumes: ##将宿主机的项目目录下的app挂载到容器目录中 - ../app:/usr/local/tomcat/webapps/ROOT ports: - 80:8080服务化开发搭建本地环境使用docker compose定义本地的一组环境，如spring项目+mysql数据库。与同事的其他服务模块产生调用（可以借助网络别名更轻松地调用）。借助Overlay网络实现不同主机互联。Docker SwarmDocker内置的集群工具，帮助管理部署不同主机上的Docker daemon集群。docker swarm init：初始化集群，默认当前节点为管理节点 docker swarm join：加入集群，docker swarm join-token表示获得管理节点的加入命令，执行获得的那条管理节点的加入命令以后就可以称为管理节点 docker network create：--driver overlay表示启动类型为跨网类型，--attachable mesh选项方便不同主机上的docker容器能够正常使用到它 docker network ls：查看其下网络列表 然后在docker compose的yml文件中配置networks配置块：123networks： mesh： external： true服务发现使用docker compose模拟zookeeper集群注册中心，用三个docker compose 服务定义这三个节点：123456789101112131415161718192021222324252627282930313233version: '3'services: zk1: image: zookeeper:3.4 restart: always hostname: zk1 environment: ZOO_MY_ID: 1 ZOO_SERVERS: server.1=0.0.0.0:2888:3888 server.2=zk2:2888:3888 server.3=zk3:2888:3888 ports: - 2181:2181 zk2: image: zookeeper:3.4 restart: always hostname: zk2 environment: ZOO_MY_ID: 2 ZOO_SERVERS: server.1=zk1:2888:3888 server.2=0.0.0.0:2888:3888 server.3=zk3:2888:3888 ports: - 2182:2181 zk3: image: zookeeper:3.4 restart: always hostname: zk3 environment: ZOO_MY_ID: 3 ZOO_SERVERS: server.1=zk1:2888:3888 server.2=zk2:2888:3888 server.3=0.0.0.0:2888:3888 ports: - 2183:2181ZOO_MY_ID:zk在集群中的编号。ZOO_SERVICES:定义所有zk和它们的连接方式。例如：server.1=0.0.0.0:2888:3888 server.2=zk2:2888:3888 server.3=zk3:2888:3888 我们可以在 ZOO_SERVERS 中定义所有处于 Zookeeper 集群中的程序，通过空格来间隔它们。而每个服务的的定义形式为 server.[id]=[host]:[port]:[port]，所以就有了上面例子中我们看到的样子。在这个例子里，我们描述了三个 Zookeeper 程序的连接地址。由于每个容器都有独立的端口表，所以即使这些程序都运行在一个主机里，我们依然不需要担心，它们会造成端口的冲突。所以这里我们直接使用默认的 2888 和 3888 来进行服务间的相互通信即可。而在进行容器互联的过程中，我们可以通过 Docker 的解析机制，直接填入对应服务的名称替代它们的 IP 地址，也就是这个例子里的 zk2 和 zk3。restart: always 这个配置，这个配置主要是用来控制容器的重启策略的。这里的 always 指的是不论任何情况，容器出现问题后都会自动重启，也包括 Docker 服务本身在启动后容器也会自动启动。配置值说明no不设重启机制always总是重启on-failure在异常退出时重启unless-stopped除非由停止命令结束，其他情况都重启]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>CI/CD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker入门学习一]]></title>
    <url>%2FDocker%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E4%B8%80.html</url>
    <content type="text"><![CDATA[虚拟化技术将计算机物理资源进行抽象、转换为虚拟资源交由应用程序使用的技术。并不是降低程序的资源占用率，而是提高计算机资源的使用率。分类：硬件虚拟化：计算机硬件支持虚拟化技术，使得该硬件支持运行多种操作系统或者程序。例如Intel和AMD的CPU VT技术；软件虚拟化：在硬件和软件层中多了一层指令转化层，实现软件在不同硬件上的指令转换。例如虚拟机、JVM等。虚拟机：Hypervisor的缺点是执行效率低，所以VMware Workstation使用了硬件辅助虚拟化技术，而JRE有JIT等技术。容器技术操作系统自身支持一些接口，能够让应用程序间可以互不干扰的独立运行，并且能够对其在运行中所使用的资源进行干预。docker与微服务随着现代应用的功能越来越复杂，需要的迭代速度也越来越快，应用程序的开发趋向服务化，微服务架构开始火热起来。特点：单独进程、轻量级通信(常用HTTP)、针对特定业务或功能、全自动独立部署、集中管理、跨语言调用、跨数据库存储。 优点：易于开发维护、部署启动快、技术扩性好、按需伸缩 缺点：运维要求提高、分布式固有复杂性、接口可调性低、重复劳动 设计原则： 单一职责---单独的一个类、方法、服务只关注整个系统中某个部分或功能； 服务自治---每个服务拥有自己的业务、运行环境、依赖； 轻量通信---轻量级通信机制：REST、AMQP、STOMP、MQTT（协议）； 粒度控制---参考“DDD”设计思想，设计之初即确定每个微服务边界，每个服务保持独立松耦合。 拆分成服务后，由于不同服务的环境依赖不一样，解决依赖问题就变得十分复杂。举个例子：公司前端是通过node运行的，后端有Java应用，有Python应用，如果要上线运行，要装node环境和python环境。然而对于开发者而言， 更愿意将时间花在编写和调试代码上，而不是去排查环境问题上，而docker则最大程度上解决了环境的问题，减少微服务的开发/部署成本。docker的技术实现命名空间 ( Namespaces ) ：命名空间是 Linux 核心在 2.4 版本后逐渐引入的一项用于运行隔离的模块。 相信很多开发者在不同的编程语言中都见过命名空间的概念，在这些编程语言中，命名空间的主要目的就是为了集合相同模块的类，区分不同模块间的同名类。 同样的道理，Linux 内核的命名空间，就是能够将计算机资源进行切割划分，形成各自独立的空间。 就实现而言，Linux Namespaces 可以分为很多具体的子系统，如 User Namespace、Net Namespace、PID Namespace、Mount Namespace 等等。 这里我们以进程为例，通过 PID Namespace，我们可以造就一个独立的进程运行空间，在其中进程的编号又会从 1 开始。在这个空间中运行的进程，完全感知不到外界系统中的其他进程或是其他进程命名空间中运行的进程。资源控制组(Control Groups)：Linux内核在2.6版本后逐渐引入的一项对计算机资源控制的模块。CGroups不光能控制计算机资源的分离，还能控制计算机资源的分配。联合文件系统(Union File System)：一种能够同时挂载不同实际文件或目录到统一目录，形成一种联合文件结构的文件系统。docker引入了一项对于UnionFS的改进，也就是AUFS（Advanced Union File System），原理和git的原理类似，其跟踪文件的改变并应用到宿主机的文件之上，而不去修改不更改的文件。属性Docker虚拟机启动速递秒级分钟级空间MBGB性能接近原生较低普通机器支撑量数百个几个应用场景：持续集成（Continuous Intergration）和持续交付（Continuous Delivery）。跨平台、跨语言部署和动态伸缩。提高计算机资源利用率，提高生产效率。docker核心组成容器引擎：Docker Engine由daemon和cli两个核心部件的C/S架构组成，通过Restful Api进行通信。四大组成对象：镜像（image）一个虚拟操作系统最原始文件系统。Docker是增量更新镜像，也就是一层一层的镜像，每次更新/修改都会生成一个新的镜像层，每一个镜像是由其下所有镜像组成。容器（container）用于隔离虚拟环境和真实物理环境的基础设施。官方定义，容器应由以下几个部分组成：一个Docker镜像一个程序运行环境一个指令集合网络（network）用于与外界通信，每一个容器都拥有其独立的网络系统或者共用一个网络环境。换句话说，每一个docker容器都可以有自己的域名，或者多个docker容器屏蔽硬件共同组成一个网络环境。数据卷（volumn）docker实现了简单轻松的目录挂载，除了能从宿主机挂载目录，还可以建立自己的目录存放数据并共享。Docker搭建配置两个版本：社区版（CE，Community Edition），免费，容器管理企业版（EE，Enterprise Edition），收费，容器管理、镜像管理、插件、安全Docker Engine的迭代版本又会分为稳定版和预览版，以年月命名版本号，如17.03，那么17.03.02就是对17.03的第二次修正。docker要求Linux的内核版本大于3.10：12 [root@localhost ~]# uname -r3.10.0-693.el7.x86_64Centos:1234567891011121314151617181920212223 #卸载老版本Docker sudo yum remove docker \ docker-client \ docker-client-latest \ docker-common \ docker-latest \ docker-latest-logrotate \ docker-logrotate \ docker-selinux \ docker-engine-selinux \ docker-engine;#yum-utils提供了yum-config-manager的作用，而device-mapper-persistent-data和lvm2存储驱动程序sudo yum install -y yum-utils device-mapper-persistent-data lvm2;#配置docker源sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo#列出当前可用的的docker-ce版本yum list docker-ce --showduplicates | sort -r;#安装docker-ce,可以安装指定版本：sudo yum install docker-ce-18.03.0.cesudo yum install docker-ce#开机自启用sudo systemctl enable docker#运行sudo systemctl start dockerDebian:123456789$ sudo apt-get install apt-transport-https ca-certificates curl gnupg2 software-properties-common$$ curl -fsSL https://download.docker.com/linux/debian/gpg | sudo apt-key add -$ sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/debian $(lsb_release -cs) stable"$ sudo apt-get update$ sudo apt-get install docker-ce$$ sudo systemctl enable docker$ sudo systemctl start dockerFedora:1234567$ sudo dnf -y install dnf-plugins-core$$ sudo dnf config-manager --add-repo https://download.docker.com/linux/fedora/docker-ce.repo$ sudo dnf install docker-ce$$ sudo systemctl enable docker$ sudo systemctl start dockerUbuntu:123456789$ sudo apt-get install apt-transport-https ca-certificates curl software-properties-common$$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -$ sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"$ sudo apt-get update$ sudo apt-get install docker-ce$$ sudo systemctl enable docker$ sudo systemctl start docker开启docker服务以后，就可以使用docker version查看docker daemon（服务端）和docker CLI（客户端）的版本信息。默认情况下，docker CLI连接的是本机的docker daemon，当然也可以通过RESTful接口修改配置用于操作其他机器上运行的docker daemon。docker info可以看到正在运行的docker engine实例中运行的容器数量，存储的引擎等信息。镜像与容器命名username：识别不同用户上传的镜像，与github中的命名空间类似；repository：识别进行的内容，形成描述；tag：镜像的版本。没有username的代表是docer官方在维护。镜像通常采用软件名直接命名，但是软件名是软件名，镜像名是镜像名，它们是独立的。有时候还会使用构建方式命名，例如：php:7.2-cli，和php:7.2-fpm。约定：没有指定tag时，会默认以latest作为缺省tag，即最新版。生命周期created：容器被创建，相关资源就绪，但程序还未运行；running：容器中的应用在运行；paused：容器中所有程序都处于暂停状态；stopped：相关资源依然被占用，但是程序未运行；deleted：容器删除，释放占用资源，移除存储在Docker中的管理信息。容器的生命周期与容器中PID为1的进程相关联，容器的启动即是该进程的启动，容器的停止即是向该进程发送结束信号。写时复制(copy on write)：编程语言：对象或者数组的拷贝时，复制并不是立刻进行，而是先让两个变量指向同一个内存空间，并进行标记，当要对对象或者数据进行修改时，才真正进行拷贝。docker：运行容器时并不是立刻把镜像里所有的内容拷贝到容器所运行的沙盒文件系统中，而是利用UnionFS将镜像以只读的方式挂载到沙盒文件系统中，只有容器中发生对文件的修改时，修改才会同步到沙盒环境中。docker inspect &lt;image/container&gt;：查看镜像详细构建信息或容器信息（包括容器IP地址，mac地址等），参数是镜像名或ID（支持模糊匹配）。 docker rmi &lt;image&gt;：将镜像从本地engine移除，参数是镜像名或ID，支持多个，以空格分隔。 docker create &lt;image&gt;：根据指定镜像创建容器，可以使用--name选项指定容器名称。 docker start &lt;container&gt;：启动指定容器。 docker run &lt;image&gt;：该命令相当于create和start命令的结合，可以使用--name指定容器名称，使用-d或者--detach选项指定后台运行，-p选项可以使用host-port:container-port将容器端口映射到主机端口，-v可以将某个目录挂载到容器内某个目录，-e设置环境参数，-d设置为后台运行。 docker ps：列出docker容器，默认是列出当前正在运行的的容器，可以使用--all或者-a查看所有状态。 docker kill -s KILL mymysql：向容器发送一个信号&quot;KILL mymysql&quot;，强制杀死容器中的mysql进程。 command：容器中主进程/主程序的启动命令；status：容器所处状态：Created：创建但还未运行；Up[Time]运行中，time表示从开始运行到当前查看的时间间隔；Exited ([Code])[Time]容器结束运行，code表示主程序的退出码，time表示从运行结束到查看时时间间隔；ports：容器的3306映射到宿主机的3306和33060，即容器只开放了两个端口。docker stop &lt;container&gt;：停止容器。 docker rm &lt;container&gt;：删除容器。-f或者--force强制停止并删除容器，不过不推荐。 当短时间内不需要容器时，最佳的做法是删除它。因为：1、docker的轻量级容器设计可以保证我们以最低的成本构建一个全新的、干净的镜像；2、有数据卷可以用来存放非常重要的数据。 docker exec &lt;container&gt;&lt;command&gt;：在某个指定容器里(container)运行某个指定的命令(command)或bash。记住要使用-i或者--interactive保持我们的输入流，保证控制台正确识别我们的指令；并且使用-t或者--tty启用一个伪终端，形成我们与bash的交互。 docker attach &lt;container&gt;：将当前的输入输出流连接到指定容器上，目前功能还不强大，用处不大。 网络配置容器网络模型(container network model):sandbox：沙盒，提供容器虚拟网络栈，包括端口套接字，IP路由表，防火墙等内容，隔离了容器网络和宿主网络；network：容器间通信，虚拟子网；endpoint：位于容器或者网络隔离墙之间的洞，主要目的是形成一个可以控制的突破封闭网络的出入口。cnm：由libnetwork模块实现，包含五大驱动：Bridge Driver（默认），通过网桥实现；Host Driver，借助docker集群模块Docker Swarm搭建的跨docker daemon网络；Overlay Driver；MacLan Driver；None Driver。在docker create或者docker run时就可以使用–link选项连接容器:12dockerrun-d--namemysql-eMYSQL_RANDOM_ROOT_PASSWORD=yesmysqldockerrun-d--namewebapp--linkmysqlwebapp:latest这样的好处在于webapp里不再需要知道数据库的具体位置，只要知道容器名就可以由docker映射。或者--link &lt;container&gt;:&lt;alias&gt;指定容器别名，这样在webapp里的配置文件只需要填例如：”jdbc:mysql://alias:3306/webapp”即可。在docker create或者docker run时可以使用--expose选项指定容器暴露的端口，多个可以写多个该选项暴露端口，接下来只需要容器内主进程/应用程序监听暴露的端口即可。docker network create：创建网络。-d可以指定驱动类型，例如-d bridge individual，创建名为individual的bridge驱动类型的网络，如果不指定,则默认是bridge，可以指定上面提到过的五种类型。 docker network ls：同docker network list，查看docker中已存在的网络。 在docker create或者docker run时可以使用--network来指定容器加入的网络类型，这样就不会加入到bridge这个网络中，但是仍然可以通过--network bridge加入。 在docker create或者docker run时可以使用-p或者--publis来进行端口映射，即将容器端口映射到主机端口上，格式为：-p &lt;ip&gt;:&lt;host-port&gt;:&lt;container-port&gt;其中ip地址是宿主机操作系统的监听IP，可以用来控制监听的网卡，默认为0.0.0.0代表所有网卡。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>CI/CD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SkyWalking基础实践]]></title>
    <url>%2FSkyWalking%E5%9F%BA%E7%A1%80%E5%AE%9E%E8%B7%B5.html</url>
    <content type="text"><![CDATA[简述在应用服务化大行其道的今天，分布式系统的全局监控和链路追踪变得及其重要。分布式系统由于其架构本身的复杂性，人为追踪调试的难度也比较高。Spring Cloud中的Sleuth+Zipkin就是一个链路追踪+系统监控的典型代表，但是本身功能较为简单，相比之下APM(Application Performance Manager)的兼容性和功能都更多一些的，SkyWalking和PinPoint就是其中的两个较为Java程序员所熟悉的。SkyWalking的发起人是中国人吴晟，现已进入Apache孵化(incubator)。官网传送门：http://skywalking.apache.org/zh/。Skywalking介绍SW提供了一个收集、分析、聚合和可视化来自服务和应用数据的观察平台，通过图形化的界面让开发人员认识应用程序的运行情况。主要特性：服务(Service)，实例(Instance)和端点(Endpoint)的metrics分析；根因分析；服务拓扑图分析；服务，实例和端点的依赖分析；慢服务和接口探测；性能优化；分布式追踪以及上下文广播(Trace)；告警(Alarm)；SW架构图如下：由图可知，skywalking支持es，mysql, TiDB, H2, ShardingSphere这些存储方式，用户可以根据自己的能力选择适合自己的存储（其中，H2仅限调研阶段使用，禁止使用在生产环境）。同时存储是开放的，用户可以自定义实现，例如使用HBase作为底层存储。skywalking通过探针收集tracing和metrics数据并格式化，然后通过协议（gRPC或者HTTP）发送给skywalking核心部分即OAP观察分析平台。架构图中间部分就是skywalking的核心，称为skywalking可观测分析平台。并且由图可知，skywalking支持通过gRPC和http两种协议接收数据。且收集的数据主要分为两部分：tracing和metrics。安装ElasticsearchElasticsearch：https://www.elastic.co/cn/downloads/past-releases根据系统平台下载对应的版本，本文下载的是6.6.1版本的es，安装于CentOS 7.2的系统上。出于安全考虑，es不能用root用户启动，所以需要先新增一个用户：1234567891011121314#新增一个用户，用于启动esuseradd es#切换回root用户，解压开下载的压缩文件，新增两个目录交由es存储数据和启动日志sumkdir -p /data/es &amp;&amp; mkdir -p /logs/estar -xzvf elasticsearch-6.6.1.tar.gz -C /usr/local/elasticsearch#将elasticsearch目录的所属用户变为es用户，以及上一步创建的数据目录和日志目录都交给es用户chown -R es /usr/local/elasticsearch /data/es /logs/es#切换回es用户su es#启动es，-d表示后台启动./elasticsearch -d#使用curl探测一下是否启动成功curl http://localhost:9200/此处的es配置如下，配置文件为config/elasticsearch.yml:cluster.name: sw-es node.name: node-1 bootstrap.memory_lock: false bootstrap.system_call_filter: false network.host: 0.0.0.0 http.port: 9200 http.cors.enabled: true http.cors.allow-origin: &quot;*&quot; 可以看到返回结果：[root@izm5edc07yhw50o7ku5zh3z ~]# curl http://localhost:9200/ { &quot;name&quot; : &quot;node-1&quot;, &quot;cluster_name&quot; : &quot;sw-es&quot;, &quot;cluster_uuid&quot; : &quot;srNhViiWSmOfKgrdaIHOvA&quot;, &quot;version&quot; : { &quot;number&quot; : &quot;6.6.1&quot;, &quot;build_flavor&quot; : &quot;default&quot;, &quot;build_type&quot; : &quot;tar&quot;, &quot;build_hash&quot; : &quot;1fd8f69&quot;, &quot;build_date&quot; : &quot;2019-02-13T17:10:04.160291Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;7.6.0&quot;, &quot;minimum_wire_compatibility_version&quot; : &quot;5.6.0&quot;, &quot;minimum_index_compatibility_version&quot; : &quot;5.0.0&quot; }, &quot;tagline&quot; : &quot;You Know, for Search&quot; } 注意：默认的启动日志在es目录下的logs/里，日志名为配置文件里的${cluster_name}.log。如果出现max vitural memory areas vm.max.map.count [65530] is too low的warn或者error，可以执行以下命令：12345##第一种sudo sysctl -w vm.max_map_count=262144##第二种echo "vm.max_map_count=262144" &gt;&gt; /etc/sysctl.confsysctl -p如果出现max file descriptors[65535] for elasticsearch process it too low,increase to at lease [65536]，可以执行以下命令：1234567891011121314151617181920##查看硬件限制ulimit -Hn##修改限制vim /etc/security/limits.conf##添加以下两行，*表示所有用户，也可以指定某个用户* soft nofile 65536* hard nofile 65536 ##或者添加以下几行,提升更多限制* soft memlock unlimited* hard memlock unlimited* soft nofile 65536* hard nofile 65536* soft nproc 2048* hard nproc 4096然后重新登陆用户即可。安装elsaticsearch-heades-head是一个小型的es监控平台，通过es的9200端口的rest Api，图形化展示es存储的数据。安装方式如下：git clone https://github.com/mobz/elasticsearch-head.gitcd elasticsearch-headnpm installnpm run start访问主机的9100端口：http://localhost:9100/界面如图，输入es的端口url，点击连接：集群健康值为green表示正常，图中service_sla_month等都是sw连接es自动创建的。安装SkyWalking下载地址：http://skywalking.apache.org/zh/downloads/如果skywalking的默认端口（有4个端口：8080、10800、11800和12800）有被占用，那么需要处理：修改skywalking的配置或者修改占用端口进程的配置。其中，8080在配置文件webapp/webapp.yml中，10800、11800和12800都在配置文件config/application.yml中。注释掉H2的存储方式，开启elasticsearch的存储方式：12345678910storage:# h2:# driver: $&#123;SW_STORAGE_H2_DRIVER:org.h2.jdbcx.JdbcDataSource&#125;# url: $&#123;SW_STORAGE_H2_URL:jdbc:h2:mem:skywalking-oap-db&#125;# user: $&#123;SW_STORAGE_H2_USER:sa&#125; elasticsearch: # nameSpace: $&#123;SW_NAMESPACE:""&#125; clusterNodes: $&#123;SW_STORAGE_ES_CLUSTER_NODES:localhost:9200&#125; indexShardsNumber: $&#123;SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2&#125; indexReplicasNumber: $&#123;SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0&#125;执行命令bin/startup.sh即可启动sw主程序。说明：skywalking6.x版本运行startup.sh会启动两个服务，强烈建议查看logs目录下的日志文件中是否有error信息。将skywalking解压文件夹中的agent文件夹拷贝到需要监控的应用所在的服务器，更改agent/config目录下的配置文件，重点修改如下配置，其中localhost是skywalking主程序中配置的地址：agent.service_name=${SW_AGENT_NAME:myblog} collector.backend_service=${SW_AGENT_COLLECTOR_BACKEND_SERVICES:localhost:11800} 正常启动java应用时，只需要带上如下参数即可，例如：java -javaagent:/usr/local/skywalking-agent/skywalking-agent.jar -jar Myblog.jar,其中-javaagent的内容就是上面拷贝的sw agent所在的位置。查看结果访问8080端口，再多次访问我的博客项目的/index接口：点击左侧导航栏的trace菜单,即可看到index接口的的响应情况：建议请保证被监控服务的系统时间和skywalking OAP服务的系统时间是一致的；config/agent.config中的agent.service_name请使用英文；jvm参数添加的-javaagent:/agent/skywalking-agent.jar请放在-jar前面（即使skywalking6.x放在-jar后面也能正常运行），比如：java -javaagent:/agent/skywalking-agent.jar -jar skywalking-demo.jar。参考阿飞的博客：https://mp.weixin.qq.com/s/MZ9PsFlOaGYMwioQ9FX_8Q]]></content>
      <categories>
        <category>编程技术</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git学习笔记]]></title>
    <url>%2FGit%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.html</url>
    <content type="text"><![CDATA[概述官网：https://git-scm.com/。CVS/SVN：集中式版本管理工具，没有网则无法提交，按文件方式存储内容，版本库只有中央服务器有，如果要提交代码，需要先获取最新版本库；GIT：分布式，每个人电脑里都有要完整的版本库，分支管理功能强大，按元数据方式存储内容，提交代码无需获取最新版本库，只需交换差异代码，内容完整优于svn和cvs。笔记主要记了基本概念、基本命令、命令大全（转载）以及流行的分支模型。安装Windows:官网下载https://git-scm.com/download/win，安装即可；Linux:1yum install -y gitUbuntu/Debian:1sudo apt-get install git Centos/RedHat教程基本概念git有三个区：工作区，就是我们写的代码。暂存区或者索引，stash或者index，在项目的隐藏目录.git里：.git/index；版本库（本地仓库），即.git目录。贴一张从菜鸟教程盗来的图：本地操作git init：初始化当前目录为一个仓库，加入git管理，此时，当前目录下出现隐藏目录.git，即版本库，版本库不能随意修改。 git add：将文件添加到缓存区，可以添加多个，一次性提交。 git status：查看当前缓存区列表； git commit：提交到该版本库。 [-m]：强烈建议带上该参数，即git commit -m &lt;message&gt;，表示提交说明。 git diff：&lt;file&gt;文件比对。 git log：显示每次提交的记录。 [--pretty=oneline]：美化显示，只显示message和版本号。 git reset：回退版本，例如：git reset --hard HEAD^，代表往上回退一个版本，从modify的这个版本回退到initial的版本了，两个^即是上两个版本。需要注意的是，这样一来，再执行git log命令时，已经看不到modify的记录了。当然如果能找到modify版本的版本号，还是可以恢复的，比如：git reset --hard c0950，版本号可以不用写全，它会自己匹配，将内部的HEAD指针指向对应的版本号。git reset HEAD &lt;file&gt;：移除file在暂存区的内容。 git reflog：然鹅，如果找不到版本号了，就需要这个指令了，记录了每一次所处的版本号和输入的命令，于是，还是可以恢复到最新版本的。 git checkout：--&lt;file&gt;表示丢弃某个文件在工作区中的修改，如果更改没有放入暂存区，则恢复到版本库内容；如果已经放入暂存区后进行了修改，则恢复到暂存区内容； git rm：&lt;file&gt;删除文件，如果使用系统自带的rm命令，git将会忽略这种删除方式，同时再输入git add 需要跟上 -A/--all/--ignore-removal命令才能成功添加，&apos;git add --ignore-removal &lt;pathspec&gt;&apos;，是当前版本的默认操作，忽略本地工作区中移除的文件。 &apos;git add --all &lt;pathspec&gt;&apos; 将对删除操作进行记录，同git rm的方式类似。如果工作区删错了，也可以用git checkout --&lt;file&gt;的方式撤销工作区更改，git rm --cached &lt;dir/file&gt; 可以删除已经add但是还没有commit的记录。 远程操作首先要有一个远程仓库和SSH-key，码云、github等都差不多。创建SSH Key。在用户主目录下，看看有没有.ssh目录，如果有，再看看这个目录下有没有id_rsa和id_rsa.pub这两个文件，如果已经有了，可直接跳到下一步。如果没有，打开Shell（Windows下打开Git Bash），创建SSH Key：ssh-keygen -t rsa -C &quot;liuhuijun_2017@163.com&quot;生成密钥对（记住邮箱那里要填自己在远程仓库的标识），找到.ssh目录找到id_rsa（私钥）和id_rsa.pub（公钥），复制公钥里的内容。登录代码托管网站，点击“Add SSH Key”，粘贴刚刚复制的内容。将本地工作区添加远程仓库，名为origin。git remote add origin git@gitee.com:guitar_coder/git-learning.git（SSH方式）或者 git remote add origin https://gitee.com/guitar\_coder/git-learning.git（HTTPS方式）。常用命令：git pull:[origin] [remote-branch]:[local-branch]，如果参数全部带上，表示从origin主机的remote-branch更新代码到本地的local-branch分支，相当于git fetch+git merge。git push：[-u] [origin] [local-master]:[remote-master] 将本地master分支推送到远程master分支，并且将origin作为默认主机，在将来的推送或者拉取时就可以简化该命令，直接使用git push，只需要第一次推送使用这个命令即可。如果省略远程分支名，那么默认会将代码提交到与本地分支同名的远程分支，远程没有会自动创建。note：如果创建远程仓库时使用了初始化模板，那么远程仓库就会有一些readme.md或者.gitignore等文件，那么需要先git pull &lt;remote&gt; &lt;branch&gt;，在本文中就是git pull origin master，意为拉取远程主分支。也可以git branch --set-upstream-to=origin/&lt;branch&gt; master，处填入远程主分支，意为将本地主分支与远程主分支关联，然后执行git pull。如果提示refusing to merge unrelated histories，表示当前代码仓库和远程仓库是两个仓库，不能直接pull，可以执行git pull origin master --allow-unrelated-histories ，关联好后，最后可以直接执行git push。git clone &lt;url&gt;：克隆远程仓库，加-b选项可以指定拉取仓库的某个分支代码，例如git clone -b release url。git checkout：切换分支，[-b]创建并切换到分支，相当于git branch &lt;branch&gt;，然后git checkout &lt;branch&gt;。git branch：查看分支；创建分支；[-d|-D]删除分支|未合并强制删除。Git还会自动提示我们当前master分支比远程的master分支的超前状态。git merge：将分支合并到当前分支。有时候，比如你在这个分支上改了某一个地方，其他人在另一个分支上改了同样一个地方，这样就会导致冲突，需要解决冲突，需要手动合并修改该文件，再重新add并commit。这时候使用git log --graph --pretty=oneline --abbrev-commit,可以看到记录变更。使用git 默认的Fast-forward方式合并分支可能会导致在删除被合并分支后丢失合并信息，所以可以用--no-ff禁用Fast-forward的方式，这样 在合并的时候它会自动创建一个新的commit：git merge --no-ff -m &quot;merge without fast-forward&quot; &lt;branch&gt;。git stash：可以理解为将当前工作保存一份快照，执行该指令后，通过git status查看工作空间就如同上次提交后没有更改一样。然后我们可以新建分支去修复bug或者去做一些临时工作，然后切换到主分支，将修复的bug分支合并进来。这时候我们再恢复快照，git stash list可以查看快照列表，可以用git stash apply &lt;stash@{0}&gt;选择恢复到哪个快照，如果产生冲突了，按照前面merge产生冲突的方案解决即可。apply恢复不会删除快照，可以使用git stash pop &lt;stash@{0}&gt;恢复并删除快照，如果产生冲突了，这个命令也不会删除快照，可以使用git stash clear清空快照。git remote：[-v]查看远程仓库地址，本地新建的分支如果不push到远程，那么别人就是看不到的。[add]：为当前工作空间关联名为origin-name的远程仓库，[remove]移除远程仓库关联。[rm]同删除远程仓库。在上面git push一节讲过如果仓库里有一些模板文件的时候，直接push是不成功的，需要先pull，如果提示no-tracking information，需要添加本地分支与远程分支的关联。git rebase：git merge合并：所有本地commit是基于当前本地的master，最终push会将远程最新master合并到本地，首先前移本地master，最终会形成一次新的commit推送到远程将远程master前移，这样就会形成分叉；git rebase合并：它会挪动所有本地commit是基于远程最新的master，即最终push会直接将远程master前移，整理成一条直线，git tag：给分支打标签，如果不加该选项，则是查看所有标签，&lt;commit_id&gt;给某版本commit加上tag，默认是当前HEAD，git tag -a v0.1 -m &quot;version 0.1 released&quot; 1094adb ，[-a]指定标签名，[-m]指定说明文字，[-d]删除，推送某个标签到远程：git push origin &lt;tagname&gt;，一次性推送全部尚未推送到远程的本地标签：git push origin --tags，删除远程标签：git push origin :refs/tags/&lt;tagname&gt;。git：查看标签信息。总结下来，多人协作模式为（假设远程仓名为origin，远程主分支为master，本地主分支为master）：首先git pull origin master；如果没有关联，则git branch--set-upstream-to=origin/master master；如果产生冲突，本地解决冲突以后add并commit；然后git push origin master，如果推送失败，则代表远程分支比本地新，回到第一步。常用命令大全转载自阮一峰博客：一、新建代码库 # 在当前目录新建一个Git代码库 $ git init # 新建一个目录，将其初始化为Git代码库 $ git init [project-name] # 下载一个项目和它的整个代码历史 $ git clone [url] 二、配置 Git的设置文件为.gitconfig，它可以在用户主目录下（全局配置），也可以在项目目录下（项目配置）。 # 显示当前的Git配置 $ git config --list # 编辑Git配置文件 $ git config -e [--global] # 设置提交代码时的用户信息 $ git config [--global] user.name &quot;[name]&quot; $ git config [--global] user.email &quot;[email address]&quot; # 清空用户名密码 $ git config --system --unset credential.helper # 保存用户名密码 $ git config --global credential.helper store 三、增加/删除文件 # 添加指定文件到暂存区 $ git add [file1][file2]... # 添加指定目录到暂存区，包括子目录 $ git add [dir] # 添加当前目录的所有文件到暂存区 $ git add . # 添加每个变化前，都会要求确认 # 对于同一个文件的多处变化，可以实现分次提交 $ git add -p # 删除工作区文件，并且将这次删除放入暂存区 $ git rm [file1][file2]... # 停止追踪指定文件，但该文件会保留在工作区 $ git rm --cached [file]# 改名文件，并且将这个改名放入暂存区 $ git mv [file-original][file-renamed] 四、代码提交 # 提交暂存区到仓库区 $ git commit -m [message] # 提交暂存区的指定文件到仓库区 $ git commit [file1][file2]...-m [message] # 提交工作区自上次commit之后的变化，直接到仓库区 $ git commit -a # 提交时显示所有diff信息 $ git commit -v # 使用一次新的commit，替代上一次提交 # 如果代码没有任何新变化，则用来改写上一次commit的提交信息 $ git commit --amend -m [message ]# 重做上一次commit，并包括指定文件的新变化 $ git commit --amend [file1][file2]... 五、分支 # 列出所有本地分支 $ git branch # 列出所有远程分支 $ git branch -r # 列出所有本地分支和远程分支 $ git branch -a # 新建一个分支，但依然停留在当前分支 $ git branch [branch-name] # 新建一个分支，并切换到该分支 $ git checkout -b [branch] # 新建一个分支，指向指定commit $ git branch [branch][commit] # 新建一个分支，与指定的远程分支建立追踪关系 $ git branch --track [branch][remote-branch] # 切换到指定分支，并更新工作区 $ git checkout [branch-name] # 切换到上一个分支 $ git checkout # 建立追踪关系，在现有分支与指定的远程分支之间 $ git branch --set-upstream [branch][remote-branch] # 合并指定分支到当前分支 $ git merge [branch] # 选择一个commit，合并进当前分支 $ git cherry-pick [commit] # 删除分支 $ git branch -d [branch-name] # 删除远程分支 $ git push origin --delete [branch-name] $ git branch -dr [remote/branch] 六、标签 # 列出所有tag $ git tag # 新建一个tag在当前commit $ git tag [tag] # 新建一个tag在指定commit $ git tag [tag][commit] # 删除本地tag $ git tag -d [tag] # 删除远程tag $ git push origin :refs/tags/[tagName] # 查看tag信息 $ git show [tag] # 提交指定tag $ git push [remote][tag] # 提交所有tag $ git push [remote]--tags # 新建一个分支，指向某个tag $ git checkout -b [branch][tag] 七、查看信息 # 显示有变更的文件 $ git status # 显示当前分支的版本历史 $ git log # 显示commit历史，以及每次commit发生变更的文件 $ git log --stat # 搜索提交历史，根据关键词 $ git log -S [keyword] # 显示某个commit之后的所有变动，每个commit占据一行 $ git log [tag] HEAD --pretty=format:%s # 显示某个commit之后的所有变动，其&quot;提交说明&quot;必须符合搜索条件 $ git log [tag] HEAD --grep feature # 显示某个文件的版本历史，包括文件改名 $ git log --follow [file] $ git whatchanged [file] # 显示指定文件相关的每一次diff $ git log -p [file] # 显示过去5次提交 $ git log -5--pretty --oneline # 显示所有提交过的用户，按提交次数排序 $ git shortlog -sn # 显示指定文件是什么人在什么时间修改过 $ git blame [file] # 显示暂存区和工作区的差异 $ git diff # 显示暂存区和上一个commit的差异 $ git diff --cached [file] # 显示工作区与当前分支最新commit之间的差异 $ git diff HEAD # 显示两次提交之间的差异 $ git diff [first-branch]...[second-branch] # 显示今天你写了多少行代码 $ git diff --shortstat &quot;@{0 day ago}&quot; # 显示某次提交的元数据和内容变化 $ git show [commit] # 显示某次提交发生变化的文件 $ git show --name-only [commit] # 显示某次提交时，某个文件的内容 $ git show [commit]:[filename] # 显示当前分支的最近几次提交 $ git reflog 八、远程同步 # 下载远程仓库的所有变动 $ git fetch [remote] # 显示所有远程仓库 $ git remote -v # 显示某个远程仓库的信息 $ git remote show [remote] # 增加一个新的远程仓库，并命名 $ git remote add [shortname][url] # 取回远程仓库的变化，并与本地分支合并 $ git pull [remote][branch] # 上传本地指定分支到远程仓库 $ git push [remote][branch] # 强行推送当前分支到远程仓库，即使有冲突 $ git push [remote]--force # 推送所有分支到远程仓库 $ git push [remote]--all 九、撤销 # 恢复暂存区的指定文件到工作区 $ git checkout [file] # 恢复某个commit的指定文件到暂存区和工作区 $ git checkout [commit][file] # 恢复暂存区的所有文件到工作区 $ git checkout . # 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变 $ git reset [file] # 重置暂存区与工作区，与上一次commit保持一致 $ git reset --hard # 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变 $ git reset [commit] # 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致 $ git reset --hard [commit] # 重置当前HEAD为指定commit，但保持暂存区和工作区不变 $ git reset --keep [commit] # 新建一个commit，用来撤销指定commit # 后者的所有变化都将被前者抵消，并且应用到当前分支 $ git revert [commit] # 暂时将未提交的变化移除，稍后再移入 $ git stash $ git stash pop 十、其他 # 生成一个可供发布的压缩包 $ git archive 子模块管理对于一个项目有多个模块，而每个模块又是一个单独的仓库，可以使用git submodule命令。例如我的hexo博客项目在github上是一个仓库，而hexo的主题next主题又是单独的一个仓库，当我clone博客代码以后，还需要clone一份主题代码，有如下两种clone方式：123456##1.递归clonegit clone url --recursive##2.先clone父项目，然后到父项目目录里更新submodulegit clone parent_urlgit submodule initgit submodule update更新代码也有两种方式可选：1234##1.递归pullgit submodule foreach git pull##2.进入到submodule所在目录git pull提交代码：12345678##进入到submodule所在目录git add ./git commit -m &quot;&quot;git push##然后回到父目录git push##更简单的方式:递推提交git submodule foreach git commit -a -m &quot;&quot;删除：1234567##首先删除submodule缓存区内容git rm --cached submodulerm submobule##删除git的.gitmodules隐藏文件rm .gitmodules##彻底清理文件，删除和submodule有关的内容vim .git/congig常用代码分支策略TBD：主干开发我当前所处公司使用的策略。所有开发者在一个称为”trunk”，即git的master分支中对代码进行协作，除了发布分支外没有其他开发分支。工作机制：发布的分支时主干某个时刻的快照，以后的改bug和功能增强，都是提交到主干，必要时会cherry-pick（选择部分变更集合并到其他分支）。即分支只用来发布，主干用来开发。代表公司：Google、Facebook。优点：避免了分支合并时的麻烦；集成冲突少，集成效率高；有利于持续交付。缺点：容易因一个人的代码导致崩溃等生产事故；要借助特性切换等机制来保证线上运行的正确性。分支开发工作机制：新建一个分支开发，保证其代码稳定，并通过自动化测试和代码审查后，然后合并到主干。Git Flow于2011左右被大家当作了推荐的分支模型：develop即开发分支，master是主分支，release是发布分支，hotfix为修复分支，feature是特性分支。然而，release和hotfix显得很多余，大多数都不会去用。Github FlowGitHub Flow是GitHub所使用的一种简单流程，该流程只使用master和特性分支，并借助GitHub的pull request功能。master只包含稳定的代码，即将发布到或部署到生产环境，任何开发人员都不允许把未测试或未审查的代码直接提交到master分支，对任何代码的修改、包括bug修复、热修复、新功能开发等都在单独的分支中进行。当新分支中的代码全部完成以后，会有其他人对代码进行审查，提出相关的修改意见，有持续集成服务器对新分支进行自动化测试，然后才能合并到master，在部署到生产环境。GitLab FlowGitLab Flow在GitHub Flow的基础上做了改良，额外衍生出三个子类模型：带生产分支：无法控制准确的发布时间，但又要求不停集成的。需要创建一个production分支来防止发布的代码。带环境分支：要求所有代码都在诸葛环境中测试过。需要未不同的环境建立不同的分支。带发布分支：用于对外界发布软件的项目，同时需要维护多个发布版本。尽可能晚地从master拉取发布分支。bug的修改应先合并到master，然后cherry pick到release分支。代表公司：阿里、携程、美团、点评优点：不同功能可以在独立分支上开发，消除了功能稳定前彼此干扰的问题；保证了主干分支的质量。缺点：如果不及时合并，那么特性分支合并到主干会比较麻烦；如果要做CI/CD，需要对不同分支配备不同的构建环境。参考参考廖雪峰git教程:https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000，以及阮一峰git常用命令清单：http://www.ruanyifeng.com/blog/2015/12/git-cheat-sheet.html，文中大量借用并参考，致谢。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>CI/CD</tag>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MybatisGenerator实践]]></title>
    <url>%2FMybatisGenerator%E5%AE%9E%E8%B7%B5.html</url>
    <content type="text"><![CDATA[描述MBG是mybatis官方提供的代码生成工具，官网：http://www.mybatis.org/generator/index.html。这篇文章主要记录了自己使用MBG的过程，同时还会使用通用mapper-tk.mapper来简化mybatis的dao层接口的初始化过程，提高工作中的开发效率。每使用一个产品或者工具，我认为读一读官方文档去了解它设计出来的目的，以及核心思想或者简介都是一个学习的过程。MyBatis Generator (MBG) is a code generator for MyBatis MyBatis and iBATIS. It will generate code for all versions of MyBatis, and versions of iBATIS after version 2.2.0. It will introspect a database table (or many tables) and will generate artifacts that can be used to access the table(s). This lessens the initial nuisance of setting up objects and configuration files to interact with database tables. MBG seeks to make a major impact on the large percentage of database operations that are simple CRUD (Create, Retrieve, Update, Delete). You will still need to hand code SQL and objects for join queries, or stored procedures.翻译过来大概的意思就是：MBG是一个Mybatis和iBatis的代码生成工具。它能够为几乎所有版本的Mybatis或者2.2.0版本以后的iBatis生成代码，它将读取（introspect内置的意思，理解为读取不知道可对）一个数据库表（或者很多的表）并且将会创建一个可以读取这些表的实体。这样就可以减轻初始化时令人厌烦的设置对象和与数据库表交互的的配置文件。MBG致力于对简单的CRUD数据库操作产生重大影响。但是你依然需要对一些join查询和存储过程手动编写sql语句。使用我们项目中常使用的有三种方式，分别是：maven集成（兼容性和通用性最好，推荐），与IDE集成，命令行。maven集成首先引入maven plugin：1234567891011121314151617&lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.38&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;configuration&gt; &lt;!--配置文件的路径--&gt; &lt;configurationFile&gt;$&#123;basedir&#125;/src/main/resources/MBG/GeneratorConfig.xml&lt;/configurationFile&gt; &lt;overwrite&gt;true&lt;/overwrite&gt; &lt;/configuration&gt; &lt;/plugin&gt;配置文件GeneratorConfig.xml：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE generatorConfiguration PUBLIC "-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN" "http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd"&gt;&lt;generatorConfiguration&gt; &lt;context id="test" targetRuntime="MyBatis3"&gt; &lt;property name="javaFileEncoding" value="UTF-8"/&gt; &lt;plugin type="org.mybatis.generator.plugins.EqualsHashCodePlugin"&gt;&lt;/plugin&gt; &lt;plugin type="org.mybatis.generator.plugins.SerializablePlugin"&gt;&lt;/plugin&gt; &lt;plugin type="org.mybatis.generator.plugins.ToStringPlugin"&gt;&lt;/plugin&gt; &lt;commentGenerator&gt; &lt;!-- 这个元素用来去除指定生成的注释中是否包含生成的日期 false:表示保护 --&gt; &lt;!-- 如果生成日期，会造成即使修改一个字段，整个实体类所有属性都会发生变化，不利于版本控制，所以设置为true --&gt; &lt;property name="suppressDate" value="true" /&gt; &lt;!-- 是否去除自动生成的注释 true：是 ： false:否 --&gt; &lt;property name="suppressAllComments" value="true" /&gt; &lt;/commentGenerator&gt; &lt;!--数据库链接URL，用户名、密码 --&gt; &lt;jdbcConnection driverClass="com.mysql.jdbc.Driver" connectionURL="jdbc:mysql://localhost:3306/tubitu?useSSL=false" userId="" password="^88*"&gt; &lt;/jdbcConnection&gt; &lt;javaTypeResolver&gt; &lt;!-- This property is used to specify whether MyBatis Generator should force the use of java.math.BigDecimal for DECIMAL and NUMERIC fields, --&gt; &lt;property name="forceBigDecimals" value="false" /&gt; &lt;/javaTypeResolver&gt; &lt;!-- 生成模型的包名和项目中路径--&gt; &lt;javaModelGenerator targetPackage="com.tubitu.model" targetProject="src\main\java"&gt; &lt;property name="enableSubPackages" value="true" /&gt; &lt;property name="trimStrings" value="true" /&gt; &lt;/javaModelGenerator&gt; &lt;!-- 生成映射文件的目录名和项目中路径 --&gt; &lt;sqlMapGenerator targetPackage="mapper" targetProject="src\main\resources\"&gt; &lt;property name="enableSubPackages" value="true" /&gt; &lt;/sqlMapGenerator&gt; &lt;!-- 生成DAO interface的包名和项目中路径 --&gt; &lt;javaClientGenerator type="XMLMAPPER" targetPackage="com.tubitu.mapper" targetProject="src\main\java"&gt; &lt;property name="enableSubPackages" value="true" /&gt; &lt;/javaClientGenerator&gt; &lt;!-- 要生成哪些表 --&gt; &lt;table tableName="test" domainObjectName="testttt" enableCountByExample="false" enableUpdateByExample="false" enableDeleteByExample="false" enableSelectByExample="false" selectByExampleQueryId="false"&gt;&lt;/table&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt;使用方法：IDEA：点开IDEA的Maven Projects的panel，展开plugins，运行MBG插件即可Eclipse：右击项目 –&gt; run as –&gt; maven build–&gt; Goals中写入命令 “mybatis-generator:generate”–&gt; apply –&gt; runIDE集成Eclipse：在Eclipse marketplace里搜索”MyBatis Generator”，或者 https://dl.bintray.com/mybatis/mybatis-generator直接下载二进制安装压缩包，在Eclipse里安装即可，配置文件与上面的几乎一致，不过需要注意的是要自己指定数据库驱动包的位置，即在配置文件标签内第一行加入如下配置：12&lt;classPathEntry location="D:\Applications\ProgrammingTools\maven\MavenRepository\mysql\mysql-connector-java\5.1.36\mysql-connector-java-5.1.36.jar" /&gt;然后在配置上右击，运行即可：IDEA：目前官方并没有IDEA插件，但是有第三方作者上传了插件，在plugin repository搜索即可。命令行创建一个文件夹，将需要的mysql驱动、oracle驱动以及MBG的jar包放入，并在当前目录下新建配置文件，文件如第二种方式，需要指定数据库驱动位置，然后打开命令行，输入以下：1java -jar mybatis-generator-core-x.x.x.jar -configfile generatorConfig.xml -overwriteoverwrite表示重名文件会覆盖，如果觉得这样麻烦，可以新建两个脚本，windows下的命名xx.bat，Linux/Mac下命名为xx.sh，把上面命令复制进去，使用的时候双击即可。注意：配置文件generatorConfig.xml里的targetProject里的第一级目录如果不存在，是会报错的，所以需要提前创建目录。扩展如果觉得这么做还是麻烦，还是很low，还有更便捷的方式，那就是使用mybatis的官方推荐通用mapper，作者是刘增辉大神（也是pagehelper作者）。用法还是比较简单的，引入依赖：123456&lt;!-- 通用Mapper --&gt;&lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper&lt;/artifactId&gt; &lt;version&gt;3.3.9&lt;/version&gt;&lt;/dependency&gt;然后配置Mybatis的mapper，xml文件配置方式：123456789&lt;!-- 通用 Mapper --&gt;&lt;bean class="tk.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;property name="basePackage" value="cn.com.test.dao"/&gt; &lt;property name="properties"&gt; &lt;value&gt; mappers=tk.mybatis.mapper.common.Mapper &lt;/value&gt; &lt;/property&gt;&lt;/bean&gt;而对于Spring Boot的自动配置，可以引入如下依赖(本文spring boot版本号为2.1.0.RELEASE)：12345&lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.2&lt;/version&gt;&lt;/dependency&gt;在yml配置文件加入通用配置和数据库类型：123mapper: mappers: tk.mybatis.mapper.common.Mapper identity: mysql在启动类加上注解，扫描数据dao层接口:123456789101112131415package com.blog;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import tk.mybatis.spring.annotation.MapperScan;@SpringBootApplication@MapperScan("com.blog.mapper")public class MyBlogApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(MyBlogApplication.class, args); &#125;&#125;需要注意的是，这里的MapperScan()使用的是tk.mapper的注解。实体类加上@Table注解，并写上name表示映射的表名，如果不写，表名默认为类名转下划线，如类名：UserInfo 对应表名user_info；成员变量加上@Column注解，不写name属性默认也是变量名驼峰转下划线的形式；如果实体类的变量多于数据库表里的字段，可以加上@Transient表示不作为表字段使用，一般推荐实体类与数据库对应，多余的字段使用dto继承扩展。建议一定是要有一个@Id注解表示主键，可以有多个表示联合主键，如果是Mysql的自增字段，加上@GeneratedValue(generator=”JDBC”)即可。例如：123456789101112131415161718192021222324@Table(name = "pv_log")public class PvLog implements Serializable &#123; @Id @GeneratedValue(generator = "JDBC") private Integer id; @Column private String ip; @Column private Integer visitTime; @Column private String referer; @Column private Date updateTime; @Column private String type; //省略get/set方法&#125;而mybatis接口只需继承Mapper接口并指定泛型即可，泛型必须明确指定，这样继承的mapper就有了通用Mapper的所有方法。例如：123456public interface PvLogMapper extends Mapper&lt;PvLog&gt; &#123; public List&lt;Integer&gt; getIndexCount();&#125;通用mapper包含的方法说明：Select 方法：List&lt;T&gt; select(T record); 说明：根据实体中的属性值进行查询，查询条件使用等号 方法：T selectByPrimaryKey(Object key); 说明：根据主键字段进行查询，方法参数必须包含完整的主键属性，查询条件使用等号 方法：List&lt;T&gt; selectAll(); 说明：查询全部结果，select(null)方法能达到同样的效果 方法：T selectOne(T record); 说明：根据实体中的属性进行查询，只能有一个返回值，有多个结果是抛出异常，查询条件使用等号 方法：int selectCount(T record); 说明：根据实体中的属性查询总数，查询条件使用等号 Insert 方法：int insert(T record); 说明：保存一个实体，null的属性也会保存，不会使用数据库默认值 方法：int insertSelective(T record); 说明：保存一个实体，null的属性不会保存，会使用数据库默认值 Update 方法：int updateByPrimaryKey(T record); 说明：根据主键更新实体全部字段，null值会被更新 方法：int updateByPrimaryKeySelective(T record); 说明：根据主键更新属性不为null的值 Delete 方法：int delete(T record); 说明：根据实体属性作为条件进行删除，查询条件使用等号 方法：int deleteByPrimaryKey(Object key); 说明：根据主键字段进行删除，方法参数必须包含完整的主键属性 Example方法 方法：List&lt;T&gt; selectByExample(Object example); 说明：根据Example条件进行查询 重点：这个查询支持通过Example类指定查询列，通过selectProperties方法指定查询列 方法：int selectCountByExample(Object example); 说明：根据Example条件进行查询总数 方法：int updateByExample(@Param(&quot;record&quot;) T record, @Param(&quot;example&quot;) Object example); 说明：根据Example条件更新实体record包含的全部属性，null值会被更新 方法：int updateByExampleSelective(@Param(&quot;record&quot;) T record, @Param(&quot;example&quot;) Object example); 说明：根据Example条件更新实体record包含的不是null的属性值 方法：int deleteByExample(Object example); 说明：根据Example条件删除数据]]></content>
      <categories>
        <category>编程技术</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java热部署实践-Jrebel]]></title>
    <url>%2FJava%E7%83%AD%E9%83%A8%E7%BD%B2%E5%AE%9E%E8%B7%B5-Jrebel.html</url>
    <content type="text"><![CDATA[描述热部署的作用是在不重启项目的情况下，使用类加载器重新加载修改过的.class文件到内存，避免花费时间在重启上。目前比较常用的有两种热部署，分别为spring-boot-devtools和JRebel。spring-boot-devtools官网：https://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#using-boot-running-with-the-maven-plugin；使用方式是直接引入Maven插件或者Gradle插件即可：1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt;&lt;/dependencies&gt;123456789configurations &#123; developmentOnly runtimeClasspath &#123; extendsFrom developmentOnly &#125;&#125;dependencies &#123; developmentOnly("org.springframework.boot:spring-boot-devtools")&#125;同时官网说明如下：Restart vs ReloadThe restart technology provided by Spring Boot works by using two classloaders. Classes that do not change (for example, those from third-party jars) are loaded into a base classloader. Classes that you are actively developing are loaded into a restart classloader. When the application is restarted, the restart classloader is thrown away and a new one is created. This approach means that application restarts are typically much faster than “cold starts”, since the base classloader is already available and populated.If you find that restarts are not quick enough for your applications or you encounter classloading issues, you could consider reloading technologies such as JRebelfrom ZeroTurnaround. These work by rewriting classes as they are loaded to make them more amenable to reloading.解释过来就是：spring boot提供了两个类加载器来进行热部署，一个叫基础类加载器，用于加载不会变化的一些系统jar包和第三方jar包；另一个是重启类加载器，当项目发生更改时，重启类加载器会抛弃旧的类加载器，并重新创建一个重启类加载器（个人觉得spring boot这里用到了OSGI的模块化思想），这意味者这种热重启通常意义下是比冷重启是快很多的，因为基础类加载器一直是可用并且就绪。如果你发现重启速度不够快或者发现了一些重启导致的问题，你可以使用ZeroTurnaround 的产品JRebel，它通过重写class文件来使得class文件适合被重新加载。在一般情况下，我们使用spring boot的热部署即可，然而我们的项目是需要通过RPC方式进行调用和通信的，这势必会导致一个问题，我们在远程发布服务并暴露通知到本地jvm，启动项目用的是v1 restart classLoader，当我们改了A.java某一行代码，原来v1 restart classLoader被抛弃，现在A.java是由v2 restart classLoader加载的。当你本地调用远程服务时，它会发现本地jvm里的A.java与远程A.java类信息不一致，于是会报 “A cannot cast to A”的错误。所以这里我们采用JRebel来进行重启。JRebel并不是开源免费的，作为一个商业产品，它并不算便宜，有条件的请支持正版。安装集成环境描述：Intellij IDEA 2018.1JRebel 2018.1JRebel集成到IDEA只需要到IDEA的plugin里，点击Browse repository，输入JRebel，安装JRebel for IntelliJ，完成以后点击重启IDEA。再次进入到IDEA设置界面，此时已经多了JRebel的选项:激活需要反向代理工具，github链接：https://github.com/ilanyu是不是一个眼熟的名字……是的，同时也是IDEA破解一系列的作者，在校大学生。选择ReverseProxy，再进入到Release页面：选择对应版本下载，darwin代表Mac os的UNIX-like系统。选择立刻激活，再选择I have license：运行刚刚下载的反向代理：代表监听本机的8888端口请求发往了作者提供的一个激活服务器，有条件的可以自己搭建一个类似的激活服务器避免lanyu的服务器被封。输入上图中类似的内容，除了http://127.0.0.1:8888不能改变以外，后面的内容可以随便填写，但是不能直接写明文，需要转换为GUID的形式。例如http://127.0.0.1:8888/liuhuijun，搜索GUID生成工具，输入liuhuijun生成，则上图中正确的内容为http://127.0.0.1:8888/e250f540-41e3-450b-aabb-0f376f83c241，下面的邮箱可以随意填写，只要格式正确即可，然后可以看到激活成功，可以使用180天，这个时候就可以再JRebel的界面点击work offline，开始脱机工作，如果180天后还想继续使用，可以点击Renew ofline seat，重新获取180天（Renew可以不借助反向代理）。以上激活步骤，目前适用于JRebel 2018.1等较新版本，其他版本未测试。有条件请支持正版！接下来，就可以享受热部署的顺滑了……，左边启动，右边debug。还可以点击左下角的JRebel唤出panel勾选项目，它会自动在对应的项目下面的resource生成一个rebel.xml文件，可以根据官方来进行一些自定义配置。安装扩展Mybatis以上的标准步骤所激活的JRebel是不支持Mybatis里的xml更新热部署的，如果你想更新了sql也能够热部署， 请继续往下看：支持sql热部署的JRebel叫JRebel-nightly，官网：https://zeroturnaround.com/software/jrebel/download/nightly-build/#!/intellij方式一：下载第一个红框里地址的压缩包，解压开，里面有一个JRebel.jar，记住其位置，然后在IDEA里面指定使用的代理jar包：使用刚刚解压的那个作为JRebel的代理类。方式二：.就是不使用IDEA自带的的plugin repository的插件，直接在JRebel-nightly的那个页面选择下载第二个红框里的包，然后卸载原来的JRebel，从磁盘安装你新下载的这个插件压缩包（无需解压）,然后重复上面的po 解步骤即可。一些配置为方便开发，可以通过设置IDEA来实现完全的实时更新部署。勾选上图中的自动编译：然后按Ctrl + Shift + a，弹出万能搜索框，输入registry再输入running，勾选运行时自动构建：这样当你更新代码后，即会触发JRebel的热部署，但是同时也会增加IDEA的开销，如果代码报错还会导致报错，所以推荐还是用手动编译吧，快捷键：Ctrl + F9 编译整个项目 Ctrl + Shift + F9，编译刚刚修改的类。补充（2018-12-20更新）对于spring boot的devtools热部署出现的”A cannot cast to A”的问题，可以通过配置热部署配置文件来让某个类文件使用同一个类加载器加载。例如：Mybatis的通用Mapper在使用devtools的时候，通用Mapper会使用base类加载器，而项目中的实体类会使用restat类加载器，会导致上述的错，只要保证它们使用同一个类加载器就可以解决，可以在 src/main/resources 中创建 META-INF 目录，在此目录下添加 spring-devtools.properties 配置，内容如下：restart.include.mapper=/mapper-[\\w-\\.]+jar restart.include.pagehelper=/pagehelper-[\\w-\\.]+jar dubbo里也可能会出现这种情况，所以也可以将dubbo的类加载器配置为使用restart类加载器。]]></content>
      <categories>
        <category>编程技术</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[持续集成服务器Jenkins实践]]></title>
    <url>%2F%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E6%9C%8D%E5%8A%A1%E5%99%A8Jenkins%E5%AE%9E%E8%B7%B5.html</url>
    <content type="text"><![CDATA[描述Jenkins是一个开源的自动部署服务器，提供了上百个插件用于自动构建、部署、发布任务项目。本文描述的是Jenkins本地部署以及远程部署等工作实现持续集成功能。官网传送门安装部署Jenkins可以在几乎所有的平台（包括docker）上运行，本文采用Java程序员最熟悉的一种方式来进行安装，即将Jenkins运行于Tomcat容器里，使用Tomcat默认的8080端口。无需进行任何配置，直接启动Tomcat。Jenkins配置访问Jenkins地址，初次进入它会让输入一个密码，密码的位置已经在初次进入的页面里显示，一般情况下，Linux服务器上的位置为：/root/.jenkins/secrets/initialAdminPassword，Windows下的位置为：C:\Users\liuhuijun.jenkins\secrets\initialAdminPassword，找到该文件复制里面的内容，输入到初次页面里，然后Jenkins会提示选择插件进行安装，一般情况下我们选择默认的插件安装：Install suggested plugins就可以了。进入到Jenkins发现这是一个英文界面（也有可能是一个繁体中文界面），我们可以装一个中文插件来让它显示简体中文。选择Jenkins配置：选择管理插件Manage Plugins:选择可用插件Avaliable，并在右侧Filter框输入插件名：这里我们提前把需要的插件安装好:maven集成插件：Maven Integration plugin;Jenkins语言插件（可选）：Locale plugin;远程部署插件：Publish Over SSH;选择Install without restart，表示免重启安装，旁边为重启生效。这里我们直接免重启安装即可。然后点击左上角Jenkins返回到主页，再次进入Jenkins配置界面，选择系统设置Configure System，找到Local配置，输入如下：简体中文为ZH_cn，英文为EN_us，选择Ignore brower preference and force this language to all users表示忽略浏览器配置并且强制所有用户使用该语言。持续集成配置首先需要进行一系列环境的安装或配置，例如git/svn，maven，jdk，远程server等。进入系统配置，选择全局工具配置，本机环境如图，如果本机没有安装可以选择自动安装，推荐提前安装好，并记住安装目录：jdk：git:maven:本地部署在Jenkins主页选择新建任务，选择构建一个maven项目。需要说明的是，由于公司项目结构为父子模块项目，每次需要持续部署的都是某一个或者某几个模块。所有子项目都在tubitu_project一个代码仓库里，如果配置了webhook（作用是收到远程仓库push来的提交信息）的话，任务一个子项目的代码推送，都会导致所有服务的自动重启，而由于公司没有正规的代码提交审计流程，所以一次提交一旦出现导致项目崩溃的代码会导致所有服务一同崩溃，基于此种原因，本文的每一个服务都是一个单独的部署任务，任务开发同学提交了哪个项目的代码只需要对应更新修改的项目即可，最终结果如下：首先新建一个任务，选择构建一个maven项目，输入名称，确定，进入配置页面。在General里勾选丢弃旧的构建，可以选择保持构建的天数和保持构建的最大个数（如果不选择会造成空间越来越大），避免空间浪费。源码管理里选择git，选择远程仓库地址，并添加个人远程仓库的账户密码：构建触发器里勾选Build whenever a SNAPSHOT dependency is built；构建环境选择Add timestamps to the Console Output（非必选）；Build在Goals and options里输入clean install -pl tubitu_service_api -am，其中-pl 代表打包指定module，可以-pl module_name -pl module_name指定打包多个项目，-am 代表自动打包指定module所依赖的模块。Post Steps打包完成后勾选Run only if build succeeds，点击Add post-build step选择执行shell，脚本如下：12345678910111213#首先停止项目pid=`ps -ef | grep tubitu_service_api-1.0.0.jar | grep -v grep | awk '&#123;print $2&#125;'`if [ -n "$pid" ]then kill -9 $pidfi#删除旧的项目rm -rf /usr/local/meilong/api/tubitu_service_api-1.0.0.jar#复制Jenkins工作空间里的项目到指定目录下cp $WORKSPACE/tubitu_service_api/target/tubitu_service_api-1.0.0.jar /usr/local/meilong/api/#授权，该步骤可以省略chmod u+x /usr/local/meilong/api/tubitu_service_api-1.0.0.jarBUILD_ID=donKillme nohup java -jar -Dlogging.file=/usr/local/meilong/api/logs/tubitu.log /usr/local/meilong/api/tubitu_service_api-1.0.0.jar &amp;PS：BUILD_ID=dontKillme 指的是不要杀死最后一步启动项目产生的子进程。官网说明如下（https://wiki.jenkins.io/display/JENKINS/ProcessTreeKiller）：To reliably kill processes spawned by a job during a build, Jenkins contains a bit of native code to list up such processes and kill them. This is tested on several platforms and architectures, but if you find a show-stopper problem because of this, you can disable this feature by setting a Java property named “hudson.util.ProcessTree.disable” to the value “true”.为了可靠地终止构建过程中滋生出来的进程，Jenkins包含了一系列的本地代码去查出这些子进程并且杀死它们。这个已经在一些平台上进行了测试，如果你发现由此引发的停止显示的问题，你可以设置名为“hudson.util.ProcessTree.disable” 的java property为true来禁止使用ProcessTreeKiller自动杀死。通常情况下，我们保持官方默认配置，所以推荐使用BUILD_ID=dontKillme 表示该进程不是由Jenkins来生成，也就不会被ProcessTreeKiller杀死。配置完成以后，返回到Jenkins首页，在刚刚配置的任务点击最后一个按钮，或者点击任务名旁边的倒三角，选择立即构建，构建执行队列即会显示构建进度：#10代表第10次构建，鼠标移到10旁边，点击倒三角形，即可选择查看控制台输出构建和启动信息。当显示Finished:SUCCESS时，构建完成。返回到Jenkins 主页，可以看到S一列下为蓝色，代表上一次构建情况，蓝色为成功，灰色为尚未构建，红色为失败，黄色为构建是不稳定的（即Jenkins不确定状态），W一列下有天气图标，代表近期构建状态，晴天代表近期全部成功，晴转多云代表有少数失败，依次类推。远程部署远程部署首先需要配置远程服务器的Ip地址和用户凭证。返回主页，点击系统管理，然后点击系统设置，在Publish over SSH下找到SSH Servers，点击新增，分别配置好IP地址和用户名密码:这里Remote Directory为Jenkins默认远程根目录，点击高级，勾选使用用户密码，并输入密码，然后点击Test Configuration测试是否连接成功：新建一个任务tubitu_service_mall，前面基本保持一致，但是在Post Steps时，不再选择执行脚本，而是选择send files or execute commands over SSH。name选择上一步配置好的远程服务器，Source files默认会以本地当前任务的Jenkins工作空间+任务名为根路径，所以Source files只能配置相对路径，而Jenkins每一个任务默认的工作空间为/root/.jenkins/workspace/任务名，所以高i任务在本文中的工作空间全路径即为：/root/.jenkins/workspace/tubitu_service_mall，而由于构建依赖的pom文件又是父项目的pom文件，所以Source files为tubitu_service_mall/target/*.jar，*代表所有的jar包。Remove prefix代表传输到远程时需要移除的前缀：即移除到远程时会自动移除tubitu_service_mall/target/，只保留文件名。Remote directory代表传输到的目标路径。注意：这个目标路径也是相对路径，相对的是你在一开始配置SSH server时Remote Directory的目录，由于本文配置的是/，所以实际传输的远程目录为/usr/local/meilong/mall，如果一开始配置的是/usr/local/meilong，那么这里只需要配置Remote directory为mall。Exec command执行的脚本内容为：12345678910111213141516171819202122232425262728#restart.sh#!/bin/bashAPP_PATH=/usr/local/meilong/mallAPP_NAME=tubitu_service_mall-1.0.0.jarLOG_FILE=$APP_PATH/logs/tubitu.logecho "Restarting $APP_NAME SpringBoot Application"pid=`ps -ef | grep $APP_NAME | grep -v grep | awk '&#123;print $2&#125;'`source /etc/profileif [ -n "$pid" ]then kill -9 $pid echo "关闭进程："$pidfiecho "授予当前用户权限"chmod u+x $APP_PATH/$APP_NAMEecho "执行....."nohup java -jar -Dlogging.file=$LOG_FILE $APP_PATH/$APP_NAME &gt;&gt; /dev/null &amp;respid=`ps -ef | grep $APP_NAME | grep -v grep | awk '&#123;print $2&#125;'`if [ -n "$respid" ]then echo "启动成功，进程号：$respid" exit 0else echo "启动失败" exit 1fidone注意：第8行，之所以要执行第8行，是因为Jenkins在执行远程脚本时，它是不会携带本机环境变量的，所以执行java会报command not found的错导致构建失败，解决办法有两个：执行java命令时输入java的全路径，本文为/usr/local/jdk1.8.0_161/bin/java;执行该脚本时，脚本内调用source /etc/profile，当然前提是在profile里配置java的环境变量。如果没有遇到command not found的错，那么可以不加第8行。推荐在Transfers里的高级选项里勾选Flattern files，代表扁平化传输文件，即只传输文件而不建立远程目录，避免创建一堆杂乱目录，前提是远程目录自己已经手动创建。综合部署本地部署+远程部署，基本步骤与前面两种应用一致，不再赘述，只贴出配置。权限分配个人还是习惯基于角色的权限分配方式，需要安装插件：Role-based Authorization Strategy。进入到全局安全配置，启用该插件：然后进入到系统管理，此时出现了Manage And Assign Roles的选项，首先选择manage roles。比如我想新增一个前端的角色，这个前端角色只能看到前端的构建任务，输入h5，点击新增，然后勾选全部/overall里的Read选项，该选项必选，否则会提示该角色没有所有的读取权限。然后新增一个项目权限，也命名为h5，Pattern里写正则，h5_.*代表显示所有以h5_开头的构建项目，选择任务里的Build，Configure，Read，启用该角色对于任务的构建，配置和读权限，点击save。然后在Jenkins的用户管理里新建一个用户，命名为h5，我这里的全名为tubitu_h5：最后返回到Manage And Assign Roles主界面，选择Assign roles分配角色。User/group to add框里输入h5（不需要输入全名，Jenkins会根据userId来找，userId=h5），然后点击Add，并勾选刚刚新建的h5的角色。注销当前用户，使用h5用户登录，只能看到h5_的任务。如果不小心分配错了权限，可以到jenkins的主目录下，例如Linux上的/root/.jenkins/目录下有一个config.xml文件，修改authorizationStrategy为hudson.security.FullControlOnceLoggedInAuthorizationStrategy，即可禁用基于角色的权限策略：12345678&lt;useSecurity&gt;true&lt;/useSecurity&gt; &lt;authorizationStrategy class="hudson.security.FullControlOnceLoggedInAuthorizationStrategy"&gt; &lt;denyAnonymousReadAccess&gt;true&lt;/denyAnonymousReadAccess&gt; &lt;/authorizationStrategy&gt; &lt;securityRealm class="hudson.security.HudsonPrivateSecurityRealm"&gt; &lt;disableSignup&gt;true&lt;/disableSignup&gt; &lt;enableCaptcha&gt;false&lt;/enableCaptcha&gt; &lt;/securityRealm&gt;]]></content>
      <categories>
        <category>编程技术</category>
      </categories>
      <tags>
        <tag>CI/CD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring MVC异常增强处理]]></title>
    <url>%2FSpring-MVC%E5%BC%82%E5%B8%B8%E5%A2%9E%E5%BC%BA%E5%A4%84%E7%90%86.html</url>
    <content type="text"><![CDATA[简述记录一些关于平时借助Spring MVC框架开发时，对异常处理的一些想法和总结。这里引用耗子叔的总结，将异常分为三大类：资源的错误，例如没有打开文件权限，写文件出现错误，网络故障等。程序的错误，比如空指针，非法参数的异常，这一类最好记录下来写入日志，并触发监控系统报警。用户的错误，比如缺少参数，请求方式错误，这类错误通常由于用户错误操作导致的，对于这类错误我们需要做统计，有利于改善软件或者侦测是否有恶意请求，并反馈给用户修正。对于我们能够预知并且需要告诉用户修正的错误，我们最好使用返回 码的形式； 对于我们不期望发生的事，我们可以使用异常捕捉。 代码Java里常用try…catch…finally的形式来建立异常堆栈，但是这种做法的缺点是重复代码较多，每个需要处理的接口都需要加上如下这几行：123456789try &#123; ... &#125; catch (XmanException e) &#123; ... &#125; catch (Exception e) &#123; ... &#125; finally &#123; ... &#125;Spring MVC提供了控制器增强来方便进行统一异常处理，首先可以自定义一个业务中的异常：12345678910111213141516171819202122232425262728/** * @Description: 自定义用户异常 * @Author: 刘会俊 * @Date: 2019-02-14 10:55 */public class CustomException extends RuntimeException &#123; private static final long serialVersionUID = 4564124491192825748L; private int code; public CustomException(int code) &#123; super(); &#125; public CustomException(String message, int code) &#123; super(message); this.setCode(code); &#125; public int getCode() &#123; return code; &#125; public void setCode(int code) &#123; this.code = code; &#125;&#125;这样我们可以在业务层检测到用户参数不合法，或者某些受检异常的时候，可以直接抛出该exception，接下来定义一个接口层VO或者叫DTO，用于异常产生时，返回特定格式的数据：1234567891011121314151617181920212223242526272829303132/** * @Description: 异常信息模板 * @Author: 刘会俊 * @Date: 2019-02-14 10:59 */public class ErrorResponseEntity &#123; private int code; private String message; public int getCode() &#123; return code; &#125; public void setCode(int code) &#123; this.code = code; &#125; public String getMessage() &#123; return message; &#125; public void setMessage(String message) &#123; this.message = message; &#125; public ErrorResponseEntity(int code, String message) &#123; this.code = code; this.message = message; &#125;&#125;当产生错误时，统一返回该数据传输对象，最后定义Spring MVC的控制器增强。我们的业务逻辑和控制逻辑通常都是分开的，在控制逻辑里进行自定义异常的处理：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * @Description: 全局异常处理，@RestControllerAdvice是@ResponseBody和ControllerAdvice的组合注解 * @Author: 刘会俊 * @Date: 2019-02-14 11:02 */@RestControllerAdvicepublic class GlobalExceptionHandler extends ResponseEntityExceptionHandler &#123; private final static Logger LOGGER = LoggerFactory.getLogger(GlobalExceptionHandler.class); /** *@description: 处理自定义异常，获取自定义异常码和信息 *@author: 刘会俊 *@params: [request, e, response] *@return: com.example.aisino.exception.ErrorResponseEntity */ @ExceptionHandler(CustomException.class) public ErrorResponseEntity customExceptionHandler(HttpServletRequest request, Exception e, HttpServletResponse response)&#123; response.setStatus(HttpStatus.BAD_REQUEST.value()); CustomException customException = (CustomException) e; return new ErrorResponseEntity(customException.getCode(),customException.getMessage()); &#125; /** *@description: 处理运行时异常，统一定义为500-服务器错误 *@author: 刘会俊 *@params: [request, e, response] *@return: com.example.aisino.exception.ErrorResponseEntity */ @ExceptionHandler(RuntimeException.class) public ErrorResponseEntity runtimeExceptionHandler(HttpServletRequest request,Exception e,HttpServletResponse response)&#123; response.setStatus(500); RuntimeException runtimeException = (RuntimeException) e; return new ErrorResponseEntity(500, runtimeException.getMessage()); &#125; @Override protected ResponseEntity&lt;Object&gt; handleExceptionInternal(Exception ex, Object body, HttpHeaders headers, HttpStatus status, WebRequest request) &#123; if (ex instanceof MethodArgumentNotValidException)&#123; MethodArgumentNotValidException methodArgumentNotValidException = (MethodArgumentNotValidException) ex; return new ResponseEntity&lt;&gt;(new ErrorResponseEntity(status.value(), methodArgumentNotValidException.getBindingResult().getAllErrors().get(0).getDefaultMessage()), status); &#125; if(ex instanceof MethodArgumentTypeMismatchException)&#123; MethodArgumentTypeMismatchException methodArgumentTypeMismatchException = (MethodArgumentTypeMismatchException) ex; LOGGER.error("参数转换失败，方法&#123;&#125;,参数&#123;&#125;,信息&#123;&#125;", methodArgumentTypeMismatchException.getParameter().getMethod().getName(), methodArgumentTypeMismatchException.getName(), methodArgumentTypeMismatchException.getLocalizedMessage()); return new ResponseEntity&lt;&gt;(new ErrorResponseEntity(status.value(), "参数转换失败"), status); &#125; return new ResponseEntity&lt;&gt;(new ErrorResponseEntity(status.value(), "请求失败！"), status); &#125;&#125;其中，@ControllerAdvice支持的限定范围有：@ControllerAdvice(annotation=RestController.clcas)，按注解；@ControllerAdvice(&quot;org.example.controllers&quot;)，按包名；@ControllerAdvice(assignableTypes={ControllerInterface.class,AbstractController.class})，按类型。如果在Controller里某个方法直接使用@ExceptionHandler(RuntimeException.class)注解，则表示该异常处理只针对于该Controller。]]></content>
      <categories>
        <category>编程技术</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络基础]]></title>
    <url>%2F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80.html</url>
    <content type="text"><![CDATA[概述TCP/IP模型TCP/IP是一组不同层次上的多个协议的组合，通常被认为是一个四层协议系统，自下而上分别为：数据链路层，网络层，传输层，应用层。数据链路层：发送数据，主要是驱动程序以及网卡等网络接口，常用有ARP和RARP等协议；网络层：处理网络活动，分组选路等，主要有IP、ICMP、IGMP协议；传输层：为应用程序提供端到端的通信，主要有TCP、UDP协议；应用层：处理应用程序细节，主要有SMTP、SMNP、FTP、e-mail等。网关：现在网关这个术语只用来表述应用层网关，为某个特定的应用程序服务，用来链接两种不同协议族的进程。协议简述TCP：提供可靠的运输层服务。UDP：为应用程序接受和发送数据报；IP：同时被TCP和UDP使用。ICMP：IP协议的附属协议，IP层用它来与其他主机或者路由器交换错误报文和其他重要信息，常见应用Ping和Traceroute。IGMP：Internet组管理协议，用于把一个UDP数据包多播到多个主机。ARP和RARP：地址解析协议和逆地址解析协议，是某些网络接口使用的特殊协议，用来转换IP层和网络接口层使用的地址。IP地址长度：32bit=4byteA类：0+7位网络号+24位主机号（0.0.0.0~127.255.255.255）B类：10+14位网络号+16位主机号（128.0.0.0~191.255.255.255）C类：110+21位网络号+8位主机号（192.0.0.0~233.255.255.255）D类：1110+28位多播组号（224.0.0.0~239.2552.55.255）E类：11110+27（待用）（240.0.0.0~255.255.255.255）计算方式：二进制转换为位点分十进制；(为方便查看，使用括号隔开)四位一组，A组第一位固定为0，所以A组为：0.0.0.0~(27-1).(28-1).(28-1).(28-1)，B组由于前两位确定，转换为十进制时，前8位二进制中只有6位可以用来表示地址，因此B组十进制数第一位在A组基础上加26=64，即128.0.0.0~191.255.255.255，剩下的依此类推。封装当应用程序使用TCP传送数据时，数据被送入协议栈中，然后逐个通过每一层直到被当作一串bit流送入网络。从上到下依次是：用户数据–》appl首部+用户数据–》TCP首部+应用数据=TCP段或TCP报文段–》首部+TCP首部+应用数据=IP数据报–》以太网首部+IP首部+TCP首部+应用数据+以太网尾部=以太网帧。代表着数据每一层的状态，最后一层即是经过网络接口处理得到的数据，其中，以太网首部14字节，以太网尾部4字节，IP首部20字节，TCP首部20字节，IP首部+TCP首部+应用数据长度为46~1500字节之间（如无特殊说明，默认当前所有计算机系统为1byte=8bit）。TCP首部为20字节，UDP数据格式与TCP基本一致，只不过UDP首部长8字节。IP的首部会有一个1字节的协议域，表示数据来源于哪一层，1表示ICMP协议，2表示IGMP协议，6表示TCP协议，17表示UDP协议。同样的，TCP或者UDP首部会有一个2byte的端口号表示不同应用程序，包含了源端口号和目的端口号。而以太网的首部有一个2byte的帧类型域表明生成数据的网络层协议。分用以太网帧到达目的主机自下而上的解包。对于ICMP和IGMP，它们实际上是IP协议的附属协议，也就是网络层，然而ICMP和IGMP又和TCP于UDP一样被封装在IP数据报中，所以ICMP和IGMP在四层模型中无法具体定位。ARP和RARP也与之类似，虽然实际上是数据链路但是它们又和IP数据报一样有自己的以太网数据帧类型。标准化小组控制TCP/IP协议族，定义新的标准。Internet协会（ISOC，Internet Society）Internet体系结构委员会（IAB，Internet Architecture Board） 技术监督和协调组织，隶属于ISOCInternet工程专门小组（IETF，Internet Engineering Task Force）面向近期标准的组织，隶属于IABInternet研究专门小组（IRIF，internet Research Task Force）研究长远项目的组织，隶属于IAB文档所有关于Internet的正式标准都以RFC文档出版，大量的RFC并不是正式标准，出版的目的只是为了提供信息。数据链路层简述目的：为IP模块发送和接收IP数据报；为ARP模块和RARP模块发送请求和应答；SLIP：Serial Line IP，一种在串行线路上对IP数据报进行封装的简单形式；缺陷：每一端都必须知道对方的IP地址，没有办法把本段的IP地址通知给另一端；数据帧中没有类型字段，因此无法区分上层协议；没有在数据帧中加上校验和，因此无法发现错误，只能通过上层协议实现；CSLIP：压缩的SLIP；PPP：点对点协议，修复了SLIP的缺陷，最终将取代SLIP。环回接口允许在同一台主机上的程序和服务器程序通过TCP/IP进行通信，IP地址通常为127.0.0.1，命名为localhost。传给环回地址（一般是127.0.0.1）的任何数据均作为I P输入。传给广播地址或多播地址的数据报复制一份传给环回接口，然后送到以太网上。这是 因为广播传送和多播传送的定义包含主机本身。任何传给该主机IP地址的数据均送到环回接口。最大传输单元MTU（单位：字节）超通道单元：6553516Mb/s令牌环（IBM）：179144Mb/s令牌环（IEEE 802.5）：4464EDDI：4352以太网：1500IEEE 802.3/802.2：1492X.25：576点对点（低时延）：296如果传输的数据报超过了MTU，那么IP层就会进行分片。IP：网际协议简述不可靠：仅提供尽力而为的传输服务，可靠性需要由上层协议来实现；无连接：不维护每一个数据报的状态信息，每个数据报的处理相对独立。IP首部通常长度20字节（含有选项字段除外），组成为：4bit版本+4bit首部长度信息+8bit服务类型（TOS）+16bit总字节数长度信息+16bit标识+3bit标志+13bit片偏移+8bit生存时间（TTL）+8bit协议+16bit首部检验和+32bit源IP地址+32bit目的IP地址+选项（如果有）+数据传输方式：big ending，即先传低位再传高位，又称为网络字节序。版本：目前协议版本号为4，因此又称为IPV4。首部长度信息：首部占32bit字的数目，包括任务选项，由于它是一个4bit字段，因此首部最长为60字节。标识字段：唯一地表示主机发送的每一份数据报，通常每发送一份报文它的值就会+1。TTL：设置了数据报可以经过的最多路由器数，每经过一个处理它的路由器就会-1，当等于0时，就会丢弃该数据报，并发送ICMP报文通知源主机。IP路由选择如果目的主机和源主机直接相连或者都在一个共享网络上，那么IP数据包就直接发送到目的主机上，否则主机会把数据报发往一默认路由器上，由路由器来转发该数据报。IP层在内存中有一个路由表。当受到一份数据报并进行发送时，它都要对该表搜索一次。路由表的每一项都包含目的IP地址，下一站或者下一跳的IP地址，标志，数据报传输指定接口。IP路由选择是逐跳的（hop-by-hop），首先搜索主机路由，其次搜索网络路由，最后搜索默认路由。子网掩码一个32bit的地址，值为1的表示网络号和子网号，值为0的表示主机号。例如高位到低位依次为24个1和8个0，即代表子网掩码的点分十进制为255.255.255.0；从高到低位如果是26个1，6个0，则代表子网掩码的点分十进制数为255.255.255.192，通过子网掩码和IP地址，主机就可以确定IP数据报的目的地是：（1）本子网上主机；（2）本网络中其他子网主机；（3）其他网络主机。IP的未来32位IP地址基本已经耗尽；路由结构没有层次，属于平面型结构，每个网络都需要一个路由表，录入一个由多个网络的网站就必须分配多个C类地址，而不是一个B类地址。ARP：地址解析协议简述ARP地址解析协议是为32bit的IP地址动态映射到48bit的以太网地址（硬件地址）的约定。ARP发送（广播）一份称作ARP请求的以太网数据帧给以太网中的每个主机，包含目的主机和IP地址，意为：如果你是这个IP地址的拥有者，请回答你的硬件地址。目的主机ARP层收到广播报文后，识别出这是发送端在寻找它的IP地址和硬件地址，于是发送ARP响应给发送端。发送端收到ARP应答后，使ARP进行请求-应答的IP数据报就可以传送了。ARP高速缓存ARP高效运行的关键是在于每个主机上都有一个ARP高速缓存，保存着最近Internet地址到硬件地址之间的映射记录，高速缓存中每一项的生存时间一般是20分钟，起始时间为创建时间。ARP分组格式6字节以太网目的地址+6字节以太网源地址+2子节帧类型+2字节硬件类型+2字节协议类型+1字节硬件地址长度+1字节协议地址长度+2字节op（操作类型）+6字节发送端以太网地址+4字节发送端IP地址+6字节目的以太网地址+4字节目的IP地址解释：目的地址全为1的为广播地址；ARP的以太网帧类型为0x0806；硬件类型=1表示以太网地址（对于ARP来说是硬件地址）；协议类型=0x0800表示IP地址；ARP请求或应答的的硬件地址长度=6（字节），协议地址长度=4（字节）；op表示操作，ARP请求=1，ARP应答=2，RARP请求=3，RARP应答=4；以太网数据帧中的以太网源地址（硬件地址）=ARP数据帧中的发送端以太网地址（硬件地址）。说明：对于一个ARP请求来说，除目的端硬件地址外的所有其他的字段都有填充值，当系统收到一份目的端为本机的ARP请求报文后，它就把硬件地址填进去，然后用两个目的端地址分别替换两个发送端地址，并把操作字段设置为2，再发送回去。RARP：逆地址解析协议简述RARP协议是许多无盘系统在引导时用来获取IP地址的。RARP请求是以广播的形式，应答是以单播的形式。RARP请求在分组中表明发送端的硬件地址，以请求相应IP地址的响应。具有本地磁盘的系统引导时，一般是从磁盘中的配置文件读取IP地址。但是无盘机，如无盘工作站，则需要采用其他方法获取ip地址。网络上的每个系统都具有唯一的硬件地址，他是由网络接口生产厂家配置的。无盘系统的RARP实现过程是从接口卡上读取唯一的硬件地址，然后发送一份RARP请求（一帧在网络上的数据），请求某个主机在无盘系统的IP地址。RARP服务器的复杂性在于。服务器一般要为多个主机提供硬件地址到IP地址的映射。更为复杂的是，RARP请求作为一个特殊类型的以太网数据帧来传送。这说明RARP服务器必须能够发送和接收这种类型的以太网数据帧。RARP是许多无盘系统在引导时用来获取IP地址的。RARP实现起来要比ARP复杂，因为RARP请求实在硬件层上广播的。这意味着他们不经过路由器进行转发。为了能让无盘系统在RARP关机的情况下也能引导，通常要在一个网络上（一根电缆）提供多个RARP服务器。RARP分组格式与ARP分组基本一致，主要差别是ARAP请求或应答的帧类型代码为0x8035，而且RARP的操作代码为3，应答操作代码为4。ICMP：Internet控制报文协议简述ICMP经常被认为是IP层的一个组成部分。它传递差错报文以及其他需要注意的信息，ICMP报文通常被IP或者更高层协议如TCP/UDP使用。一些ICMP报文把差错报文返回给用户进程。ICMP是在IP数据报内部传输的（ICMP报文+20字节IP首部）。ICMP报文通常为8位类型+8位代码+16位检验和=32位，其中类型字段可以与15个不同的值，以描述特定类型的ICMP报文。ICMP报文的类型类型代码描述查询差错00回显应答13目的不可达130网络不可达131主机不可达132协议不可达133端口不可达134需要进行分片但设置了不分片比特135源站选路失败136目的网络不认识137目的主机不认识138源主机被隔离139目的网络被强制禁止1310目的主机被强制禁止1311由于服务类型TOS，网络不可达1312由于服务类型TOS，主机不可达1313由于过滤，通信被强制禁止1314主机越权1315优先权中止生效140源端被关闭15重定向150网络重定向151主机重定向152服务类型和网络重定向153服务类型和主机重定向180请求回显190路由器宣告1100路由器请求111超时110传输期间TTL为01111在数据报组装期间生存时间为0112参数问题120坏的IP首部，包括各种差错1121减少必须的选项1130时间戳请求1140时间戳应答1150信息请求（废弃）1160信息应答（废弃）1170地址掩码请求1180地址掩码应答15种场景不会导致产生ICMP差错报文：ICMP差错报文；目的地址位广播地址或多播地址的IP数据报；作为链路层广播的数据报不是IP分片的第一片；源地址不是单个主机的数据报。ICMP的一个规则是：ICMP差错报文必须包括生成该差错报文的数据报IP首部，还必须至少跟在该IP首部后面的前8个字节。Ping程序ping程序发送一份ICMP回显请求报文给主机，并等待返回ICMP回显应答。Ping还能测出我们到某一台主机的距离，通过当前时间减去在ICMP报文中的时间即是往返时间。Traceroute程序traceroute程序使用ICMP报文和首部中的TTL字段。发送端初始设置一个8bit字段，推荐的初始值由赋值RFC指定，当前值为64，较老系统经常设置为15或者32。每个处理数据报的路由器都需要把TTL减1或者减去数据报在路由器中停留的秒数。当路由器收到一份IP数据报，如果TTL字段是0或者1，则路由器不转发该数据报（接收到这种数据报的目的主机可以将它交给应用程序，这是因为不需要转发该数据报，但是在通常情况下，系统不应该接收TTL字段为0的数据报）。相反，路由器将该数据报丢弃，并给源主机发送一份“超时”信息。Traceroute程序的关键在于包含这份ICMP信息的IP报文的信源地址是该路由器的IP地址。我们现在可以猜想一下Traceroute程序的操作过程。它发送一份TTL字段为1的IP数据报给目的主机。处理这份数据报的第一个路由器将TTL值减1，丢弃该数据报，并发回一份超时ICMP报文。这样就得到了该路径中的第一个路由器的地址。然后Traceroute程序发送一份TTL值为2的数据报，这样我们就可以得到第二个路由器的地址。然后继续这个过程直至该数据报到达目的主机。但是目的主机哪怕接收到TTL值为1的IP数据报，也不会丢弃该数据报并产生一份超时ICMP报文，这是因为数据报已经到达其最终目的地。Traceroute程序发送一份UDP数据报给目的主机，但它会选择一个不可能的值作为UDP端口号（大于30000），使目的主机的UDP模块产生一份：”端口不可达错误“的ICMP报文，这样，Traceroute程序所要做的就是区分接收到的ICMP报文是超时还是端口不可达，以判断什么时候结束。IP选路 与 动态选路协议IP搜索路由表的步骤：搜索主机路由搜索网络路由搜索默认路由当相邻路由器之间进行通信，以告知对方每个路由器当前所连接的网络，这时候就出现了动态选路，路由器之间必须采用选路协议进行通信。路由器上有一个进程称为路由守护程序，它运行选路协议，并与相邻的一些路由器进行通信，然后它会动态更新路由表。RIP：选路信息协议RIP报文包含于UDP报文中，即8字节UDP首部+RIP报文。常用UDP端口号是520。OSPF：开放最短路径优先直接包含于IP数据报中，采用多播的形式，逐渐取代RIP中。BGP：边界网关协议不同自治系统的路由器之间进行通信的外部网关协议。CIDR：无类型区域间选路采用一种分配多个IP的方式，使其能够将路由表中的许多表项总和成更少的数目。UDP：用户数据报协议简述简单的面向数据报的传输层协议，进程的每个输出操作都正好产生一个UDP数据报，并组装成一份待发送的IP数据报，全体数据与每一份数据不一定存在关联，传输但不保证可达。TCP协议是面向字符流的传输层协议。应用程序必须关心IP数据报的长度，如果超过网络的MTU，则必须进行分片。组成：8字节UDP首部+UDP数据规范：RFC768UDP首部16位源端口号+16位目的端口号+16位UDP长度+16位UDP校验和IP分片把一份IP数据报分片以后，只有到达目的地进行重新组装（这里的重新组装与其他网络协议不同，它们要求在下一站就进行重新组装，而不是在最终目的地）。重新组装有目的地的IP端完成，使得分片和重新组装对传输层是透明的，以防止某些可能的性能降低。已经分片的信息可能会再次分片。IP首部中包含的数据位分片和重新组装提供了足够的信息。UDP和ARP之间的交互式应用这是不常被人注意到的一个细节，这是针对一些系统地实现来说的。当ARP缓存还是空的时候。UDP在被发送之前一定要发送一个ARP请求来获得目的主机的MAC地址，如果这个UDP的数据包足够大，大到IP层一定要对其进行分片的时候，想象中，该UDP数据包的第一个分片会发出一个ARP查询请求，所有的分片都辉等到这个查询完成以后再发送。事实上是这样吗？结果是，某些系统会让每一个分片都发送一个ARP查询，所有的分片都在等待，但是接受到第一个回应的时候，主机却只发送了最后一个数据片而抛弃了其他，这实在是让人匪夷所思。这样，因为分片的数据不能被及时组装，接受主机将会在一段时间内将永远无法组装的IP数据包抛弃，并且发送组装超时的ICMP报文（其实很多系统不产生这个差错），以保证接受主机自己的接收端缓存不被那些永远得不到组装的分片充满。广播、多播和单播简述仅用于UDP，广播：向网上所有的主机发送数据帧；多播：帧仅传送给说某个多播组的多个主机。广播(broadcast)受限的广播地址是255.255.255.255，该地址用户主机配置过程中IP数据报目的地址。A类网络广播地址为netid.255.255.0。指向子网的广播地址全为1且有特定子网号的地址。广播是主机针对某一个网络上的所有主机发送数据包。这个网络可能是网络，可能是子网，还可能是所有的子网。如果是网络，例如A类网址的广播就是 netid.255.255.255，如果是子网，则是netid.netid.subnetid.255；如果是所有的子网（B类IP）则是则是 netid.netid.255.255。广播所用的MAC地址FF-FF-FF-FF-FF-FF。网络内所有的主机都会收到这个广播数据，网卡只要把 MAC地址为FF-FF-FF-FF-FF-FF的数据交给内核就可以了。一般说来ARP，或者路由协议RIP应该是以广播的形式播发的。多播(multicast)可以说广播是多播的特例，多播就是给一组特定的主机（多播组）发送数据，这样，数据的播发范围会小一些(实际上播发的范围一点也没有变小)，多播的MAC地址是最高字节的低位为一，例 如01-00-00-00-00-00。多播组的地址是D类IP，规定是224.0.0.0-239.255.255.255。然多播比较特殊，但是究其原理，多播的数据还是要通过数据链路层进行MAC地址绑定然后进行发送。所以一个以太网卡在绑定了一个多播IP地址之后，必 定还要绑定一个多播的MAC地址，才能使得其可以像单播那样工作。这个多播的IP和多播MAC地址有一个对应的算法，这个对应不是一一对应的，主机还是要对多播数据进行过滤。两类服务：向多个目的地址传送数据，有许多向多个接收者传递信息的应用：例如交互式会议系统和向多个接收者分发邮件和新闻；客户对服务器的请求。单播(unicast)单播是说，对特定的主机进行数据传送。例如给某一个主机发送IP数据包。这时候，数据链路层给出的数据头里面是非常具体的目的地址，对于以太网来 说，就是网卡的MAC地址（不是FF-FF-FF-FF-FF-FF这样的地址）。现在的具有路由功能的主机应该可以将单播数据定向转发，而目的主机的网 络接口则可以过滤掉和自己MAC地址不一致的数据。IGMP：Internet组管理协议简述用于支持主机和路由器进行多播的Internet组管理协议（IGMP）。它让一个物理网络上的所有系统知道主机当前所在的多播组。规范：RFC11212IGMP报文4位版本号+4位IGMP类型+8位未使用+16位检验和+32位组地址（D类IP地址）DNS：域名系统简述用于TCP/IP应用程序的分布式数据库，它提供主机名和IP地址之间的转换和有关电子邮件的选路信息。当一个数据库发现自己并没有某查询所需要的数据的时候，它将把查询转发出去，而转发的目的地通常是根服务器，根服 务器从上至下层层转发查询，直到找到目标为止。DNS还有一个特点就是使用高速缓存，DNS把查询过的数据缓存在某处，以便于下次查询时使用。规范：RFC1035国家域（顶级域）：ae（阿拉伯联合酋长国），us（美国），zw（津巴布韦）普通顶级域：arpa，com，edu，gov，int，mil，net，orgcom：商业组织edu：教育机构gov：其他美国政府部门int：国际组织mil：美国军事网店net：网络org：其他组织DNS协议DNS报文定义了一个既可以查询也可以响应的报文格式。对各个字段简单解释如下：最前面的16个bit唯一的标示了问题号码，用于查询端区别自己的查询。紧接着的16个bit又可以做进一步的细分，标示了报文的性质和一些细节，比如说是查询报文还是响应报文，需要递归查询与否（一般服务器都支持递归查询，而且不需要任何设置，BIND就是这样）查询问题后面有查询类型，包括A，NS，CNAME，PTR，HINFO，MX，如果熟悉BIND的话，就知道在zong的配置文件里面，每一条记录都记载了各自的类型，比如A就是IP地址，NS就是名字服务器。响应报文可以回复多个IP，也就是说，域名可以和多个IP地址对应，并且有很多CNAME。DNS服务器支持TCP和UDP两种协议的查询方式，而且端口都是53。而大多数的查询都是UDP查询的，一般需要TCP查询的有两种情况：当查询数据多大以至于产生了数据截断(TC标志为1)，这时，需要利用TCP的分片能力来进行数据传输（看TCP的相关章节）。当主（master）服务器和辅（slave）服务器之间通信，辅服务器要拿到主服务器的zone信息的时候。TFTP：简单文件传送协议简述TFTP（Trivial File Transfer Protocol）简单文件传送协议，最初打算用于引导无盘系统（通常是工作站或X终端），使用UDP。TCP：传输控制协议简述提供一种面向连接的、可靠的字节流服务。 服务如何实现可靠性： 数据会被分割为最合适发送的数据块，这和UDP完全不同，应用程序产生的 数据报长度将保持不变。由TCP传递给IP的信息单位称为报文段或段（ segment）。TCP发出一个报文段后，会启动一个定时器（超时重发和重传）。收到另一端的数据后，它将发送一个确认。TCP将保持它首部和数据的检验和。重排序。丢弃重复数据。控制发送端只能发送接收端缓冲区所能接纳的数据（流量控制）。首部20字节。16位源端口号+16位目的端口号+32位序号+32位确认序号+4位首部长度+保留6位+16位窗口大小+16位检验和+16位紧急指针 序号：标识从发送端到接收端的数据字节流，表示在这个报文段中的第一个数据字节。序号是32位的无符号数，到达最高后又从0开始。当建立一个新连接时，SYN标志变1，序号字段包含有这个主机选择的该裂解的处事序号ISN，该主机要发送数据的第一个字节序号位ISN加1，因为SYN标志消耗了一个序号TCP首部中有6个标志比特：URG：紧急指针有效。ACK：确认序号有效。PSH：接收方应该尽快将这个报文段交给应用层。RST：重建连接。SYN：同步序号用来发起一个连接。FIN：发送段完成任务连接建立与终止三次握手：客服端发送一个SYN段指明客户打算连接服务器端口，以及ISN。这个SYN段位报文段1。服务器发回包含服务器的初始序号的SYN报文段作为应答。同时将确认序号设置位客户的ISN加1以对客户的SYN报文段进行确认，一个SYN将占用一个序号。客户必须确认序号设置为服务器的ISN加1以对服务器的SYN报文段进行确认。在建立连接的时候，通信的双方要互相确认对方的最大报文长度(MSS)，以便通信。一般这个SYN长度是MTU减去固定IP首部和TCP首部长度。对于一个以太网，一般可以达到1460字节。当然如果对于非本地的IP，这个MSS可能就只有536字节，而且，如果中间的传输网络的MSS更佳的小的话，这个值还会变得更小。由于TCP的半关闭，因此关闭连接时，客户端和服务端分别关闭。四次挥手：客户端发起带FIN状态的请求。服务器收到FIN会发回一个ACK，值等于收到的序号加1。服务端主动请求一次FIN。客户端收到FIN会发回一个ACK，值等于收到的序号加1。客户端状态迁移：CLOSED-&gt;SYN_SENT-&gt;ESTABLISHED-&gt;FIN_WAIT_1-&gt;FIN_WAIT_2-&gt;TIME_WAIT-&gt;CLOSED服务端状态迁移：CLOSED-&gt;LISTEN-&gt;SYN收到-&gt;ESTABLISHED-&gt;CLOSE_WAIT-&gt;LAST_ACK-&gt;CLOSED解释：LISTEN-&gt;SYN_SENT，对于这个解释就很简单了，服务器有时候也要打开连接的嘛。SYN_SENT-&gt;SYN收到，服务器和客户端在SYN_SENT状态下如果收到SYN数据报，则都需要发送SYN的ACK数据报并把自己的状态调整到SYN收到状态，准备进入ESTABLISHEDSYN_SENT-&gt;CLOSED，在发送超时的情况下，会返回到CLOSED状态。SYN_收到-&gt;LISTEN，如果受到RST包，会返回到LISTEN状态。SYN_收到-&gt;FIN_WAIT_1，这个迁移是说，可以不用到ESTABLISHED状态，而可以直接跳转到FIN_WAIT_1状态并等待关闭。超时与重传对于每个连接，TCP管理4个不同的定时器。重传定时器适用于当希望收到另一端的确认。坚持定时器使窗口大小信息保持不断流动。报活定时器可检测到一个空闲连接的另一端何时崩溃或重启。2MSL定时器测量一个连接处于TIME_WAIT状态的时间。数据流交互式数据类型小流量数据交换，例如一次交互按键，显示等，telnet、ssh是其中代表。对于交互性要求比较高的应用，TCP给出两个策略来提高发送效率和减低网络负担：（1）捎带ACK。(2)Nagle算法（一次尽量多的发数据）。通常，在网络速度很快的情况下，比如用lo接口进行telnet通信，当按下字母键并要求回显的时候，客户端和服务器将经历 发送按键数据-&gt;服务器发送按键数据的ack -&gt; 服务器端发送回显数据-&gt;客户端发送回显数据的ACK的过程，而其中的数据流量将是40bit + 41bit+41bit+40bit = 162bit，如果在广域网里面，这种小分组的TCP流量将会造成很大的网络负担。捎带ACK的发送方式这个策略是说，当主机收到远程主机的TCP数据报之后，通常不马上发送ACK数据报，而是等上一个短暂的时间，如果这段时间里面主机还有发送到远程主机的TCP数据报，那么就把这个ACK数据报“捎带”着发送出去，把本来两个TCP数据报整合成一个发送。一般的，这个时间是200ms。可以明显地看到这个策略可以把TCP数据报的利用率提高很多。Nagle算法上过bbs的人应该都会有感受，就是在网络慢的时候发贴，有时键入一串字符串以后，经过一段时间，客户端“发疯”一样突然回显出很多内容，就好像数据一下子传过来了一样，这就是Nagle算法的作用。Nagle算法要求一个TCP连接上最多只有一个未被确认的未完成的小分组，在该分组的确认到达（接收方ACK）之前不能发送其他的小分组。当收到ACK时，它会以一个分组的方式发出去。在编写插口程序的时候，可以通过TCP_NODELAY来关闭这个算法。并且，使用这个算法看情况的，比如基于TCP的X窗口协议，如果处理鼠标事件时还是用这个算法，那么“延迟”可就非常大了。数据成块类型要求发送方尽可能块地运载数据，常用又停止等待协议和滑动窗口协议，ftp和tftp是其中代表。对于FTP这样对于数据吞吐量有较高要求的要求，将总是希望每次尽量多的发送数据到对方主机，就算是有点“延迟”也无所谓。TCP也提供了一整套的策略来支持这样的需求。TCP协议中有16个bit表示“窗口”的大小，这是这些策略的核心。 传输数据时ACK的问题在解释滑动窗口前，需要看看ACK的应答策略，一般来说，发送端发送一个TCP数据报，那么接收端就应该发送一个ACK数据报。但是事实上却不是这样，发送端将会连续发送数据尽量填满接受方的缓冲区，而接受方对这些数据只要发送一个ACK报文来回应就可以了，这就是ACK的累积特性，这个特性大大减少了发送端和接收端的负担。 滑动窗口滑动窗口本质上是描述接受方的TCP数据报缓冲区大小的数据，发送方根据这个数据来计算自己最多能发送多长的数据。如果发送方收到接受方的窗口大小为0的TCP数据报，那么发送方将停止发送数据，等到接受方发送窗口大小不为0的数据报的到来。 关于滑动窗口协议，介绍三个术语，分别是：窗口合拢：当窗口从左边向右边靠近的时候，这种现象发生在数据被发送和确认的时候。窗口张开：当窗口的右边沿向右边移动的时候，这种现象发生在接受端处理了数据以后。窗口收缩：当窗口的右边沿向左边移动的时候，这种现象不常发生。TCP就是用这个窗口，慢慢的从数据的左边移动到右边，把处于窗口范围内的数据发送出去（但不用发送所有，只是处于窗口内的数据可以发送。）。这就是窗口的意义。窗口的大小是可以通过socket来制定的，4096并不是最理想的窗口大小，而16384则可以使吞吐量大大的增加。数据拥塞上面的策略用于局域网内传输还可以，但是用在广域网中就可能会出现问题，最大的问题就是当传输时出现了瓶颈（比如说一定要经过一个slip低速链路）所产生的大量数据堵塞问题（拥塞），为了解决这个问题，TCP发送方需要确认连接双方的线路的数据最大吞吐量是多少。这，就是所谓的拥塞窗口。 拥塞窗口的原理很简单，TCP发送方首先发送一个数据报，然后等待对方的回应，得到回应后就把这个窗口的大小加倍，然后连续发送两个数据报，等到对方回应以后，再把这个窗口加倍（先是2的指数倍，到一定程度后就变成线性增长，这就是所谓的慢启动），发送更多的数据报，直到出现超时错误，这样，发送端就了解到了通信双方的线路承载能力，也就确定了拥塞窗口的大小，发送方就用这个拥塞窗口的大小发送数据。要观察这个现象是非常容易的，我们一般在下载数据的时候，速度都是慢慢“冲起来的”。 HTTPS：加密的通信简述传统的http通信，是明文的，因此安全性比较低。而建立在SSL/TLS协议上的HTTPS协议就是为了通信安全而生的。目前，应用最广泛的是TLS 1.0，接下来是SSL 3.0。但是，主流浏览器都已经实现了TLS 1.2的支持。TLS 1.0通常被标示为SSL 3.1，TLS 1.1为SSL 3.2，TLS 1.2为SSL 3.3。原理SSL/TLS基本原理：公钥加密，服务器存放着一个由可信机构颁发的数字证书，证书里包含公钥，同时服务器还持有一个私钥。但是，每次通信如果都是客户端索要公钥加密，服务端用私钥解密，效率太低。有没有什么好办法提高效率？有！客户端和服务端每次会话，生成session key，即会话密钥，公钥只用于加密会话密钥，只要保证在生成会话密钥的阶段使用公钥加密，那么就可以保证会话密钥的安全，在通信时就可以使用会话密钥进行对称解密，对称解密效率远大于非对称解密。如图：1.ClientHello协议版本，例如TLS 1.0客户端随机数，用于生成会话密钥支持的加密方法，例如RSA支持的压缩方法2.ServerHello确认使用的加密通信协议版本，比如TLS 1.0版本。如果浏览器与服务器支持的版本不一致，服务器关闭加密通信一个服务器生成的随机数，稍后用于生成”会话密钥”确认使用的加密方法，比如RSA公钥加密服务器证书除了上面这些信息，如果服务器需要确认客户端的身份，就会再包含一项请求，要求客户端提供”客户端证书”。比如，金融机构往往只允许认证客户连入自己的网络，就会向正式客户提供USB密钥，里面就包含了一张客户端证书。3.ClientResponse一个随机数。该随机数用服务器公钥加密，防止被窃听。编码改变通知，表示随后的信息都将用双方商定的加密方法和密钥发送。客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时也是前面发送的所有内容的hash值，用来供服务器校验。上面第一项的随机数，是整个握手阶段出现的第三个随机数，又称”pre-master key”。有了它以后，客户端和服务器就同时有了三个随机数，接着双方就用事先商定的加密方法，各自生成本次会话所用的同一把”会话密钥”。 如果上一步里，服务器要求客户端证书，也会在这一步发。4.ServerResponse编码改变通知，表示随后的信息都将用双方商定的加密方法和密钥发送。服务端握手结束通知，表示客户端的握手阶段已经结束。这一项同时也是前面发送的所有内容的hash值，用来供服务器校验。对于三次随机数，引用一位大神的解释：由于ssl协议中dh份额来源于证书，而证书又是静态的，因此十分有必要引入一种随机因素来保证通过静态证书导出的密钥份额协商出来的密钥的随机性。同时这也是pre_master的意义，那就是随机，对于rsa密钥交换算法来说，pre-master-key本身就是一个随机数，再加上hello消息中的随机，三个随机数通过一个密钥导出器最终导出一个对称密钥，但是对于dh，包括ecdh算法(不考虑匿名dh和瞬时dh)，就只有hello消息中的两个随机数因子了。 pre master的存在在于ssl协议不信任每个主机都能产生完全随机的随机数，如果随机数不随机，那么pre master secret就有可能被猜出来，那么仅适用pre master secret作为密钥就不合适了，因此必须引入新的随机因素，那么客户端和服务器加上pre master secret三个随机数一同生成的密钥就不容易被猜出了，一个伪随机可能完全不随机，可是是三个伪随机就十分接近随机了，每增加一个自由度，随机性增加的可不是一。作者：dog250来源：CSDN原文：https://blog.csdn.net/dog250/article/details/5717162最后，依然使用HTTP协议传输数据，只不过会用会话密钥加密内容。但是，在实际很多的互联网分层项目中，往往会有一个反向代理或者负载均衡的服务器，例如nginx，前端请求nginx时使用https请求，但是代理服务器转发请求时依然是使用的http，所以这样依然会有资源劫持的风险。OAuth2.0：用于授权的开放网络标准简述用户授权自己的资源给第三方应用来进行读取的一种授权协议规范：RFC6749举例：开发一个网站，现在需要使用微信登陆该网站，那么该网站肯定要读取你的微信信息（user_info），user_info就是你的个人资源。在oauth之前，传统做法是要你输入微信用户名和密码，然后网站的后台服务就可以拿着你的用户名密码去向微信请求信息。弊端：用户名密码暴露，不安全；用户不想授权该网站时必须改密码，繁琐；该网站能使用用户所有的权利，越权；该网站一旦被破解，用户信息泄漏，危险。办法：在第三方程序和微信之间设置一个授权层，第三方程序只能登录这个授权层，用户能够在授权层指定第三方程序能读取哪一些信息，第三方根据这个授权层提供的令牌提供范围内资源 。术语：Third-party application：第三方应用，即例子中的网站，实际上可以有很多，例如第三方小程序等；Http Server：服务提供商，例子中的微信；Resource owner：个人资源拥有者；User Agent：用户借助来进行授权的代理，例如小程序会调用微信浏览器，第三方网站会调用你用来上网的浏览器；Authorization server：认证服务器，即授权层；Resource Server：资源服务器，可以和认证服务器是同一台。摘自RFC6749： （A）用户打开客户端以后，客户端要求用户给予授权。（B）用户同意给予客户端授权。（C）客户端使用上一步获得的授权，向认证服务器申请令牌。（D）认证服务器对客户端进行认证以后，确认无误，同意发放令牌。（E）客户端使用令牌，向资源服务器申请获取资源。（F）资源服务器确认令牌无误，同意向客户端开放资源。用户必须授权给客户端，客户端才能通过授权拿到令牌。OAuth2.0定义了四种授权方式：授权码模式（authorization code）简化模式（implicit）密码模式（resource owner password credentials）客户端模式（client credentials）授权码模式（A）用户访问客户端，后者将前者导向认证服务器。（B）用户选择是否给予客户端授权。（C）假设用户给予授权，认证服务器将用户导向客户端事先指定的”重定向URI”（redirection URI），同时附上一个授权码。（D）客户端收到授权码，附上早先的”重定向URI”，向认证服务器申请令牌。这一步是在客户端的后台的服务器上完成的，对用户不可见。（E）认证服务器核对了授权码和重定向URI，确认无误后，向客户端发送访问令牌（access token）和更新令牌（refresh token）。A步骤中，客户端申请认证的URI，包含以下参数：response_type：表示授权类型，必选项，此处的值固定为”code”client_id：表示客户端的ID，必选项redirect_uri：表示重定向URI，可选项scope：表示申请的权限范围，可选项state：表示客户端的当前状态，可以指定任意值，认证服务器会原封不动地返回这个值。关于state：原文如下：RECOMMENDED. An opaque value used by the client to maintain state between the request and callback. The authorization server includes this value when redirecting the user-agent back to the client. The parameter SHOULD be used for preventing cross-site request forgery as described in Section 10.12.即该值是一个动态的用来维持请求和回调的状态的，这个值能够避免CSRF漏洞的发生，所以该state应该做成一个动态的，每次不同的请求都是一个不同的state用以辨别传输过程中是否发生了篡改。例子：微信支付公众号支付的某一个接口：&quot;https://open.weixin.qq.com/connect/oauth2/authorize?appid=123&amp;redirect_uri=https://www.baidu.com&amp;response_type=code&amp;scope=snsapi_base&amp;state=123#wechat_redirect&quot; ​appid即指代client_id。E步骤中，认证服务器发送的HTTP回复，包含以下参数：access_token：表示访问令牌，必选项。token_type：表示令牌类型，该值大小写不敏感，必选项，可以是bearer类型或mac类型。expires_in：表示过期时间，单位为秒。如果省略该参数，必须其他方式设置过期时间。refresh_token：表示更新令牌，用来获取下一次的访问令牌，可选项。scope：表示权限范围，如果与客户端申请的范围一致，此项可省略。结合实际工作经验：其中：user agent指代浏览器，Application Server知道网站后台服务器，Http Server是代表资源和认证服务器。简化模式简化模式（implicit grant type）不通过第三方应用程序的服务器，直接在浏览器中向认证服务器申请令牌，跳过了”授权码”这个步骤，因此得名。所有步骤在浏览器中完成，令牌对访问者是可见的，且客户端不需要认证。（A）客户端将用户导向认证服务器。（B）用户决定是否给于客户端授权。（C）假设用户给予授权，认证服务器将用户导向客户端指定的”重定向URI”，并在URI的Hash部分包含了访问令牌。（D）浏览器向资源服务器发出请求，其中不包括上一步收到的Hash值。（E）资源服务器返回一个网页，其中包含的代码可以获取Hash值中的令牌。（F）浏览器执行上一步获得的脚本，提取出令牌。（G）浏览器将令牌发给客户端。A步骤中，客户端发出的HTTP请求，包含以下参数：response_type：表示授权类型，此处的值固定为”token”，必选项。client_id：表示客户端的ID，必选项。redirect_uri：表示重定向的URI，可选项。scope：表示权限范围，可选项。state：表示客户端的当前状态，可以指定任意值，认证服务器会原封不动地返回这个值。C步骤中，认证服务器回应客户端的URI，包含以下参数：access_token：表示访问令牌，必选项。token_type：表示令牌类型，该值大小写不敏感，必选项。expires_in：表示过期时间，单位为秒。如果省略该参数，必须其他方式设置过期时间。scope：表示权限范围，如果与客户端申请的范围一致，此项可省略。state：如果客户端的请求中包含这个参数，认证服务器的回应也必须一模一样包含这个参数。密码模式密码模式（Resource Owner Password Credentials Grant）中，用户向客户端提供自己的用户名和密码。客户端使用这些信息，向”服务商提供商”索要授权。在这种模式中，用户必须把自己的密码给客户端，但是客户端不得储存密码。这通常用在用户对客户端高度信任的情况下，比如客户端是自家服务或者操作系统的一部分，或者由一个著名公司出品。而认证服务器只有在其他授权模式无法执行的情况下，才能考虑使用这种模式。它的步骤如下：（A）用户向客户端提供用户名和密码。（B）客户端将用户名和密码发给认证服务器，向后者请求令牌。（C）认证服务器确认无误后，向客户端提供访问令牌。B步骤中，客户端发出的HTTP请求，包含以下参数：grant_type：表示授权类型，此处的值固定为”password”，必选项。username：表示用户名，必选项。password：表示用户的密码，必选项。scope：表示权限范围，可选项。客户端模式客户端模式（Client Credentials Grant）指客户端以自己的名义，而不是以用户的名义，向”服务提供商”进行认证。严格地说，客户端模式并不属于OAuth框架所要解决的问题。在这种模式中，用户直接向客户端注册，客户端以自己的名义要求”服务提供商”提供服务，其实不存在授权问题。（A）客户端向认证服务器进行身份认证，并要求一个访问令牌。（B）认证服务器确认无误后，向客户端提供访问令牌。A步骤中，客户端发出的HTTP请求，包含以下参数：grant_type：表示授权类型，此处的值固定为”client_credentials”，必选项。scope：表示权限范围，可选项。更新令牌如果用户访问的时候，客户端的”访问令牌”已经过期，则需要使用”更新令牌”申请一个新的访问令牌。客户端发出更新令牌的HTTP请求，包含以下参数：grant_type：必选项，表示使用的授权模式，固定为”refresh_token”。refresh_token：表示早前收到的更新令牌，必选项。scope：表示申请的授权范围，不可以超出上一次申请的范围，如果省略该参数，则表示与上一次一致。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式配置中心Apollo实践]]></title>
    <url>%2F%E5%88%86%E5%B8%83%E5%BC%8F%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83Apollo%E5%AE%9E%E8%B7%B5.html</url>
    <content type="text"><![CDATA[描述Apollo（阿波罗）是携程框架部门研发的分布式配置中心，能够集中化管理应用不同环境、不同集群的配置，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性，适用于微服务配置管理场景。官网传送门：apollo.github。安装实践当前版本apollo(包括config server、admin server、portal server)是基于spring boot 1.3.x所开发，因此无需依赖tomcat容器，可以直接通过java -jar 启动。meta是注册中心地址，以eureka为注册中心，默认情况下，config server自己本身就是一个eureka服务，所以config server和admin server都会注册到config server的eureka上。aopllo官方有两种配置方案：一、Quick start，这种方案是将三个server整合到了一起，名为apollo_all_in_one.jar，启动方式为通过官方提供的demo.sh来进行脚本启动，这种方式只能管理单个环境，但部署方便。 二、分布式部署方案，这种方案是在每一套环境中各部署一套apollo，但是他们都共用一个portal数据库。Quick start官方的介绍和安装步骤非常详细，请自行查阅: https://github.com/ctripcorp/apollo/wiki/Quick-Start。需要注意的是，官方的一段关于异常的说明：如果启动遇到了异常，可以分别查看service和portal目录下的log文件排查问题。注：在启动apollo-configservice的过程中会在日志中输出eureka注册失败的信息，如com.sun.jersey.api.client.ClientHandlerException: java.net.ConnectException: Connection refused。需要注意的是，这个是预期的情况，因为apollo-configservice需要向Meta Server（它自己）注册服务，但是因为在启动过程中，自己还没起来，所以会报这个错。后面会进行重试的动作，所以等自己服务起来后就会注册正常了。分布式部署参阅官方教程进行部署：https://github.com/ctripcorp/apollo/wiki/%E5%88%86%E5%B8%83%E5%BC%8F%E9%83%A8%E7%BD%B2%E6%8C%87%E5%8D%97其部署图如下：解释一下该图，portal为管理中心，adminservice和configservice共同组成配置服务器，所以可以理解为portal可以只用安装一台，adminservice和confingservice需要在每一个环境中安装一份，同理，portaldb只需要部署一个，而configdb在每一个环境的数据库都需要部署一份，由于成本限制，公司只有A、B两个环境，其中A为开发/测试环境，B为预发布/生产环境，环境布置好以后，需要在portal-service/confif/apollo-env.properties里配置不同环境的meta信息，并且在portalDB的serverconfig表里key为apollo.portal.envs添加所需要的环境，多个环境间以逗号分隔开。注：如果公司服务器环境为阿里云，在获取配置服务器IP地址时，client获取到的可能是服务器内网地址，查看eureka的图形化界面信息，如图：这是由于注册到eureka服务器（即configservice）时，eureka获取到的是其他网卡上的内网地址，导致client一直在超时重试。解决这个的办法有三个：一：下载一份源码，clone或者下载zip，在configservice或者adminservice的bootstrap.yml文件里加入以下配置：123eureka: instance: ip-address: $&#123;指定的IP&#125;然后运行scripts里的build脚本，即可获得重新编译打包后的configservice，adminservice，portal三个项目的zip文件，这种方式的不便之处在于每一种环境都要改一次配置然后build。二：直接指定要注册的IP，可以修改startup.sh，通过JVM System Property在运行时传入-Deureka.instance.ip-address=${指定的IP}。下载官方的configservice，adminservice，portal三个项目的zip包，在服务器上解压开之后，在configservice项目里的scripts/start.sh文件里，如图：这种方式较为推荐，对源码的入侵性比较小。三：直接指定要注册的IP+PORT，可以修改startup.sh，通过JVM System Property在运行时传入，如-Deureka.instance.homePageUrl=http://${指定的IP}:${指定的Port}，或者也可以修改apollo-adminservice或apollo-configservice 的bootstrap.yml文件，加入以下配置：1234eureka: instance: homePageUrl: http://$&#123;指定的IP&#125;:$&#123;指定的Port&#125; preferIpAddress: false做完上述修改并重启后，可以查看Eureka页面（http://${config-service-url:port}）检查注册上来的IP信息是否正确。需要记住，在scripts/start.sh文件里还需要修改JAVA_OPTS里的jvm参数，如果服务器内存足够（8G以上），那么无需更改，如果不足，请适当按比例缩小,本文机器是4C8G，配置为export JAVA_OPTS=&quot;-Xms1024m -Xmx1024m -Xss256k -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=384m -XX:NewSize=614m -XX:MaxNewSize=614m -XX:SurvivorRatio=8&quot;。项目配置项目概况：spring boot 1.5.10.RELEASE+dubbo 2.6.2由于dubbo-qos等的启动配置可能早于spring初始化完成，所以推荐使用注解式配置。配置导入maven依赖:12345&lt;dependency&gt; &lt;groupId&gt;com.ctrip.framework.apollo&lt;/groupId&gt; &lt;artifactId&gt;apollo-client&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt;在resource目录下创建apollo-env.properties文件，内容如下：app.id = provider_vouchers apollo.bootstrap.enabled = true logging.level.com.tubitu=debug apollo.bootstrap.namespaces = application,datasource 然后新建一个dubbo配置类：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566@Configurationpublic class DubboConfig &#123; /**这里也可以使用Spring 的@value注解注入属性，然后set到dubbo的applicationConfig、registryConfig、protocolConfig里面*/ @ApolloConfig private Config config; /** *@Author: 刘会俊 *@Description: dubbo.application配置 *@Params [] *@Return com.alibaba.dubbo.config.ApplicationConfig */ @Bean public ApplicationConfig applicationConfig() &#123; ApplicationConfig applicationConfig = new ApplicationConfig(); applicationConfig.setId(config.getProperty("dubbo.application.id","provider_vouchers")); applicationConfig.setName(config.getProperty("dubbo.application.name","provider_vouchers")); applicationConfig.setQosEnable(config.getBooleanProperty("dubbo.application.qos.enable",false)); applicationConfig.setQosPort(config.getIntProperty("dubbo.application.qos.port",22222)); return applicationConfig; &#125; /** *@Author: 刘会俊 *@Description: dubbo.registry配置 *@Params [] *@Return com.alibaba.dubbo.config.RegistryConfig */ @Bean public RegistryConfig registryConfig() &#123; RegistryConfig registryConfig = new RegistryConfig(); registryConfig.setAddress(config.getProperty("dubbo.registry.address","zookeeper://127.0.0.1:2181")); registryConfig.setCheck(config.getBooleanProperty("dubbo.registry.check",true)); return registryConfig; &#125; /** *@Author: 刘会俊 *@Description: dubbo.protocol配置 *@Params [] *@Return com.alibaba.dubbo.config.ProtocolConfig */ @Bean public ProtocolConfig protocolConfig() &#123; ProtocolConfig protocolConfig = new ProtocolConfig(); protocolConfig.setId(config.getProperty("dubbo.protocol.id","dubbo")); protocolConfig.setName(config.getProperty("dubbo.protocol.name","dubbo")); protocolConfig.setPort(config.getIntProperty("dubbo.protocol.port",20880)); return protocolConfig; &#125; /** *@Author: 刘会俊 *@Description: dubbo.provider配置 *@Params [] *@Return com.alibaba.dubbo.config.ProviderConfig */ @Bean public ProviderConfig providerConfig()&#123; ProviderConfig providerConfig = new ProviderConfig(); providerConfig.setVersion(config.getProperty("dubbo.provider.version", "1.0.0")); return providerConfig; &#125; &#125;2018-10-19日更新：配置日志的打印级别动态修改：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * @Description: 动态日志配置 * @Author: 刘会俊 * @Date: 2018-10-18 22:18 */@Configurationpublic class DynamicLoggersConfig &#123; private final static Logger LOGGER = LoggerFactory.getLogger(DynamicLoggersConfig.class); @ApolloConfig private Config config; private final static String LOGGER_TAG = "logging.level."; @Autowired private LoggingSystem loggingSystem; @ApolloConfigChangeListener private void configChangeListter(ConfigChangeEvent changeEvent)&#123; refreshLoggingLevels(); &#125; @PostConstruct private void refreshLoggingLevels() &#123; Set&lt;String&gt; keyNames = config.getPropertyNames(); for (String key : keyNames) &#123; if (containsIgnoreCase(key, LOGGER_TAG)) &#123; String strLevel = config.getProperty(key, "info"); LogLevel level = LogLevel.valueOf(strLevel.toUpperCase()); loggingSystem.setLogLevel(key.replace(LOGGER_TAG, ""), level); LOGGER.info("&#123;&#125;:&#123;&#125;", key, strLevel); &#125; &#125; &#125; public static boolean containsIgnoreCase(String str, String searchStr) &#123; if (str == null || searchStr == null) &#123; return false; &#125; int len = searchStr.length(); int max = str.length() - len; for (int i = 0; i &lt;= max; i++) &#123; if (str.regionMatches(true, i, searchStr, 0, len)) &#123; return true; &#125; &#125; return false; &#125; &#125;]]></content>
      <categories>
        <category>编程技术</category>
      </categories>
      <tags>
        <tag>CI/CD</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx安装实践]]></title>
    <url>%2FNginx%E5%AE%89%E8%A3%85%E5%AE%9E%E8%B7%B5.html</url>
    <content type="text"><![CDATA[描述Nginx官网：http://nginx.org/en/Nginx是一个高性能的代理服务器，其使用c语言编写，依赖pcre，zlib和openSSL第三方库，因其性能高，占用内存低，bug少并且稳定性高而被很多大公司亲睐，作者是一名俄罗斯人。本笔记会从安装到配置，最后会介绍一些nginx的实践应用。安装首先上传nginx的tar.gz包至服务器，将nginx解压至/usr/local目录下，local目录常用来放置用户安装的软件。123456tar -xzvf nginx-1.12.2.tar.gz -C /usr/localcd /usr/locallscd nginx-1.14.0./configure --with-debug##./configure [--prefix=/usr/local/nginx] --with-debug其中中括号里的内容表示安装目录，默认就是/usr/local/nginx执行配置脚本，并打开调试模式如果报错如下：表示需要gcc-c++编译器，所以我们需要联网安装。12345##ubuntuapt-get install build-essentialapt-get install libtool##centosyum install gcc-c++nginx依赖于PCRE和zlib的库，所以看到类似于requires the PCRE library或者zlib library的报错，在centos下直接安装即可：12yum install pcre-develyum install zlib-devel出现以下提示即为成功：此时出现Makefile文件，输入：123makemake install或者make &amp;&amp; make install此时出现如下提示即为成功：此时在configure步骤指定的目录中(本文为/usr/local/)，即出现了nginx目录。带版本号的是解压后的源码，nginx目录是编译好的软件。卸载首先在/usr/local/下删除nginx目录：rm -rf nginx然后进入源码目录，输入：make clean启停12345678##启动./nginx##停止./nginx -s stop##重启./nginx -s reload##测试./nginx -t没有结果即是最好的结果………实际上启动后nginx/logs目录里会出现nginx.pid的文件，记录了nginx的进程号，停止以后就没了。或者启动以后访问nginx所在域名以及监听端口：配置文件位于nginx/conf目录下vim nginx.conf启用调试日志：主要分两大块模块，events模块和http模块，常用到的就是http模块下的server模块，server模块里可以指定nginx监听的IP地址或者域名，端口等等，端口默认80.location匹配的是uri，其匹配规则如下(来源于网络)：语法location [=|~|~*|^~] /uri/ {…}规则:= ： 表示精确的URI匹配(有兴趣的同学可以看一下url和uri的区别)～： 表示区分大小写的正则匹配～*：表示不区分大小写的正则匹配!~ &amp;&amp; !~*：表示区分大小写不匹配的正则和不区分大小写的不匹配的正则/：通用匹配，任何请求都会匹配到location匹配目标location匹配测试只使用请求URI的部分，而不使用参数部分。（原因：参数的写法太多，无法精确匹配）location匹配顺序多个location配置的前提下，location的匹配顺序（未验证，嘿嘿，google上搜的）首先匹配=其次匹配^~再其次按照配置文件的顺序进行正则匹配最后是交给/进行通用匹配注意：当有匹配成功时，立刻停止匹配，按照当前匹配规则处理请求演示实例nginx 配置文件，自下到上分为三种层次分明的结构：| http block the protocol level| server block the server levelV location block the requested URINginx 允许用户定义 Location block ，并指定一个匹配模式（pattern）匹配特定的 URI。除了简单的字符串（比如文件系统路径），还允许使用更为复杂的匹配模式（pattern）。Location block 的基本语法形式是：location [=|~|~|^~|@] pattern { … }[=|~|~|^~|@] 被称作 location modifier ，这会定义 Nginx 如何去匹配其后的 pattern ，以及该 pattern 的最基本的属性（简单字符串或正则表达式）。关于 location modifier=这会完全匹配指定的 pattern ，且这里的 pattern 被限制成简单的字符串，也就是说这里不能使用正则表达式。123456server &#123; server_name jb51.net; location = /abcd &#123; […] &#125;&#125;匹配情况：http://jb51.net/abcd # 正好完全匹配 http://jb51.net/ABCD # 如果运行 Nginx server 的系统本身对大小写不敏感，比如 Windows ，那么也匹配 http://jb51.net/abcd?param1?m2 # 忽略查询串参数（query string arguments），这里就是 /abcd 后面的 ?param1?m2 http://jb51.net/abcd/ # 不匹配，因为末尾存在反斜杠（trailing slash），Nginx 不认为这种情况是完全匹配 http://jb51.net/abcde # 不匹配，因为不是完全匹配 (None)可以不写 location modifier ，Nginx 仍然能去匹配 pattern 。这种情况下，匹配那些以指定的 patern 开头的 URI，注意这里的 URI 只能是普通字符串，不能使用正则表达式。123456server &#123; server_name website.com; location /abcd &#123; […] &#125;&#125;匹配情况：http://jb51.net/abcd # 正好完全匹配 http://jb51.net/ABCD # 如果运行 Nginx server的系统本身对大小写不敏感，比如 Windows ，那么也匹配 http://jb51.net/abcd?param1?m2 # 忽略查询串参数（query string arguments），这里就是 /abcd 后面的 ?param1?m2 http://jb51.net/abcd/ # 末尾存在反斜杠（trailing slash）也属于匹配范围内 http://jb51.net/abcde # 仍然匹配，因为 URI 是以 pattern 开头的 定义location时需要注意的是proxy_pass里转发的服务器：请求地址：http://192.168.1.4/proxy/test.html配置一：location /proxy/ { proxy_pass http://127.0.0.1:81/; } 会被代理到http://127.0.0.1:81/test.html 这个url配置二：location /proxy/ { proxy_pass http://127.0.0.1:81; } 会被代理到http://127.0.0.1:81/proxy/test.html 这个url注意：该情况只在没有location modifier的情况下才有，对于~或者~*等正则匹配，是不能在proxy_pass里最后配置/的。~这个 location modifier 对大小写敏感，且 pattern 须是正则表达式server { server_name jb51.net; location ~ ^/abcd$ { […] } } 匹配情况：http://jb51.net/abcd # 完全匹配 http://jb51.net/ABCD # 不匹配，~ 对大小写是敏感的 http://jb51.net/abcd?param1?m2 # 忽略查询串参数（query string arguments），这里就是 /abcd 后面的 ?param1?m2 http://jb51.net/abcd/ # 不匹配，因为末尾存在反斜杠（trailing slash），并不匹配正则表达式 ^/abcd$ http://jb51.net/abcde # 不匹配正则表达式 ^/abcd$ 注意：对于一些对大小写不敏感的系统，比如 Windows ，~ 和 ~* 都是不起作用的，这主要是操作系统的原因。~*与 ~ 类似，但这个 location modifier 不区分大小写，pattern 须是正则表达式server { server_name website.com; location ~* ^/abcd$ { […] } } 匹配情况：http://jb51.net/abcd # 完全匹配 http://jb51.net/ABCD # 匹配，这就是它不区分大小写的特性 http://jb51.net/abcd?param1?m2 # 忽略查询串参数（query string arguments），这里就是 /abcd 后面的 ?param1?m2 http://jb51.net/abcd/ # 不匹配，因为末尾存在反斜杠（trailing slash），并不匹配正则表达式 ^/abcd$ http://jb51.net/abcde # 不匹配正则表达式 ^/abcd$ ^~匹配情况类似 (None) 的情况，以指定匹配模式开头的 URI 被匹配，不同的是，一旦匹配成功，那么 Nginx 就停止去寻找其他的 Location 块进行匹配了（与 Location 匹配顺序有关）@用于定义一个 Location 块，且该块不能被外部 Client 所访问，只能被 Nginx 内部配置指令所访问，比如 try_files or error_page常见问题504 gate-way timeout服务端如果使用的是PHP，server块可以调整如下配置：12345678fastcgi_connect_timeout 1000;fastcgi_send_timeout 1000;fastcgi_read_timeout 1000;fastcgi_buffer_size 64k;fastcgi_buffers 8 128k;fastcgi_busy_buffers_size 128k;fastcgi_temp_file_write_size 128k;fastcgi_intercept_errors on;如果使用的tomcat,1234567proxy_connect_timeout 1000;proxy_send_timeout 1000;proxy_read_timeout 1000;proxy_buffer_size 64k;proxy_buffers 8 128k;proxy_busy_buffers_size 128k;proxy_temp_file_write_size 128k;413 Request Entity Too Large请求体过大,server块调整以下配置：client_max_body_size 50m;实践静态资源将请求m.tubitu.cn/mtpic/1.jpg的图片请求转发到nginx/mtpic图片目录下。123456789101112131415161718192021222324server&#123; listen 80; server_name m.tubtu.cn; client_max_body_size 10m; location / &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Real-Port $remote_port; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://localhost:8084/; &#125; #第一种配置 location ~ ^/mtpic/ &#123; root /usr/local/nginx; &#125; #第二种配置 location ~* \.(jpg|png|jpeg)&#123; root mtpic; &#125;&#125;负载均衡+反向代理123456789101112131415161718192021222324upstream test_server&#123; server 192.168.1.63:8082; server 192.168.1.64:8082; &#125; server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; root html; index index.html index.htm; &#125; location ~ ^/test &#123; proxy_pass http://test_server; &#125; &#125;请求会分配给test_server里的两个服务。也可以指定ip_hash的算法，即同一ip地址算出来的hash值一致，发出来的请求都会交由同一台服务器执行，这也可以作为session一致性的解决方案之一。还可以在upstream给每一台服务器分配权重。如：server 192.168.1.63:8082 weight=10。在更新被代理的后端服务器时，还可以将某几台服务器临时标记为宕机，nginx就不会将请求转发到该服务器，方便进行灰度发布，如：server 192.168.1.63:8082 down。HTTPS服务配置需要在./configure这一步开启ssl_module:./configure --with-http_ssl_module12345678910111213141516171819202122server &#123; listen 443; server_name test.com; ssl on; #以下两行为证书所在位置 本文位于/usr/local/nginx/conf/cert 下 ssl_certificate cert/123456.pem; ssl_certificate_key cert/123456.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; location ~ ^/test &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_pass http://localhost:9000; &#125; &#125;还可以重写url，使得客户端发过来的HTTP请求全部变为HTTPS请求：在需要重写的server模块加上：rewrite ^(.*)$ https://$host$1 permanent;Nginx HA(Hign-Availability) 主从原理两台nginx共用一个virtual IP，当其中一台服务器的nginx宕机后，keepalived会通过用户在配置文件里指定的检测脚本检测到nginx挂掉以后，同时停止keepalived，并发出多播消息，另一台服务器中运行的keepalived进程收到多播消息以后即会持有virtual IP，保证nginx的高可用。keepalived安装http://www.keepalived.org/下载后上传到服务器，安装步骤和Nginx基本一致，就不细说了，其依赖于openssl。123456tar -xzvf keepalived-2.0.7.tar.gz -C /usr/local/yum install opensslyum install openssl-develcd /usr/local/keepalived-2.0.7./configure --prefix=/usr/local/keepalived/make &amp;&amp; make install没有结果就是最好的结果,暂时无需管ipv6的支持性警告。接下来将keepalived作为系统服务启动：1234567891011121314#将keepalived可执行文件复制到系统路径下cp /usr/local/keepalived/sbin/keepalived /usr/sbin/#创建keepalived配置文件目录并复制配置文件，/etc目录常用于Linux软件配置mkdir /etc/keepalivedcp /usr/local/keepalived/etc/keepalived/keepalived.conf /etc/keepalived/#将软件目录下的系统配置文件复制到系统目录下cp /usr/local/keepalived/etc/sysconfig/keepalived /etc/sysconfig/#将源码目录下的开机启动脚本复制到系统开机启动脚本目录中cp /usr/local/keepalived-2.0.7/keepalived/etc/init.d/keepalived /etc/init.d#启动systemctl start keepalivedsystemctl status keepalived#停止systemctl stop keepalived验证通过。ps : systemctl是centos 7后加入的一个系统服务管理指令，速度更快，推荐使用。原来的service不推荐使用。主从配置虚拟机描述：1234#查看系统版本cat /etc/centos-release#查看内核发行号uname --r配置描述：服务器1:192.168.1.63 服务器2:192.168.1.64 虚拟IP:192.168.1.100 然后进行配置：1234##备份官方配置文件cd /etc/keepalivedcp keepalived.conf keepalived.conf.bak vim keepalived.conf删除其他所有配置，只需要以下配置：! Configuration File for keepalived ## keepalived会定时执行脚本并对脚本执行的结果进行分析,动态调整vrrp_instance的优先级。 ##如果脚本执行结果为0,并且weight配置的值大于0,则优先级相应的增加。如果脚本执行结果非0, ##并且weight配置的值小于 0,则优先级相应的减少。其他情况,维持原本配置的优先级,即配置文件中priority对应的值 global_defs { router_id LVS_DEVEL_01 #标识本节点的名称，通常为hostname } vrrp_script check_nginx{ script &quot;/etc/keepalived/check_nginx.sh&quot; interval 2 #每2秒检测一次nginx的运行状态 weight -2 #失败一次，将自己的优先级-20 } vrrp_instance VI_1 { state MASTER # 状态，主节点为MASTER，备份节点为BACKUP interface ens33 # 绑定VIP的网络接口，通过ifconfig查看自己的网络接口 virtual_router_id 51 # 虚拟路由的ID号,两个节点设置必须一样,可选IP最后一段使用,相同的VRID为一个组,他将决定多播的MAC地址 #mcat_src_ip 192.168.1.63 # 本机IP地址 priority 100 # 节点优先级，值范围0～254，MASTER要比BACKUP高 advert_int 1 # 组播信息发送时间间隔，两个节点必须设置一样，默认为1秒 # 设置验证信息，两个节点必须一致 authentication { auth_type PASS auth_pass 1111 } # 虚拟IP，两个节点设置必须一样。可以设置多个，一行写一个 virtual_ipaddress { 192.168.1.100 } track_script{ check_nginx # nginx存活状态检测脚本 } } 从节点配置：! Configuration File for keepalived global_defs { router_id LVS_DEVEoL_02 } vrrp_script check_nginx{ script &quot;/etc/keepalived/check_nginx.sh&quot; interval 2 weight -2 } vrrp_instance VI_1 { state BACKUP interface ens33 virtual_router_id 51 #mcast_src_ip 192.168.1.64 priority 99 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 192.168.1.100 } track_script{ check_nginx } } 检测脚本check_nginx.sh（主备机都要有该脚本）：12345678910#!/bin/bashcounter=$(ps -C nginx --no-heading|wc -l)if [ $counter -eq 0 ]; then /usr/local/nginx/sbin/nginx sleep 2 counter=$(ps -C nginx --no-heading|wc -l) if [ $counter -eq 0 ];then systemctl stop keepalived fifi需要注意的是：if 后中括号里第一个字符和最后一个字符必须是空格，否则脚本语法错误，编辑完可以使用sh check_nginx.sh运行检测一下。分别启动两台服务器的nginx和keepalived，访问虚拟IP即可访问到nginx主页。master机输入命令：ip addr #或者ip add可以看到虚拟ip 已经绑定到 ens33网卡上，此时停止主机keepalived，在备机输入相同指令：此时virtual IP漂移到了从机，访问虚拟ip，nginx依然正常。以上配置每次主机启动都会抢占master，可以配置非抢占式，其配置方法是在vrrp_instance VI_1 模块中加入nopreempt参数，并将两台机器都作为从机，如图：两个keepalived节点都启动后，默认都是BACKUP状态，双方在发送组播信息后，会根据优先级来选举一个MASTER出来。由于两者都配置了nopreempt，所以MASTER从故障中恢复后，不会抢占virtual IP。这样会避免VIP切换可能造成的服务延迟。Nginx HA主主其原理就是两台机器互为master和backup。系统信息与主从部分基本保持一致。对于Virtual IP，由于两台机器互为主备，因此一个Virtual IP 肯定不能满足要求了，角色关系如下：服务器1:192.168.1.63 服务器2:192.168.1.64 虚拟IP1:192.168.1.100（主-服务器1，备-服务器2） 虚拟IP2:192.168.1.101（主-服务器2，备-服务器1） 同样还是编辑keepalived.conf文件，输入英文冒号进入末行模式，在末行模式下输入set nu然后按enter，显示行号：将光标移到第13行，按esc键再次进入命令模式，输入18yy，该命令不会显示出过程只有结果：复制了18行然后进入末行模式，输入30，按enter跳转到第30行，然后按p，粘贴刚刚复制的18行内容。末行模式下，跳转到31行，需要修改的地方有六处，vrrp instance名，主备状态，虚拟路由id，优先级，虚拟ip地址等，虚拟ip 101备机配置如下：主机配置：分别启动nginx和keepalived，在两台机器上输入ip addr，结果如下：192.168.1.64是虚拟ip 192.168.1.101的master，192.168.1.63是虚拟ip 192.168.1.100的master。关闭64的keepalived，虚拟地址101开始漂移：]]></content>
      <categories>
        <category>编程技术</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java进阶学习-反射]]></title>
    <url>%2FJava%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A0-%E5%8F%8D%E5%B0%84.html</url>
    <content type="text"><![CDATA[简述主要是自己对于Java一些进阶知识的补充学习，包括但不局限于反射，多线程、源码等，本篇主要介绍反射，相关API在Java.lang.reflect中。反射反射是Java运行时动态获取类或者方法信息等一种机制。任何一个类都是Class的实例对象，要获取这个实例对象，有以下三种方式；1234567891011121314151617181920212223242526272829303132333435363738//实际上可以看出来每一个类里面都有一个隐含的成员变量classClass c1 = Color.class;//通过实例来获取类信息​Color color = new Color();Class c2 = color.getClass();//第三种Class c3 = null;try&#123; c3 = Class.forName("com.test.Color");&#125;catch(ClassNotFoundExection e)&#123; e.printStackTrace();&#125;//可以通过类的类类型创建该类的对象实例 ---&gt; 通过c1 c2 c3创建新实例try &#123; AQSTest a = (AQSTest) c1.newInstance();//前提是必须有默认无参构造函数&#125; catch (InstantiationException | IllegalAccessException e) &#123; // TODO Auto-generated catch block e.printStackTrace();&#125; //使用new 创建一个类的实例时，是静态加载类，即在编译时刻就需要加载所有的有可能使用到的类try &#123; //动态获取类，在运行时加载 Class c4 = Class.forName(args[0]); //通过类类型，动态创建类 c4.newInstance();&#125; catch (ClassNotFoundException e) &#123; // TODO Auto-generated catch block e.printStackTrace();&#125; catch (InstantiationException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; catch (IllegalAccessException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; //基本的数据类型，以及void等关键字都有类类型成员函数1234567891011121314151617181920/** * 打印成员变量 * @param obj */public static void printFieldMessage(Object obj) &#123; Class c = obj.getClass(); Field[] fs = c.getDeclaredFields(); /** * 成员变量也是对象，是 * java.lang.refelct.Field的实例对象，该类封装了关于成员变量的操作 */ for (Field field : fs) &#123; //得到成员变量类型的类类型 Class fieldType = field.getType(); String typeName = fieldType.getName(); //得到成员变量的名称 String fieldName = field.getName(); System.out.println(typeName+" "+fieldName); &#125;&#125;构造函数12345678910111213141516171819/** * 打印对象的构造函数的信息 * @param obj */public static void printConstructor(Object obj)&#123; Class c = obj.getClass(); //获取所有的自己所有的public的构造函数 Constructor[] cs = c.getDeclaredConstructors(); for (Constructor constructor : cs) &#123; System.out.print(constructor.getName()+"("); //获取构造函数的参数列表 ---&gt; 得到的是参数列表的类类型 Class[] parameterTypes = constructor.getParameterTypes(); for (Class class1 : parameterTypes) &#123; System.out.print(class1.getName()+","); &#125; System.out.println(")"); &#125; System.out.println();&#125;方法的反射操作1234567891011121314151617181920212223242526public static void main(String[] args) &#123; A a = new A(); Class c = a.getClass(); try &#123; //获取方法对象 Method m = c.getMethod("print", new Class[]&#123;String.class,String.class&#125;); //c.getMethod("print", int.class,int.class); //方法的反射操作是用方法的对象m自己调用自己，和a.print()的效果相同 //方法如果没有返回值返回null，有返回值返回具体的返回值 Object obj = m.invoke(a, "1","2"); &#125; catch (Exception e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125;Class A&#123; public void print(int a,int b)&#123; System.out.println(a+b); &#125; public void print(String a,String b)&#123; System.out.println(a.toUpperCase()+" "+b.toUpperCase()); &#125;&#125;通过反 射认识范型1234567891011121314151617181920212223242526272829303132public static void main(String[] args) &#123; //首先看一个问题： List&lt;String&gt; list = new ArrayList&lt;String&gt;(); List list1 = new ArrayList&lt;&gt;(); //list.add(20);错误操作 Class c = list.getClass(); Class c1 = list1.getClass(); System.out.println(c == c1);//true //反射的操作都是编译之后的操作 /** * 结论： * 说明编译之后集合的泛型是去泛型化的，Java中集合的泛型，是为了防止错误输入的 * 只在编译阶段有效 */ try &#123; Method m = c.getMethod("add", Object.class); m.invoke(list, 20); System.out.println(list.size()); System.out.println(list); //用string进行遍历时就会进行报错 /*for (String string : list) &#123; System.out.println(string); &#125;*/ for (Object object : list) &#123; System.out.println(object); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125;]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven+Dubbo+ZK构建soa架构]]></title>
    <url>%2Fmaven-dubbo-zk%E6%9E%84%E5%BB%BAsoa%E6%9E%B6%E6%9E%84.html</url>
    <content type="text"><![CDATA[简述dubbo 是目前国内最广泛的rpc框架，官网见 http://dubbo.apache.org/zh-cn/index.html，建议直接对着官网开发文档配置较为可靠。dubbo常用于soa架构，soa架构和微服务架构均是分布式系统的两种实践，从某种程度而言，soa架构是微服务架构的超集，或者说微服务是soa的一个变种。SOA微服务应用程序服务的可重用性的最大化专注于解耦系统性的改变需要修改整体系统性的改变是创建一个新的服务DevOps和持续交付正在变得流行，但还不是主流强烈关注DevOps和持续交付专注于业务功能重用更重视“上下文边界，服务粒度”的概念支持多种消息协议使用轻量级协议，例如HTTP，REST或Thrift API对部署到它的所有服务使用通用平台应用程序服务器不是真的被使用，通常使用云平台容器（如Docker）的使用不太受欢迎容器在微服务方面效果很好SOA服务共享数据存储每个微服务可以有一个独立的数据存储共同的治理和标准轻松的治理，更加关注团队协作和选择自由图表资料来源于网上：资深架构师dubbo+spring xml方式pom文件123456789101112131415161718192021&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;2.5.3&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.8&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.sgroschupf&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;0.1&lt;/version&gt; &lt;/dependency&gt;服务发布方dubbo-provider.xml:123456789&lt;!-- dubbo配置 --&gt;&lt;!-- 服务提供者的名字，随意定义，只要不重复即可 --&gt;&lt;dubbo:application name="user_provider"/&gt;&lt;!-- 配置zookeeper注册中心的地址 --&gt;&lt;dubbo:registry address="zookeeper://localhost:2181"/&gt;&lt;!-- 配置dubbo暴露服务时所使用的端口号 --&gt;&lt;dubbo:protocol name="dubbo" port="20880"/&gt;&lt;!--暴露的接口完整限定名，也可以用@Service注解配合dubbo:annotation的标签暴露服务接口--&gt;&lt;dubbo:service interface="com.tubitu.service.user.UserInfoService" ref="userInfoServiceImpl"/&gt;服务消费方dubbo-consumer.xml:1234567891011121314151617&lt;!-- 服务调用者的应用名字，随便定义，只要不重复即可，不需要跟服务提供者的名字对应 --&gt;&lt;dubbo:application name="platform_consumer"/&gt;&lt;!-- 配置zookeeper地址，用于订阅（发现）服务 --&gt;&lt;dubbo:registry address="$&#123;dubbo.address&#125;"/&gt;&lt;!-- 配置需要调用哪一个服务接口 --&gt;&lt;!-- 一个标签只能调用一个服务接口 如果需要调用多个服务接口，需要配置多个标签 会将该接口的实例，存入spring容器 id属性：该实例在容器中的id，值是自定义的 interface属性：服务接口对应的完全限定名 --&gt; &lt;!--此处的配置是当spring里的远程service为空时打开，因为springmvc扫描时可能dubbo还未扫描导致未初始化，所以下面的注解就是在装载spring bean前初始化dubbo的远程服务--&gt;&lt;!--&lt;dubbo:annotation package=""/&gt;--&gt;&lt;dubbo:reference id="userInfoServiceImpl" interface="com.tubitu.service.user.UserInfoService"/&gt;调用service的调用可以直接使用spring的@Autowired注解，就和spring扫描的服务一样，version和timeout，由于这个版本的dubbo不支持全局超时配置，因此需要在调用方指定超时时间。zookeeper官网下载zookeeper的压缩包，解压后即可打开，linux和windows通用，首先需要进入config目录将其中的zoo-sample.cfg 改名为zoo.cfg因为zookeeper是默认读取的zoo.cfg文件的。然后进入bin目录，双击zkServer.bat文件即可运行。linux下需要进入zookeeper里的bin目录下，执行zkServer start命令启动，执行zkServer stop停止zk。dubbo+spring boot方式搭建父项目新建项目，类型选择maven，然后勾选Create from archetype，选择maven-archetype-quickstart，生成一个普通的maven项目，填写maven仓库坐标即可一路点击完成，如果有src目录，可以直接删除，然后修改pom文件的packaging标签的值为pom，表示父项目只提供pom依赖。搭建子模块对于普通子模块：在父项目的基础上new -&gt; module，然后操作与第一步大致一致，需要注意的是groupId要和父项目的保持一致，artifactId可以自定义。对于spring boot子木块：在父项目的基础上new -&gt; module，选择spring initializer，在new module窗口上，填写group与父项目的groupId保持一致，artifact为项目名，并填写好name和package，packaging根据需要可以填写jar、war等包类型，本文推荐使用jar包，注意右上角小的下拉框，本文所使用的配置无法保证在spring boot 1.5.X以外的版本使用。父子关联重复第二步，创建自己所需各个模块以后，其结构基本如下：将父pom文件里增加modules标签，并与子module的artifactId一一关联上：1234567891011121314151617&lt;modules&gt; &lt;module&gt;tubitu_service_user&lt;/module&gt; &lt;module&gt;tubitu_service_api&lt;/module&gt; &lt;module&gt;tubitu_common&lt;/module&gt; &lt;module&gt;tubitu_util&lt;/module&gt; &lt;module&gt;tubitu_service&lt;/module&gt; &lt;module&gt;tubitu_service_business&lt;/module&gt; &lt;module&gt;tubitu_service_mall&lt;/module&gt; &lt;module&gt;tubitu_service_pay&lt;/module&gt; &lt;module&gt;tubitu_service_log&lt;/module&gt; &lt;module&gt;tubitu_service_monitor&lt;/module&gt; &lt;module&gt;tubitu_service_calculate&lt;/module&gt; &lt;module&gt;tubitu_service_task&lt;/module&gt; &lt;module&gt;tubitu_web_platform&lt;/module&gt; &lt;module&gt;tubitu_data_synchronous&lt;/module&gt; &lt;module&gt;tubitu_service_vouchers&lt;/module&gt; &lt;/modules&gt;同理，每一子module的pom文件也要与父项目进行关联：12345&lt;parent&gt; &lt;groupId&gt;tubitu_project&lt;/groupId&gt; &lt;artifactId&gt;tubitu_project&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;/parent&gt;此时会发现，原本spring boot项目的父依赖不再是spring boot的pom文件了，而是我们自己的父项目pom文件，有如下两种解决方案：在每个spring boot项目里的pom文件里，加上如下代码：1234567891011&lt;dependencyManagement&gt; &lt;!--定义全局公用的一些依赖，此处只定义依赖而不引入--&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;1.5.10.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencyManagement&gt;或者在父项目的pom文件里，加上该代码。本文为方便起见，直接在父项目pom文件里加入该依赖声明。打包配置对于tubitu_common、tubitu_util和tubitu_service这几个项目，第一个和第二个分别为实体类以及工具类所在项目，而tubitu_service是作为dubbo提供父和调用方的一个公共接口。这三个项目均可以打成单独的jar包作为其他项目依赖而存在，所以可以指定maven编译插件和源码版本。123456789101112131415161718192021222324252627&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;maven-compiler-plugin.version&#125;&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;$&#123;maven.compile.source&#125;&lt;/source&gt; &lt;target&gt;$&#123;maven.compile.target&#125;&lt;/target&gt; &lt;encoding&gt;$&#123;project.build.sourceEncoding&#125;&lt;/encoding&gt; &lt;skip&gt;true&lt;/skip&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;!--boot需要配置这个否则会提示找不到主类--&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;如此最后才能打出完整的包。依赖统一管理在父pom文件里定义公共jar包或框架的统一版本，只定义而不引入，在子模块中直接引入。例如：在父pom文件里配置了统一属性:123456789101112131415161718192021222324252627&lt;properties&gt; &lt;tubitu.version&gt;1.0&lt;/tubitu.version&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;mybatis.version&gt;3.4.6&lt;/mybatis.version&gt; &lt;spring.version&gt;4.3.14.RELEASE&lt;/spring.version&gt; &lt;!--项目基本依赖--&gt; &lt;slf4j.version&gt;1.7.7&lt;/slf4j.version&gt; &lt;log4j.version&gt;1.2.12&lt;/log4j.version&gt; &lt;aspectj.version&gt;1.7.2&lt;/aspectj.version&gt; &lt;mysql-connector-java.version&gt;5.1.38&lt;/mysql-connector-java.version&gt; &lt;rocketmq.version&gt;4.3.0&lt;/rocketmq.version&gt; &lt;fasterxml.jackson.version&gt;2.5.0&lt;/fasterxml.jackson.version&gt; &lt;javax.servlet.version&gt;3.1.0&lt;/javax.servlet.version&gt; &lt;!--分布式配置中心--&gt; &lt;apollo.client.version&gt;1.0.0&lt;/apollo.client.version&gt; &lt;!--dubbo依赖--&gt; &lt;curator.version&gt;2.12.0&lt;/curator.version&gt; &lt;zookeeper.version&gt;3.4.10&lt;/zookeeper.version&gt; &lt;dubbo.version&gt;2.6.2&lt;/dubbo.version&gt; &lt;!--spring boot所需依赖--&gt; &lt;mybatis.starter.version&gt;1.3.2&lt;/mybatis.starter.version&gt; &lt;pagehelper.starter.version&gt;1.2.3&lt;/pagehelper.starter.version&gt; &lt;druid.starter.version&gt;1.1.0&lt;/druid.starter.version&gt; &lt;spring.data.version&gt;1.8.10.RELEASE&lt;/spring.data.version&gt; &lt;/properties&gt;并定义依赖：12345678910111213141516&lt;dependencyManagement&gt; &lt;!--定义全局公用的一些依赖，此处只定义依赖而不引入--&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;1.5.10.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;$&#123;mybatis.starter.version&#125;&lt;/version&gt; &lt;/dependency&gt;&lt;dependencyManagement&gt;则在子模块中，可以直接引入，无需定义依赖：1234&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt;dubbo引入123456&lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;0.1.1&lt;/version&gt; &lt;/dependency&gt;注意的是：只有0.1.x的版本是支持spring boot 1.5.x，0.2.x用于spring boot 2.x。dubbo生产者配置1234567891011121314dubbo.application.id = provider_paydubbo.application.name = provider_paydubbo.application.qos.port=22232dubbo.application.qos.enable=truedubbo.protocol.id = dubbodubbo.protocol.name = dubbodubbo.protocol.port = 20882dubbo.protocol.status = server//注册中心地址dubbo.registry.address = zookeeper://127.0.0.1:2181//dubbo扫描的包含@Reference注解或者@Service的包dubbo.scan.basePackages = com.tubitu.servicedubbo.provider.version=1.0.0业务类代码编写方式与使用spring一致，区别在于@Service注解是由Dubbo提供。启动类：123456789@MapperScan("com.tubitu.mapper")@SpringBootApplication@EnableTransactionManagement@EnableAspectJAutoProxypublic class ProviderUserApplication &#123; public static void main(String[] args) &#123; new SpringApplicationBuilder(ProviderUserApplication.class).web(false).run(args); &#125;&#125;dubbo消费者配置123456789101112131415## Dubbo 服务消费者配置dubbo.application.id = consumer_platformdubbo.application.name = consumer_platformdubbo.application.qos.port=22234dubbo.application.qos.enable=truedubbo.protocol.id = dubbodubbo.protocol.name = dubbodubbo.protocol.port = 20880dubbo.consumer.version=1.0.0//调用方全局定义超市时间dubbo.consumer.timeout=60000dubbo.registry.address = zookeeper://127.0.0.1:2181## 启动时检测提供者是否存在dubbo.consumer.check=falsedubbo.registry.check=false事务配置启用事务需要使用cglib的方式实现aop代理：spring.aop.proxy-target-class=true并在启动类上加上如下两个注解：@EnableTransactionManagement@EnableAspectJAutoProxy在实现类上加上注解：@Transactional(rollbackFor = Exception.class)调用方式使用dubbo的@Reference注解，可以对某个Reference配置版本号和超时时间，来达到灰度发布的效果。一点补充启动脚本1234567891011121314151617181920212223//1、启动脚本vim start.sh:nohup java -jar app.jar &gt;&gt; logs/tubitu.out &amp;//或者touch start.shecho "nohup java -jar app.jar &gt;&gt; logs/tubitu.out &amp;" &gt;&gt; start.sh//2、停止脚本vim stop.sh;PID=$(ps -ef | grep app.jar | grep -v grep | awk '&#123;print $2&#125;')if [ -z "$PID"]thenecho Application has already stoppedelseecho kill $PIDkill -9 $PIDfi//3、自动化脚本echo stop applicationsource stop.shecho start applicationsource start.sh项目目录下出现重复jar包的解决问题：Multiple bindings were found on the class path解决：12345678910111213141516171819&lt;dependency&gt; &lt;groupId&gt;tubitu_project&lt;/groupId&gt; &lt;artifactId&gt;tubitu_util&lt;/artifactId&gt; &lt;version&gt;$&#123;tubitu.version&#125;&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-simple&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;哪个jar包有多个，就将jar包的groupID和artifactID填入exclusion标签即可。]]></content>
      <categories>
        <category>编程技术</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>随记</tag>
        <tag>Maven</tag>
        <tag>分布式</tag>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 支付宝/微信支付]]></title>
    <url>%2FJava-%E6%94%AF%E4%BB%98%E5%AE%9D-%E5%BE%AE%E4%BF%A1%E6%94%AF%E4%BB%98.html</url>
    <content type="text"><![CDATA[描述接入支付宝和微信支付详情参阅官网，需要注意的是支付宝支付可以使用开发环境进行测试，但是微信支付是不可以的。官网传送门：支付宝支付微信支付设计思路使用策略+工厂方法模式，工厂方法用于创建不同场景下的策略，本文中即创建不同商户的支付策略，具体的策略实现类有其不同的算法逻辑。类图如下：策略接口IPayStrategy定义了需要子类实现的方法 ，每一种支付方式即为支付策略，场景类通过枚举类获取策略类型，通过PayFactory创建场景类需要的支付策略，工厂方法可以创建默认商户的支付策略，也可以在工厂方法里再写一个使用指定商户id或第三方支付的沙箱环境的方法 ，payBaseModel为一些业务参数，例如标题，描述，回调接口以及支付完的跳转页面等。代码准备工作核心包：12345678910111213141516171819202122232425262728293031&lt;dependency&gt; &lt;groupId&gt;com.alipay.sdk&lt;/groupId&gt; &lt;artifactId&gt;alipay-sdk-java&lt;/artifactId&gt; &lt;version&gt;3.0.52.ALL&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.wxpay.sdk&lt;/groupId&gt; &lt;artifactId&gt;wxpay-sdk&lt;/artifactId&gt; &lt;version&gt;3.0.9&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;version&gt;4.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;version&gt;3.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;version&gt;3.3.1&lt;/version&gt; &lt;/dependency&gt;注意：由于微信最新的支付sdk在maven仓库里已经没有，合并为了weixin-java-tools里的一个模块，详见https://gitee.com/binary/weixin-java-tools。本文所使用的微信支付sdk是官网下载后自己编译的。策略接口12345public interface IPayStrategy &#123; public Map&lt;String,String&gt; excutePayOrder(PayBaseModel model) throws Exception; &#125;业务参数12345678910111213141516171819202122232425262728293031323334353637383940public class PayBaseModel implements Serializable &#123; private static final long serialVersionUID = 1L; //商品标题 private String title; //商品描述 private String desc; //回调地址 private String notifyUrl; //交易金额 private String tradeMoney; //商户订单号 private String outTradeNo; //自定义参数 private String attach; //网页支付完成后的跳转地址 private String returnUrl; //用户ip private String realIp; //请求头 private String referer; ... ... //get set方法自己实现 也可以不用实现，因为构造函数里传入了 public PayBaseModel(String title, String notifyUrl, String tradeMoney, String outTradeNo, String returnUrl) &#123; this.title = title; this.notifyUrl = notifyUrl; this.tradeMoney = tradeMoney; this.outTradeNo = outTradeNo; this.returnUrl = returnUrl; &#125; public PayBaseModel(String title, String notifyUrl, String tradeMoney, String outTradeNo) &#123; this.title = title; this.notifyUrl = notifyUrl; this.tradeMoney = tradeMoney; this.outTradeNo = outTradeNo; &#125;&#125;支付策略实现支付宝APP支付：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/** * @Author: 刘会俊 * @Date: 2018/8/30 14:28 * @Description: 支付宝app支付实现类 */public class AliAppPayStrategy implements IPayStrategy &#123; private String url; private String appId; private String privateKey; private String publicKey; private int orderTimeOUt; private final static Logger LOGGER = LoggerFactory.getLogger(AliAppPayStrategy.class); public AliAppPayStrategy(String url, String appId, String privateKey, String publicKey, int orderTimeOUt) &#123; this.url = url; this.appId = appId; this.privateKey = privateKey; this.publicKey = publicKey; this.orderTimeOUt = orderTimeOUt; &#125; @Override public Map&lt;String, String&gt; excutePayOrder(PayBaseModel payBaseModel) throws AlipayApiException &#123; LOGGER.info("**********************获取支付宝APP支付模板" + payBaseModel.toString() + "**************************************************"); Map&lt;String, String&gt; resultMap = new HashMap&lt;&gt;(); //支付的核心请求 AlipayTradeAppPayRequest payRequest = new AlipayTradeAppPayRequest(); AlipayTradeAppPayModel model = new AlipayTradeAppPayModel(); //组装必填参数：订单标题 商家交易订单号 交易金额 model.setSubject(payBaseModel.getTitle()); model.setOutTradeNo(payBaseModel.getOutTradeNo()); if (!StringUtils.isEmpty(payBaseModel.getDesc())) &#123; //交易详情 model.setBody(payBaseModel.getDesc()); &#125; model.setTotalAmount(new DecimalFormat("0.00").format(new BigDecimal(payBaseModel.getTradeMoney()))); if (!StringUtils.isEmpty(payBaseModel.getAttach())) &#123; //自定义参数 model.setPassbackParams(payBaseModel.getAttach()); &#125; //非必填参数 订单过期时间 model.setTimeoutExpress(this.orderTimeOUt + "m"); //app支付交易码-固定值 model.setProductCode("QUICK_MSECURITY_PAY"); //回调通知 payRequest.setNotifyUrl(payBaseModel.getNotifyUrl()); //业务参数模板 payRequest.setBizModel(model); AlipayClient alipayClient = new DefaultAlipayClient(this.url, this.appId, this.privateKey, PayConstant.ALI_DEFAULT_FORMAT, PayConstant.DEFAULT_CHARSET, this.publicKey, PayConstant.ALI_DEFAULT_SIGNTYPE); AlipayResponse response = alipayClient.sdkExecute(payRequest); resultMap.put("payContent", response.getBody()); resultMap.put("out_trade_no", payBaseModel.getOutTradeNo()); LOGGER.info("**********************阿里支付下单接口返回数据:" + resultMap + "**************************************************"); return resultMap; &#125;&#125;支付宝网页H5支付：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * @Author: 刘会俊 * @Date: 2018/8/30 15:03 * @Description: 支付宝网页支付 */public class AliWebPayStrategy implements IPayStrategy &#123; private String url; private String appId; private String privateKey; private String publicKey; private int orderTimeOut; public AliWebPayStrategy(String url, String appId, String privateKey, String publicKey, int orderTimeOUt) &#123; this.url = url; this.appId = appId; this.privateKey = privateKey; this.publicKey = publicKey; this.orderTimeOut = orderTimeOUt; &#125; @Override public Map&lt;String, String&gt; excutePayOrder(PayBaseModel payBaseModel) throws AlipayApiException &#123; Map&lt;String,String&gt; resultMap = new HashMap&lt;&gt;(); //创建API对应的request AlipayTradeWapPayRequest alipayRequest = new AlipayTradeWapPayRequest(); //支付完成阿里回跳转到该页面 alipayRequest.setReturnUrl(payBaseModel.getReturnUrl()); //判断传入的地址是否为http或者https开头 支付结果通知接口 alipayRequest.setNotifyUrl(payBaseModel.getNotifyUrl()); JSONObject json = new JSONObject(); json.put("out_trade_no", payBaseModel.getOutTradeNo()); json.put("total_amount", new DecimalFormat("0.00").format(new BigDecimal(payBaseModel.getTradeMoney()))); json.put("subject", payBaseModel.getTitle()); json.put("passback_params", payBaseModel.getAttach()); json.put("product_code", "QUICK_WAP_PAY"); json.put("timeout_express",this.orderTimeOut+""); //填充业务参数 alipayRequest.setBizContent(json.toJSONString()); String form = ""; AlipayClient alipayClient = new DefaultAlipayClient(this.url, this.appId,this.privateKey, PayConstant.ALI_DEFAULT_FORMAT, PayConstant.DEFAULT_CHARSET, this.publicKey, PayConstant.ALI_DEFAULT_SIGNTYPE); //调用SDK生成表单 form = alipayClient.pageExecute(alipayRequest).getBody(); resultMap.put("form",form); return resultMap; &#125;&#125;微信APP支付：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596/** * @Author: 刘会俊 * @Date: 2018/8/30 15:02 * @Description: 微信app支付 */public class WxAppPayStrategy implements IPayStrategy &#123; private String url; private String appId; private String mchId; private String appKey; private String partnerId; private int orderTimeOut; public WxAppPayStrategy(String url, String appId, String mchId, String appKey, String partnerId, int orderTimeOut) &#123; this.url = url; this.appId = appId; this.mchId = mchId; this.appKey = appKey; this.partnerId = partnerId; this.orderTimeOut = orderTimeOut; &#125; private final static Logger LOGGER = LoggerFactory.getLogger(WxAppPayStrategy.class); @Override public Map&lt;String, String&gt; excutePayOrder(PayBaseModel payBaseModel) &#123; LOGGER.info("**********************获取微信APP支付模板" + payBaseModel.toString() + "**************************************************"); Map&lt;String, String&gt; resultMap = null; //返回结果 resultMap = new HashMap&lt;&gt;(); /* 1 拼接参数向微信请求，获取prepare_id */ Map&lt;String, String&gt; paramMap = new HashMap&lt;&gt;(); paramMap.put("appid", this.appId); paramMap.put("body", payBaseModel.getTitle()); paramMap.put("mch_id", this.mchId); //后面返回给app时的nonceStr需要与这里的一致 String nonceStr = WXPayUtil.generateNonceStr(); paramMap.put("nonce_str", nonceStr); paramMap.put("sign_type", WXPayConstants.MD5); if (!StringUtils.isEmpty(payBaseModel.getAttach())) &#123; paramMap.put("attach", payBaseModel.getAttach()); &#125; paramMap.put("out_trade_no", payBaseModel.getOutTradeNo()); //微信支付必须乘以100 paramMap.put("total_fee", new BigDecimal(payBaseModel.getTradeMoney()).multiply(new BigDecimal("100")).intValue() + ""); //获取用户真实ip paramMap.put("spbill_create_ip", payBaseModel.getRealIp()); Date currDate = new Date(); //订单生成时间 paramMap.put("time_start", DateUtil.formatDate(currDate, "yyyyMMddHHmmss")); //订单失效时间 paramMap.put("time_expire", DateUtil.formatDate(DateUtil.addDate(currDate, Calendar.MINUTE, this.orderTimeOut), "yyyyMMddHHmmss")); //异步回调 paramMap.put("notify_url", payBaseModel.getNotifyUrl()); //支付类型 //app支付 paramMap.put("trade_type", "APP"); try &#123; paramMap.put("sign", WXPayUtil.generateSignature(paramMap, this.appKey, WXPayConstants.SignType.MD5)); LOGGER.info("**********************微信支付参数集合:" + paramMap + "**************************************************"); String xmlString = WXPayUtil.mapToXml(paramMap); String entityString = PayUtil.post(this.url,xmlString,ContentTypeEnum.TextXml.getContentType()); LOGGER.info("**********************微信支付统一下单接口返回数据:" + entityString + "**************************************************"); Map&lt;String, String&gt; wxXmlMap = WXPayUtil.xmlToMap(entityString); /* 2 此处组装返回给前端的参数集合 */ //组装返回给前端的数据 //app支付 服务端返回App所需数据 resultMap.put("appid", this.appId); resultMap.put("noncestr", nonceStr); resultMap.put("partnerid", this.partnerId); resultMap.put("prepayid", wxXmlMap.get("prepay_id")); //官方暂时规定为固定值 resultMap.put("package", "Sign=WXPay"); resultMap.put("timestamp", System.currentTimeMillis() / 1000 + ""); //再次生成签名 resultMap.put("sign", WXPayUtil.generateSignature(resultMap, this.appKey, WXPayConstants.SignType.MD5)); resultMap.put("out_trade_no", payBaseModel.getOutTradeNo()); &#125; catch (Exception e) &#123; LOGGER.error("\n********************请求微信统一下单接口异常********************",e); &#125; return resultMap; &#125;&#125;微信网页支付：包括微信公众号内跳转支付（或者小程序支付）、微信外H5页面跳转支付，由于微信小程序支付的请求逻辑和公众号内支付基本一致，唯一不同的就是appid和appSecret不同(appSecret用于公众号内和小程序内或者用户的openId，即使同一商家，公众号和小程序的appID和appSecret也不一致，而由此获得的同一个用户的openID也不一致），因此可以和公众号内使用相同的逻辑。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798/** * @Author: 刘会俊 * @Date: 2018/8/30 15:04 * @Description: 微信网页支付 */public class WxWebPayStrategy implements IPayStrategy &#123; private String url; private String appId; private String mchId; private String appKey; private String openId; private int orderTimeOut; public WxWebPayStrategy(String url, String appId, String mchId, String appKey, String openId, int orderTimeOut) &#123; this.url = url; this.appId = appId; this.mchId = mchId; this.appKey = appKey; this.openId = openId; this.orderTimeOut = orderTimeOut; &#125; private final static Logger LOGGER = LoggerFactory.getLogger(WxWebPayStrategy.class); @Override public Map&lt;String, String&gt; excutePayOrder(PayBaseModel payBaseModel) &#123; LOGGER.debug("\n********************微信网页支付参数\n" + payBaseModel.toString() + "\n********************"); Map&lt;String, String&gt; resultMap = new HashMap&lt;&gt;(); Map&lt;String, String&gt; preParamMap = new HashMap&lt;&gt;(); String nonceStr = WXPayUtil.generateNonceStr(); preParamMap.put("appid", this.appId); preParamMap.put("mch_id", this.mchId); preParamMap.put("nonce_str", nonceStr); preParamMap.put("body", payBaseModel.getTitle()); preParamMap.put("out_trade_no", payBaseModel.getOutTradeNo()); Date currDate = new Date(); //订单生成时间 preParamMap.put("time_start", DateUtil.formatDate(currDate, "yyyyMMddHHmmss")); //订单失效时间 preParamMap.put("time_expire", DateUtil.formatDate(DateUtil.addDate(currDate, Calendar.MINUTE, this.orderTimeOut), "yyyyMMddHHmmss")); preParamMap.put("total_fee", new BigDecimal(payBaseModel.getTradeMoney()).multiply(new BigDecimal("100")).intValue() + ""); preParamMap.put("spbill_create_ip", payBaseModel.getRealIp()); LOGGER.debug("************************spbill_create_ip" + preParamMap.get("spbill_create_ip") + "************************************"); preParamMap.put("notify_url", payBaseModel.getNotifyUrl()); if (StringUtils.isNotEmpty(payBaseModel.getAttach())) &#123; preParamMap.put("attach", payBaseModel.getAttach()); &#125; if (StringUtils.isNotEmpty(this.openId)) &#123; //公众号支付 或者 小程序 preParamMap.put("openid", this.openId); preParamMap.put("trade_type", "JSAPI"); &#125; else &#123; //h5 页面支付 preParamMap.put("trade_type", "MWEB"); //需要注意的是H5 页面支付微信需要下面的场景信息，在最终页面提交支付请求的时候拿此处的referer里的数据与提交状态比对 preParamMap.put("scene_info", "&#123;\"h5_info\": &#123;\"type\":\"Wap\",\"wap_url\": " + payBaseModel.getReferer() + "," + "\"wap_name\":" + " " + "\"兔比兔\"&#125;&#125;"); &#125; try &#123; preParamMap.put("sign", WXPayUtil.generateSignature(preParamMap, PayConstant.WX_APP_KEY)); String entityString = PayUtil.post(this.url, WXPayUtil.mapToXml(preParamMap), ContentTypeEnum.TextXml .getContentType()); Map&lt;String, String&gt; wxXmlMap = WXPayUtil.xmlToMap(entityString); /* 2 此处组装返回给前端的参数集合 */ LOGGER.debug("**********************微信支付统一下单接口返回数据:" + wxXmlMap + "**************************************************"); if (StringUtils.isEmpty(this.openId)) &#123; String mwebUrl = wxXmlMap.get("mweb_url") + "&amp;redirect_url=" + URLEncoder.encode(payBaseModel.getReturnUrl(), PayConstant.DEFAULT_CHARSET); LOGGER.debug("***************** mweb_url = " + mwebUrl + " ************************************************"); wxXmlMap.put("mweb_url", mwebUrl); resultMap.putAll(wxXmlMap); resultMap.put("code", 100000 + ""); &#125; else &#123; resultMap.put("appId", this.appId); resultMap.put("timeStamp", System.currentTimeMillis() / 1000 + ""); resultMap.put("nonceStr", nonceStr); resultMap.put("package", "prepay_id=" + wxXmlMap.get("prepay_id")); resultMap.put("signType", WXPayConstants.MD5); resultMap.put("paySign", WXPayUtil.generateSignature(resultMap, this.appKey)); resultMap.put("code", 100000 + ""); &#125; &#125; catch (Exception e) &#123; LOGGER.error("\n********************请求微信统一下单接口异常********************",e); &#125; return resultMap; &#125;&#125;相关工具类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public final class PayUtil &#123; public static String post(String url, String stringEntity, String ContentType)&#123; String result = ""; CloseableHttpClient httpClient = HttpClients.createDefault(); CloseableHttpResponse response = null; try &#123; HttpPost httpPost = new HttpPost(url); RequestConfig requestConfig = RequestConfig.custom().setSocketTimeout(8000).setConnectTimeout(6000).build(); httpPost.setConfig(requestConfig); StringEntity entity = new StringEntity(stringEntity, PayConstant.DEFAULT_CHARSET); httpPost.addHeader("Content-Type", ContentType); httpPost.addHeader("User-Agent", "Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1;SV1)"); httpPost.setEntity(entity); response = httpClient.execute(httpPost); //读取响应体转化为字符串 建议：确定目标地址发出有限长度的响应时，使用该方法 HttpEntity responseEntiry = response.getEntity(); //不然使用流的方式好些 /* if (entity != null) &#123; InputStream inputStream = entity.getContent(); BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(inputStream)); String line = ""; while ((line = bufferedReader.readLine()) != null) &#123; System.out.println(line); &#125; &#125;*/ result = EntityUtils.toString(responseEntiry, PayConstant.DEFAULT_CHARSET); &#125; catch (IOException e) &#123; LOGGER.error("\n******************http post error**********************",e); &#125; finally &#123; try &#123; httpClient.close(); response.close(); &#125; catch (IOException e) &#123; LOGGER.error("\n********************close httpclient/response error********************",e); &#125; &#125; return result; &#125; /** * @Author: 刘会俊 * @Description: 获取用户真实IP * @Params [request] * @Return java.lang.String */ public static String getIpAddr(HttpServletRequest request) &#123; String ip = request.getHeader("x-forwarded-for"); if (ip == null || ip.length() == 0 || " unknown ".equalsIgnoreCase(ip)) &#123; ip = request.getHeader("Proxy-Client-IP"); &#125; if (ip == null || ip.length() == 0 || " unknown ".equalsIgnoreCase(ip)) &#123; ip = request.getHeader("WL-Proxy-Client-IP"); &#125; if (ip == null || ip.length() == 0 || "unknown".equalsIgnoreCase(ip)) &#123; ip = request.getRemoteAddr(); &#125; if (ip == null || ip.length() == 0 || "unknown".equalsIgnoreCase(ip)) &#123; ip = request.getHeader("X-Real-Ip"); &#125; if (ip == null || ip.length() == 0 || "unknown".equalsIgnoreCase(ip)) &#123; ip = request.getRemoteAddr(); &#125; if (ip.contains(",")) &#123; ip = ip.split(",")[0]; &#125; return ip; &#125;&#125;策略枚举12345678910111213public enum PayAlgorithm &#123; //支付宝客户端 ALI_APP, //支付宝页面端 ALI_WEB, //微信客户端 WX_APP, //微信页面端 WX_WEB, //微信小程序 WX_XCX; &#125;策略工厂工厂创建策略时，需要传入策略所需的一些配置参数，本文中商户只有一个，因此只有一个创建默认商户的支付策略。1234567891011121314151617181920212223242526272829303132333435363738394041/** * @Author: 刘会俊 * @Date: 2018/8/31 14:13 * @Description: 支付工厂类 可以创建兔比兔默认支付客户端，也可以创建自定义账户客户端 */public class PayFactory &#123; /** *@Author: 刘会俊 *@Description: 创建默认支付客户端 *@Params [algorithm] *@Return com.tubitu.util.pay.IPayStrategy */ public static IPayStrategy createDefaultTubituStrategy(PayAlgorithm algorithm, String openId)&#123; IPayStrategy iPayStrategy = null; switch (algorithm)&#123; case ALI_APP: iPayStrategy = new AliAppPayStrategy(PayConstant.ALI_ORDER_URL,PayConstant.ALI_APP_ID,PayConstant .ALI_PRIVATE_KEY,PayConstant.ALI_PUBLIC_KEY,30); break; case ALI_WEB: iPayStrategy = new AliWebPayStrategy(PayConstant.ALI_ORDER_URL,PayConstant.ALI_APP_ID,PayConstant .ALI_PRIVATE_KEY,PayConstant.ALI_PUBLIC_KEY,30); break; case WX_APP: iPayStrategy = new WxAppPayStrategy(PayConstant.WX_UNIFIEDORDER_URL,PayConstant.WX_APP_ID, PayConstant.WX_MCH_ID,PayConstant.WX_APP_KEY,PayConstant.WX_PARTNER_ID,30); break; case WX_WEB: iPayStrategy = new WxWebPayStrategy(PayConstant.WX_UNIFIEDORDER_URL,PayConstant.WX_H5_APPID, PayConstant.WX_H5_MCHID,PayConstant.WX_APP_KEY,openId,30); break; case WX_XCX: iPayStrategy = new WxWebPayStrategy(PayConstant.WX_UNIFIEDORDER_URL,PayConstant.WX_XCX_APPID, PayConstant.WX_H5_MCHID,PayConstant.WX_APP_KEY,openId,30); break; &#125; return iPayStrategy; &#125; &#125;调用方式123IPayStrategy strategy = PayFactory.createDefaultTubituStrategy(PayAlgorithm.WX_WEB,"");PayBaseModel payBaseModel = new PayBaseModel(商品描述,回调接口,交易金额,商户订单编号,支付完跳转页面);Map&lt;String,String&gt; resultMap = strategy.excutePayOrder(payBaseModel);前端js这是从前端那里偷过来的公众号内支付js，之所以记录是因为H5页面的支付和小程序的支付官方都提供了案例，而且只有一种调用方式。但是公众号内支付有两种调用方式。第一种：调用微信浏览器的js-api：1234567891011121314151617181920212223242526272829function onBridgeReady()&#123; WeixinJSBridge.invoke( 'getBrandWCPayRequest', &#123; "appId":"wx2421b1c4370ec43b", //公众号名称，由商户传入 "timeStamp":"1395712654", //时间戳，自1970年以来的秒数 "nonceStr":"e61463f8efa94090b1f366cccfbbb444", //随机串 "package":"prepay_id=u802345jgfjsdfgsdg888", "signType":"MD5", //微信签名方式： "paySign":"70EA570631E4BB79628FBCA90534C63FF7FADD89" //微信签名 &#125;, function(res)&#123; if(res.err_msg == "get_brand_wcpay_request:ok" )&#123; // 使用以上方式判断前端返回,微信团队郑重提示： //res.err_msg将在用户支付成功后返回ok，但并不保证它绝对可靠。 //此处可看作支付可能成功，跳转到成功页面 window.location.replace("index.html"); &#125; &#125;); &#125;if (typeof WeixinJSBridge == "undefined")&#123; if( document.addEventListener )&#123; document.addEventListener('WeixinJSBridgeReady', onBridgeReady, false); &#125;else if (document.attachEvent)&#123; document.attachEvent('WeixinJSBridgeReady', onBridgeReady); document.attachEvent('onWeixinJSBridgeReady', onBridgeReady); &#125;&#125;else&#123; onBridgeReady();&#125;第二种：先引入http：//res.wx.qq.com/js/jwexin-1.2.0.js，然后代码如下：1234567891011121314151617181920212223242526272829303132wx.config(&#123; debug: true, // 开启调试模式,调用的所有api的返回值会在客户端alert出来，若要查看传入的参数，可以在pc端打开，参数信息会通过log打出，仅在pc端时才会打印。 appId: '', // 必填，企业号的唯一标识，此处填写企业号corpid timestamp: , // 必填，生成签名的时间戳 nonceStr: '', // 必填，生成签名的随机串 signature: '',// 必填，签名，见附录1 jsApiList: [] // 必填，需要使用的JS接口列表，所有JS接口列表见附录2&#125;);wx.ready(function()&#123; // config信息验证后会执行ready方法，所有接口调用都必须在config接口获得结果之后，config是一个客户端的异步操作，所以如果需要在页面加载时就调用相关接口，则须把相关接口放在ready函数中调用来确保正确执行。对于用户触发时才调用的接口，则可以直接调用，不需要放在ready函数中。&#125;);wx.chooseWXPay(&#123; appId: 'wx23841cce7185b550', timestamp: '1461300911', // 支付签名时间戳，注意微信jssdk中的所有使用timestamp字段均为小写。但最新版的支付后台生成签名使用的timeStamp字段名需大写其中的S字符 nonceStr: '5719aeafb587f', // 支付签名随机串，不长于 32 位 package: 'prepay_id=wx20160422125512b7d2205c9c0913643939', // 统一支付接口返回的prepay_id参数值，提交格式如：prepay_id=***） signType: 'MD5', // 签名方式，默认为'SHA1'，使用新版支付需传入'MD5' paySign: '5DAB1DDABE1AD34E8FF3386AE971B727', // 支付签名 success: function(res) &#123; // 支付成功后的回调函数 if (res.errMsg == "chooseWXPay:ok") &#123; //支付成功 alert('支付成功'); else &#123; alert(res.errMsg); &#125; &#125;, cancel: function(res) &#123; //支付取消 alert('支付取消'); &#125; &#125;);注意：实际过程中前端发现，即使是调用jsapi的方式，也需要引入js-sdk的那个js。具体原因暂时未知，官方文档也没有提到。第二种方式里的signature的获取也并不复杂：获取AccessToken获取jsapi_ticket生成signature下面提供一种解决方案参考：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** * 获取微信token * @returnP */ public static String getAccessToken()&#123; //获取token String tokenParam = "grant_type=client_credential&amp;appid=" + WxPayConfig.APPID + "&amp;secret=" + WxPayConfig.APPSECRET; //这一步的发送请求工具类请自己实现 String tokenJsonStr = HttpUtil.sendGET("https://api.weixin.qq.com/cgi-bin/token", tokenParam); Map&lt;String,String&gt; tokenMap = JSONObject.fromObject(tokenJsonStr); System.out.println(tokenMap); // 获取access_token String access_token = (String) tokenMap.get("access_token"); return access_token; &#125; //获取jsapi_ticket public static String getJsApiTicket(String accessToken)&#123; String ticketParam = "access_token=" + accessToken + "&amp;type=jsapi"; String ticketJsonStr = HttpUtil.sendGET("https://api.weixin.qq.com/cgi-bin/ticket/getticket", ticketParam); Map&lt;String,String&gt; ticketMap = JSONObject.fromObject(ticketJsonStr); // 获取jsapi_ticket String ticket = (String) ticketMap.get("ticket"); return ticket; &#125; //生成signature String url = PayConstant.PAY_DOMAIN;//微信授权的网址 这个要看微信公众号设置 String signValue = "jsapi_ticket=" + ticket + "&amp;noncestr=" + noncestr + "×tamp=" + timestamp + "&amp;url=" + url; String signature = Sha1Util.getSha1((signValue)) public static String getSha1(String str) &#123; if (str == null || str.length() == 0) &#123; return null; &#125; char hexDigits[] = &#123;'0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f'&#125;; try &#123; MessageDigest mdTemp = MessageDigest.getInstance("SHA1"); mdTemp.update(str.getBytes("GBK")); byte[] md = mdTemp.digest(); int j = md.length; char buf[] = new char[j * 2]; int k = 0; for (int i = 0; i &lt; j; i++) &#123; byte byte0 = md[i]; buf[k++] = hexDigits[byte0 &gt;&gt;&gt; 4 &amp; 0xf]; buf[k++] = hexDigits[byte0 &amp; 0xf]; &#125; return new String(buf); &#125; catch (Exception e) &#123; return null; &#125; &#125;回调函数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/** * @description: 处理微信回调请求 * @author: 刘会俊 * @params: [request] * @return: java.util.Map */ public static Map&lt;String, String&gt; resolveWXPayResponse(HttpServletRequest request, String appkey) throws Exception &#123; LOGGER.info("***************************************处理微信回调request域********************************************"); ByteArrayOutputStream outSteam = new ByteArrayOutputStream(); InputStream inStream = request.getInputStream(); byte[] buffer = new byte[1024]; int len = 0; while ((len = inStream.read(buffer)) != -1) &#123; outSteam.write(buffer, 0, len); &#125; outSteam.close(); inStream.close(); String result = new String(outSteam.toByteArray(), PayConstant.DEFAULT_CHARSET); LOGGER.info("***************************************微信返回结果" + result + "********************************************"); Map&lt;String, String&gt; resultMap = new HashMap&lt;&gt;(); if (!StringUtils.isEmpty(result)) &#123; Map&lt;String, String&gt; map = WXPayUtil.xmlToMap(result); //验签 if (WXPayUtil.isSignatureValid(map, appkey, WXPayConstants.SignType.MD5)) &#123; String attach = map.get("attach"); LOGGER.info("***************************************微信自定义参数" + attach + "********************************************"); LOGGER.info("***************************************商户订单号 ：" + map.get("out_trade_no") + "********************************************"); resultMap = map; &#125; else &#123; resultMap.put("return_code", "FAIL"); resultMap.put("return_msg", "验签失败"); &#125; &#125; return resultMap; &#125; /** * @Author: 刘会俊 * @Description: 处理支付宝回调请求 * @Date 2018/7/5 * @Params [request] * @Return java.util.Map */ public static Map&lt;String, String&gt; resolveAliPayResponse(HttpServletRequest request) throws UnsupportedEncodingException, AlipayApiException &#123; Map&lt;String, String&gt; result = new HashMap(); LOGGER.info("***************************************处理支付宝回调request域********************************************"); //1.从支付宝回调的request域中取值 Map&lt;String, String[]&gt; requestParams = request.getParameterMap(); for (Iterator&lt;String&gt; iter = requestParams.keySet().iterator(); iter.hasNext(); ) &#123; String name = iter.next(); String[] values = requestParams.get(name); String valueStr = ""; for (int i = 0; i &lt; values.length; i++) &#123; valueStr = (i == values.length - 1) ? valueStr + values[i] : valueStr + values[i] + ","; &#125; result.put(name, valueStr); &#125; //2.签名验证(对支付宝返回的数据验证，确定是支付宝返回的) boolean signVerified; //2.1调用SDK验证签名 signVerified = AlipaySignature.rsaCheckV1(result, PayConstant.ALI_PUBLIC_KEY, PayConstant.DEFAULT_CHARSET, PayConstant.ALI_DEFAULT_SIGNTYPE); if (signVerified) &#123; return result; &#125; return null; &#125;注意：由于设置redirect_url后,回跳指定页面的操作可能发生在：1,微信支付中间页调起微信收银台后超过5秒 2,用户点击“取消支付“或支付完成后点“完成”按钮。因此无法保证页面回跳时，支付流程已结束，所以商户设置的redirect_url地址不能自动执行查单操作，应让用户去点击按钮触发查单操作]]></content>
      <categories>
        <category>编程技术</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo接入在线聊天daovoice]]></title>
    <url>%2Fhexo%E6%8E%A5%E5%85%A5%E5%9C%A8%E7%BA%BF%E8%81%8A%E5%A4%A9daovoice.html</url>
    <content type="text"><![CDATA[简述给hexo接入看起来很高大上的在线聊天daovoice，详情请看本博客右下角的气泡标志。接入daovoice官网传送门注册完成以后会进入到daovoice的控制面板页，选择应用设置，安装到网站：看情况而定，通常这种个人博客不需要注册，因此，直接可以选择匿名用户沟通，然后复制daovoice提供的代码：将这两份代码复制到一起，放到themes/next/layout/_partials/head.swig中，位置随意，保证是在{% endif %} 后面即可，注册用户的使用方式类似。然后到主题配置文件里，加入如下两行：daovoice: true daovoice_app_id: your appid 最后使用hexo s即可查看到效果。]]></content>
      <categories>
        <category>编程技术</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM基础-内存自动管理]]></title>
    <url>%2FJVM%E5%9F%BA%E7%A1%80-%E5%86%85%E5%AD%98%E8%87%AA%E5%8A%A8%E7%AE%A1%E7%90%86.html</url>
    <content type="text"><![CDATA[简述阅读周志明先生著《深入理解Java虚拟机》所记笔记。主要讲述虚拟机运行时区域、内存分配算法、垃圾回收算法以及虚拟机工具等基础内容。自动内存管理机制区域概述Java虚拟机管理的内存包括：方法区（Method Area）堆（Heap）虚拟机栈（VM Stack）本地方法栈（Native Method Stack）程序计数器（Program Counter Register）前两项是线程共享的的数据区，后三项是线程隔离的数据区，黑色区域是运行时数据区。方法区存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。也被称为非堆（non-heap），HotSpot虚拟机将GC分代扩展方法区，所以方法区也叫做永久代（Permanent Generation），但是实际上只是HotSpot虚拟机像管理堆一样管理方法区内存。在JDK1.7中，字符串常量池也从原来的永久代移到了堆中，而到了JDK1.8更是去除了永久带，改为了元数据空间（MetaSpace，但是本质都是方法区的一种实现），比较少出现垃圾收集的情况，当方法区无法满足内存分配时会出现OOM。堆存放对象实例，几乎所有的对象实例都在这里分配内存。但是随着JIT编译器的发展和逃逸分析技术逐渐程数，栈上分配、标量替换优化技术会让“所有对象都分配在堆上”渐渐变得不是那么绝对。堆中又划分：新生代，由Eden空间，From Surivor和To Survivor等组成；老年代；线程私有的分配缓冲区（Thread Local Allocation Buffer，TLAB）。虚拟机栈线程私有的，和线程同生共死。描述了方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。局部变量表所需内存再编译期就会完成分配，在方法运行期间不会改变，这个数据区可能会抛出oom或者StackOverFlowError。本地方法栈虚拟机栈执行的是class文件，是字节码。而本地方法栈对于所执行的对象没有强制规定语言和数据结构，是由虚拟机自己实现，对于HotSpot虚拟机来说，其做法是将本地方法栈和虚拟机栈放到一起管理，所以这个数据区可能会出现的异常同虚拟机栈。程序计数器该数据区的作用，可以简单理解 记录了执行到的代码行号。分支、循环、跳转、线程恢复、异常处理等都需要程序计数器来完成，字节码指示器就是依靠程序计数器来选去下一条字节码指令。如果线程执行的是字节码文件，那么程序计数器记录的就是虚拟机字节码执行地址；如果执行的是本地方法，那么它为空（Undefined），这是唯一一个在Java虚拟机规范中没有规定任何OOM情况的数据区域。运行时常量池曾经是方法区的一部分，存放编译器生成的各种字面量（基本类型、final类型变量、字符串）和符号引用，在类加载完后进入运行时常量池中存放，字符串常量池就是在运行时常量池之中，因为无论是类、接口还是方法中的字符串，总是在编译时就能确定的。直接内存JDK1.4引入了NIO（New Input/Output）类，提供了一种基于通道（channel）的和缓冲区（buffer）的I/O方式，它可以直接调用本地native方法分配堆外内存，然后通过在堆中建立一个DirectByteBuffer作为堆外内存的引用从而实现了直接操作堆外内存，也避免了在Java堆中和直接内存中来回复制。直接内存大小默认和堆大小相同，可以通过-XX:MaxDirectMomorySize参数指定，会出现OOM错误。HotSpot对象对象的创建new指令的执行过程：首先去运行时常量池里检查是否存在该类的符号引用，并且是否已经被加载解析和初始化过，如果没有还要先执行相对应的类加载过程。如果验证通过以后，会为一个类在堆上分配内存，分配方式根据堆的规整情况的使用不同的方法。在使用带整理过程的（compact）回收的收集器，例如Serial、ParNew等收集器，使用的就是指针碰撞法（Bump the Pointer），分配内存就是将临界点指针往空闲方向挪动与对象大小相等的距离；而CMS收集器使用的是Mark-Sweep算法的收集器通常使用空闲列表法（Free List），列表中记录了可用内存块，分配时划出足够大的内存。线程安全性保证：CAS（该指令是硬件级原子操作指令）+失败重试使用上文介绍的TLAB，可以通过-XX:+/-UseTLAB来决定是否启用，如果采用这种方式，在分配空间时就可以初始化零值，保证对象的实例字段可以不赋初始值即可使用如果使用CAS方式，接下来需要初始化零值（不包括对象头），此时一个对象已经产生，但是还需要执行方法来真正赋值。对象的内存布局Mark Word里根据虚拟机位数的不同分为32bit和64bit的非固定结构数据，以便在有限的空间存储尽可能多的信息，它会根据对象复用存储空间，其中，锁标志位为2bit，不同值存储不同信息：内容标志位状态哈希码、对象分代年龄01对象未锁定指向锁记录的指针00轻量级锁定指向重量级锁的指针10重量级锁定空11GC标记偏向线程ID，偏向时间戳，对象分代年龄01可偏向类型指针：对象指向它的类元数据，但是查找对象的类元数据不一定经过对象本身。对于数组来说，对象头中还有一块用于记录数组长度的数据。实例数据：受到虚拟机分配策略参数（FieldsAllocationStyle）和字段在Java源码中定义的顺序的影响。长度相同的数据类型会被分配到一起。对齐：HotSpot虚拟机的自动内存管理系统要求对象起始地必须是8字节的整数倍，也就是说对象必须是8字节的整数倍，对象头正好是8字节的1倍或者2倍，所以对齐通过占位保证对象大小是8字节的整数倍。对象寻址1.句柄池寻址方式栈中的reference引用了句柄池的内存地址，而该内存地址又分别指向了对象类型数据和对象实例数据。当对象的地址发生变化时，只需要改变句柄池所存储的指向地址即可，句柄本身地址不用改变.2.直接寻址相对于句柄寻址少了一次实例数据指针定位的操作，效率高一些。HotSpot虚拟机是采用这种方案。垃圾收集对象引用引用计数法：对象中有一个计数器，每当有一个地方引用该对象时就会在计数器里加1，但是解决不了循环引用的问题。可达性分析法：GC Roots做根节向下寻找，搜索过的路径称为引用链。如果一个对象没有任何的链路到达GC Roots，就判定该对象是可以回收的对象。Jvm里可作为GC Roots的对象有以下几种：虚拟机栈（栈帧中的局部变量表）方法区中类静态属性引用的对象方法区中常量引用的对象本地方法栈中Native Method引用的对象引用类型：强引用（Strong Reference）：代码中使用Object obj = new Object一类的方法；软引用（Soft Reference）：描述一些还有用但非必须的对象，内存不足时不会立即回收，而是会加入待回收列表，下一次再回收；弱引用（Weak Referenct）：描述非必须的对象，只能存活到下一次回收之前；虚引用：通过这个对象被收集器回收时收到一个系统通知。方法区回收方法区主要有废弃变量回收和无用类回收：废弃变量回收与回收堆中的基本一致无用类回收需要同时满足：堆中没有任何该类实例；加载该类的ClassLoader已经卸载；该类对象的java.lang.Class对象没有在任何地方被引用垃圾收集算法标记-清除算法（mark-sweep）：首先标记所有需要回收的对象，然后统一回收。但是两个节点的效率都不高，而且很容易产生空间碎片；复制算法（copying）：将空间分为容量相等的两块，回收只需将存活的复制到另一块上，分配时直接可以使用指针碰撞法来分配；标记-整理算法（mark-compact）：标记所有需要回收的对象，然后让所有对象往一端移动，然后直接清理掉边界以外的内存。分代思想根据对象不同的生命周期使用不同的收集算法：新生代对象生存周期短，每次收集都会有大量对象回收，只有少数对象存活，复制算法比较合适；老年代对象生存周期长，就必须使用标记清除或者标记整理算法。HotSpot算法实现枚举根节点（GC Roots Tracing）：可以作为GC Roots的节点必须是在全局引用或者执行上下文中；同时执行可达性分析的前提是建立在一致性快照的前提下—-保证在进行可达性分析的情况下对象的引用情况不会发生变化（通常伴随着stop the world，即停止所有的Java线程的情况）；大多数虚拟机都采用的是准确式GC，所以无需检查所有变量和上下文。HotSpot借助OopMap的数据结构，在编译时就能知道什么偏移量上是什么数据类型；同时在JIT编译过程中，也会在safe-point中记录寄存器和栈中哪些位置是引用。安全点（safe-point）：保证程序长时间运行（特征：指令序列复用，例如方法调用，循环跳转，异常跳转）的代码段中，选定安全点，在安全点执行GC时对象的引用关系不会发生变化。抢先式中断（Preemptive Suspensuin）：GC发生时主动暂停所有线程；主动式中断（Voluntary Suspension）：GC需要中断线线程时，修改某个标志位，线程主动轮询这个标识位，发现中断标志为真时会主动中断挂起。安全区域（safe-region）：安全点的扩大版，可以理解为该区域内的对象引用关系不会变化。线程执行待安全区域代码段时，会标记自己进入safe-region，GC时可以直接回收该线程的对象，如果线程要离开safe-region，首先会检查GC是否已经完成，如果完成了会继续执行，没执行完成则会等待知道GC完成。垃圾收集器并行与并发：并行（Parallel）是指多个垃圾收集线程工作；并发（Concurrent）是指垃圾收集线程和用户线程同时工作，但是可能是交替执行。Serial新生代收集器，虚拟机client模式下默认的收集器，稳定高效，单线程，使用复制算法。Par new新生代收集器，虚拟机server模式下默认的收集器，多线程（默认与CPU数量相同），Serial的多线程版。Parallel Scavenger新生代收集器，多线程，吞吐量可控，自适应收集器。吞吐量计算：用户代码执行时间/（用户代码执行时间+垃圾收集执行时间）重要参数：-XX:MaxGCPauseMillis：停顿时长；-XX:GCTimeRatio:小于100的正整数，相当于GC时间占用户代码执行时间的倒数。例如99，则GC时间：用户代码执行时间=1:99，所以吞吐量为99/（1+99）=99%，默认也是99；-XX:+UseAdaptiveSizePolicy:开启自适应模式，能够自动根据系统运行情况收集性能监控信息，动态调整例如新生代大小（-Xmn）、Eden区域和Survivor区域比例（-XX:SurvivorRatio）、对象晋升老年代年龄（-XX:PretenureSizeThreshold）等的参数，只需要设置好最大堆内存（-Xmx），停顿时长或者吞吐量等目标即可。Serial Old老年代收集器，Serial的老年版，使用标记整理（mark-compact ）算法。Parallel OldJDK1.6出现，Parallel Scavenger的老年代版本，使用标记整理算法。拓展：关于Parallel系的垃圾收集器，在Parallel Old出现以前，实际上6.3小节中提到的Parallel Scavenger并不是指某一个收集器，而是一个完整的垃圾收集框架，由PSScavenger（新生代）+PSMark-Sweep（老年代）组成，此处虽然名称是叫标记-清除算法，实际上只是在Serial Old的基础上加了一个壳。直到Parallel Old的出现，才算一套完整的吞吐量优先收集器。-XX:+UseParallelGC实际上是PSScavenger+PSMak-Sweep-XX:+UseParallelOldGC才是PSScavenger+Parallel OldCMSConcurrent Mark Sweep，老年代收集器，使用标记清除算法，以低停顿为目标。初始标记只是标记GC Roots能直接关联的对象，并发标记会进行GC Roots Tracing，重新标记则是对用户并发执行的用户线程产生变动的对象进行记录。时间：并发标记&gt;重新标记&gt;初始标记缺点：CPU资源敏感，默认回收线程数=（CPU数+3）/4，当CPU数低于2时很不划算；浮动垃圾，即并发清除时用户线程留下来的未被清除的对象，只能等下一次GC，如果用户线程产生的对象大小大于GC预留的空间，会报“Concurrent Mode Failure”；空间碎片，由于使用标记清除算法，会导致大量空间碎片，虽然默认开启了碎片整理（-XX:+UseCMSCompactAtFullCollection），但是碎片整理是无法并发的，因此可能会延长停顿时间。重要参数：-XX:CMSFullGCsBeforeCompaction：不压缩Full GC次数，超过该次数后会进行一次压缩Full GC，默认是0，每次都会压缩。G1Garbage-First，整个堆的收集器，基于复制算法和标记整理算法，未来有可能取代CMS。G1把整个堆分成大小相等Region，Region之间通过复制算法，整体通过标记-整理算法。每个Region都会有一个Remembered Set（下文简称R Set），在对Reference类型数据进行写操作时会产生一个Write Barrier暂时中断写操作，检查Reference引用的对象是否处于两个不同的Region之间，如果是，通过CardTable把相关引用信息记录到被引用对象所属的Region的R Set中，进行内存回收时，在GC根节点的枚举范围中加入R Set即可保证不扫描整个堆也没有遗漏。收集过程大体类似于CMS的过程，区别在于最终标记阶段，这一阶段G1会将对象变动记录记录在每个标记线程的R set logs中，最后再合并到R Set里。-XX：+UseG1GC：启用G1 GC。JDK7和JDK8要求必须显示申请启动G1 GC，JDK可能会设置G1 GC为默认GC选项，也有可能会退到早期的Parallel GC，这个也请关注吧，JDK9预计2017年正式发布；-XX：G1NewSizePercent：初始年轻代占整个Java Heap的大小，默认值为5%；-XX：G1MaxNewSizePercent：最大年轻代占整个Java Heap的大小，默认值为60%；GC日志浅析[GC(MetadataGCThreshold)[PSYoungGen:22881K-&gt;5109K(71680K )]26152K-&gt;9484K(159232K),0.0126338secs][Times:user=0 .02sys=0.01,real=0.02secs] [FullGC(MetadataGCThreshold)[PSYoungGen:5109K-&gt;0K(71680K )][ParOldGen:4375K-&gt;6098K(52736K)]9484K-&gt;6098K(124416K ),[Metaspace:20679K-&gt;20679K(1067008K)],0 .0529407secs][Times:user=0.11sys=0.00,real=0.05secs] 以上信息是使用了-XX:+PrintGCDetails打印出的GC日志。IDEA里可以点击Edit Configurations，在VM Options里输入参数即可。[GC或者[Full GC 表示停顿类型，[Full GC（system）表示是由System.gc()引发的垃圾收集，Metadata表示是由元数据引发的GC，Allocation Failure表示是有新生代不足引发的GC，紧随其后的PSYoungGen表示使用的Parallel Scavenger收集的新生代，新生代和老年代的名称是根据收集器名称确定的。每个代的方括号内部的例如“22881K-&gt;5109K(71680K)”表示：“GC前该内存已使用容量-&gt;GC后该内存使用容量（该区域总容量）”，而最外层的”26152K-&gt;9484K(159232K)”则是表示整个堆。”0.0126338 secs”表示的是手机该内存区域使用的时间，单位为秒（secs），后面中括号里跟的Times则是具体时间详情，和Linux的time命令输出一致，分别代表用户态消耗的CPU时间、内核态消耗的CPU时间和操作从开始到结束的墙钟时间（Wall Clock Time）。CPU时间和墙钟时间的区别是：墙钟时间包括各种I/O，等待线程阻塞时间，而CPU时间则不包括时间，但当系统由多CPU或者多核的话，多线程操作会叠加这些时间。拓展：如果是开启或者关闭某个虚拟机选项，使用-XX:+/-，如果是赋值某个选项，使用-XX:=。内存分配与回收策略Minor GC：新生代GC，速度较快Major/Full GC：发生在老年代的GC，经常会伴随至少一次的Minor GC，但并不绝对，比Minor GC慢分配策略：其中，跟大对象阀值有关的参数有：-XX:PretenureSizeThreshold，单位为byte，新生代会优先分配在Eden区，跟使用TLAB有关的是+XX:+/-UseTLAB，TLAB在Eden区域，默认情况下占10%GC策略：重要参数：-XX:MaxTenuringThreshold=15：对象晋升年龄，每一次Minor GC以后仍然存活在Survivor区域中的对象年龄会+1-XX:HandlePromotionFailure=true：是否允许担保分配失败对象年龄并不是完全按照上面这个参数来的，它还有一个动态判定策略：如果在Survivor空间中相同年龄的对象大小之和大于Survivor空间的一般，也会晋升老年代。虚拟机工具JDK自带命令行工具JDK自带命令行工具只是jdk/lib/tools.jar的一层薄封装而已。名称作用jpsJVM Process Status Tool显示当前系统所有进程jstatJVM Statistics Monitoring Tool 收集虚拟机各方面运行数据jinfo显示虚拟机配置信息jmapMemory Map for Java 生成虚拟机的内存转储快照（heapdump文件）jhatJVM heap dump Browers 建立一个HTTP/HTML服务器方便用户分析heapdump文件jstackStack Trace for Java 显示虚拟机的线程快照jpsJVM Process Status Tool格式： jps [option]作用：通过RMI协议查询开启了RMI服务的远程虚拟机进程状态。常用options:option 作用-q 只输出LVMID，省略主类名称-l 输出主类的全名，如果进程执行的是Jar包，输出该包路径-m 输出虚拟机进程启动时传递给主类main()函数的参数-v 输出虚拟机进程启动时JVM参数hostid 为RMI注册表中注册的主机名jstatJVM Statistics Monitoring Tool格式：jstat [option vmid [interval[s|ms] [count]]]作用：监视虚拟机各种运行状态信息如果是本地虚拟机进程，那么vmid和lvmid是一致的，如果是远程虚拟机进程，那么vmid的格式为：[progocol:][//]lvmid[@hostname[:port]/servername]，interval 和count 分表代表查询间隔和次数，如果省略这两个参数代表只查询一次。常用options：选项作用-calss监视类装载、卸载数量、总空间以及类装载所耗费的时间-gc监视Java堆状况各个区容量、已用空间、GC合计时间等信息-gccapacity基本同-gc，但是更关注各个区使用到的的最大、最小空间-gcutil基本同-gc，但是输出的是已使用的百分比-gccause-gcutil基本一样，但是会额外输出导致上一次GC产生的原因-gcnew监视新生代GC状况-gcnewcapacity新生代使用到的最大最小空间-gcold监视老年代GC状况-gcoldcapacity老年代使用到的最大最小空间-compiler输出JIT编译器编译过的方法、耗时等信息-printcompilation输出已经被JIT编译的方法示例以及解析：s0表示Survivor的from区，s1表示to，E表示Eden区的已经使用量，O代表老年代，M代表MetaSpace，CCS表示压缩使用比例，YGC表示新生代回收次数，FGC表示Full GC次数，FGCT表示Full GC时间，GCT表示总的GC时间。jinfoConfiguration Info for Java格式：jinfo [option] pid作用：实时地查看和戴哦整虚拟机各项参数。选项作用-sysprops可以把System.getProperties()的内容打印出来-flagflag后面可以跟javm参数的key，这样就可以获得该key的值jmapMemory Map for Java格式：jmap [option] vmidoptions列表：选项作用-dump生成Java堆转储快照，格式为-dump:[live,]format=b,file=-finalizerinfo显示在F-Queue中等Finalizer线程执行finalize方法的对象，只在Linux/Solaris下有效-heap显示Java堆详细信息，如回收器、参数配置、分代状况等，只在Linux/Solaris下有效-histo显示堆中对象统计信息，包括类、示例数量、合计容量Minor GC：新生代GC，速度较快Major/Full GC：发生在老年代的GC，经常会伴随至少一次的Minor GC，但并不绝对，比Minor GC慢分配策略：其中，跟大对象阀值有关的参数有：-XX:PretenureSizeThreshold，单位为byte，新生代会优先分配在Eden区，跟使用TLAB有关的是+XX:+/-UseTLAB，TLAB在Eden区域，默认情况下占10%GC策略：重要参数：-XX:MaxTenuringThreshold=15：对象晋升年龄，每一次Minor GC以后仍然存活在Survivor区域中的对象年龄会+1-XX:HandlePromotionFailure=true：是否允许担保分配失败对象年龄并不是完全按照上面这个参数来的，它还有一个动态判定策略：如果在Survivor空间中相同年龄的对象大小之和大于Survivor空间的一般，也会晋升老年代。jhatJVM Heap Analysis Tool格式：jhat可以对dump出来的文件进行解析，并且会创建一个微型的HTTP/HTML服务器，可以在浏览器中查看页面，但是一般并不推荐这么做。jstackStack Trace for Java格式:jstack [option] vmidoptions:选项作用-F当正常使出的请求不被响应时，强制输出线程堆栈-l出堆栈外，显示关于锁的附加信息-m如果调用到本地方法的话，可以显示C/C++的堆栈jconsole这个工具并不是命令行工具，而是一个可视化工具，所以必须在带交互界面的系统上执行，例如Windows和Mac，位于JDK/bin目录下，也可以在命令行中直接执行jconsole。下图是在IDEA中打开某个项目的情况：VisualVM多合一故障处理工具，可以在IDEA里或者Eclips里以插件形式启动。同时它还有一个插件BTrace，这个插件可以作为程序独立运行，作用是在不停止目标程序运行的前提下，通过HotSpot VM的HostSwap技术动态加入原本不存在的调试代码。需要注意的是，如果要使用VisualVM连接远程的程序，需要在程序启动时加上以下VM参数：-Djava.rmi.server.hostname=localhost -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=1099 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false 启用jmx并且不使用ssl和用户名密码校验，并且在Visual VM里添加jmx连接才能连接远程项目。参考《深入理解Java虚拟机：JVM高级特性和最佳实践》周志明 著https://hllvm-group.iteye.com/group/topic/37095]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java输出文字到图片]]></title>
    <url>%2FJava%E8%BE%93%E5%87%BA%E6%96%87%E5%AD%97%E5%88%B0%E5%9B%BE%E7%89%87.html</url>
    <content type="text"><![CDATA[描述java 的awt工具包里是有图像类(Image)，所以可以读取图像并利用Graphics2D进行操作。但是ImageIO.read()方法读取图片时可能存在不正确处理图片ICC（ICC为JPEG图片格式中的一种头部信息）信息的问题，导致渲染图片前景色时蒙上一层红色，因此需要用JDK提供的Toolkit.getDefaultToolkit()进行操作。代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768import javax.imageio.ImageIO;import javax.swing.*;import java.awt.*;import java.awt.image.BufferedImage;import java.io.ByteArrayOutputStream;import java.io.FileOutputStream;import java.net.URL;public class PrintImageUtil &#123; public String printWordImage(String word,String imgUrl)&#123; String imgStr = ""; try &#123; URL url = new URL(imgUrl); Image src = Toolkit.getDefaultToolkit().createImage(url); BufferedImage bi = toBufferedImage(src); if(bi != null)&#123; g = bi.createGraphics(); g.setBackground(Color.WHITE); g.setColor(Color.WHITE); g.setFont(new Font("黑体",Font.ITALIC,50)); g.drawString(word,130,250); g.setFont(new Font("黑体",Font.BOLD,15)); g.drawString("兔比",130+26*word.length(),250); g.dispose(); ByteArrayOutputStream outputStream = new ByteArrayOutputStream(); ImageIO.write(bi,"png",outputStream); byte[] bytes = outputStream.toByteArray(); //该bytes数组就可以输出到文件，或者云服务器 &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return "http://img.yiqx.com/"+imgStr; &#125; public static BufferedImage toBufferedImage(Image image) &#123; if (image instanceof BufferedImage) &#123; return (BufferedImage) image; &#125; // This code ensures that all the pixels in the image are loaded image = new ImageIcon(image).getImage(); BufferedImage bimage = null; GraphicsEnvironment ge = GraphicsEnvironment .getLocalGraphicsEnvironment(); try &#123; int transparency = Transparency.OPAQUE; GraphicsDevice gs = ge.getDefaultScreenDevice(); GraphicsConfiguration gc = gs.getDefaultConfiguration(); bimage = gc.createCompatibleImage(image.getWidth(null), image.getHeight(null), transparency); &#125; catch (HeadlessException e) &#123; // The system does not have a screen &#125; if (bimage == null) &#123; // Create a buffered image using the default color model int type = BufferedImage.TYPE_INT_RGB; bimage = new BufferedImage(image.getWidth(null), image.getHeight(null), type); &#125; // Copy image to buffered image Graphics g = bimage.createGraphics(); // Paint the image onto the buffered image g.drawImage(image, 0, 0, null); g.dispose(); return bimage; &#125;&#125;一些问题当代码打包上传到Linux服务器的时候，某些字体就无法使用了，所以需要到Winsows下找到对应的字体，最笨的办法就是复制所有的字体，上传到Linux服务器。服务器路径为/usr/java/jdk1.8.0_161/jre/lib/fonts(添加jdk支持的字体)/或者/usr/share/fonts/（添加系统字体）。]]></content>
      <categories>
        <category>编程技术</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>随记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring AOP随记]]></title>
    <url>%2FSpring-AOP%E9%9A%8F%E8%AE%B0.html</url>
    <content type="text"><![CDATA[简述最近看到公司业务代码执行的时候有这么两句：1234long startTime = System.currentMilles(); ...long endTime = System.currentMilles();LOGGER.info("执行时长&#123;&#125;",endTime-startTime);每个service层代码几乎都有这么两句，实在是臃肿。AOPAOP是对OOP的一种补充，如果说OOP将万事万物都看作对象之间的关系的话，从上到下，例如餐具-盘子-瓷盘，那么AOP定义这种纵向关系之间的一种横向行为，例如盘子可以盛放菜肴，这也可以说是他们的公共行为，而不同材质的盘子适合盛放什么类型的食物或者适合做观赏性的盘子就可以理解为他们的核心业务。我的理解就是AOP某个系统中定义的一些公共行为，专业名词为“横切关注点”，OOP则是其独有行为，称之为“核心关注点”。Spring AOP是AOP的一种实现方式，还有一种实现方式是AspectJ，Spring AOP借用了AspectJ的语法。Spring AOP里几个比较关键的概念：pointCut：切点，定义拦截的行为或者标志；join point：连接点，由于Spring只支持方法级别的连接点，所以在Spring中，join point就是一个方法，但是广义的join point不光是方法，也能是变量或者类；aspect：切面，点构成面，即横切关注点抽象出来组织成一个切面；advice：通知，满足拦截的行为的标志以后执行的操作，通知分为前置、后置、异常、最终、环绕五大类（后面再写详细点）；weave：织入，将切面功能注入进目标方法并创建代理对象的过程；introduction：引入，通过动态代理在运行期为类动态添加一些行为或属性；Spring Aop代理由Spring 的IOC容器生成，管理。所以AOP代理可以使用容器中的其他bean作为代理目标，一般情况下，Spring会使用JDK的动态代理来创建AOP代理，当要代理的对象不是接口时，会使用CGLIB的方式来创建代理，也可以强制使用cglib的方式，代码如下：xml方式：&lt;aop:aspectj-autoproxy proxy-target-class=&quot;true&quot; /&gt;spring boot:@EnableAspectJAutoProxy使用Spring AOP进行编程，通常来说有以下三步：定义核心业务组件；定义切点和切面，一个切点和切面可以横跨多个业务；定义增强处理，这里就是AOP为业务组件织入的处理动作。实战举例场景1：统计网站访问来源假如我有一个个人网站，我想统计一下某个接口的访问数，或者主页的访问数，访问来源，并记录下这个访问，那么就可以使用AOP来实现。step 1：定义切面，切面可以是一个类作为切面；step 2：定义切点，需求简单，由于我的接口基本都在包com.blog.controller下，所以使用execution ​表达式即可，可以参考https://docs.spring.io/spring/docs/current/spring-framework-reference/core.html#aop网站，这里随便记一下execution的格式，根据官网介绍，execution的格式类似于execution(modifiers-pattern?ret-type-patterndeclaring-type -pattern?name-pattern(param-pattern) throws-pattern?) 对应中文为execution(访问修饰符表达式？ 返回值类型表达式 名称表达式（参数表达式）异常表达式? )，除了名称表达式，其他表达式都可以不写，下面介绍几种常用的特殊通配符：访问修饰符表达式：不写代表所有访问修饰符；返回值类型表达式：*在返回类型通配符中代表所有返回值类型；名称通配符：*在名称通配符中是代表所有的意思，.在名称通配符中代表当前包或者当前类，..两个点表示当前包以及子包；参数表达式：不写表示无参方法，..表示0或多个参数，*表示任何类型的一个参数，那么*，String就表示一个任意类型的参数+一个String类型的参数；异常表达式：格式为throws(*)表示所有异常。那么贴出切点定义：1234@Pointcut(value="execution(public*com.blog.controller..*.*(..))") public void pointCut()&#123; &#125;step3：定义增强处理，首先确认通知类型：前置通知[Before advice]：在连接点前面执行，前置通知不会影响连接点的执行，除非此处抛出异常。正常返回通知[After returning advice]：在连接点正常执行完成后执行，如果连接点抛出异常，则不会执行。异常返回通知[After throwing advice]：在连接点抛出异常后执行。返回通知[After (finally) advice]：在连接点执行完成后执行，不管是正常执行完成，还是抛出异常，都会执行返回通知中的内容。环绕通知[Around advice]：环绕通知围绕在连接点前后，比如一个方法调用的前后。这是最强大的通知类型，能在方法调用前后自定义一些操作。环绕通知还需要负责决定是继续处理join point(调用ProceedingJoinPoint的proceed方法)还是中断执行。我的需求是在返回以后都要记录访问来源，所以使用返回通知类型，代码如下：12345678910111213@After(value="pointCut())")public void after(JoinPoint joinPoint)&#123; PvLogpvLog=newPvLog(); LOGGER.info("当前请求的方法名:&#123;&#125;",joinPoint.getSignature().getName()); HttpServletRequestrequest=((ServletRequestAttributes)RequestContextHolder.getRequestAttributes()).getRequest(); StringrealIp=HttpUtil.getIpAddr(request); LOGGER.info("当前请求来源IP地址为:&#123;&#125;",realIp); pvLog.setUpdateTime(newDate()); pvLog.setReferer(request.getHeader("Referer")); pvLog.setVisitTime(1); pvLog.setIp(realIp); pvLogMapper.insert(pvLog);&#125;需要记住，执行这个方法传入参数不能是注解中定义的value里没有的，例如我代码中想传两个参数一个是连接点，一个是注解，所以value中就是pointCut()和@annotation()，如果你想传入一个参数那么就是args(参数名)。拓展一下切入点指示符（PCD）：execution:匹配方法执行连接点；within：限制匹配某些类型中的连接点（spring aop中连接点通常指方法，以下相同）；args：限制匹配指定参数的连接点，其中参数是指参数名；@args：限制匹配指定带有指定注解的参数的连接点；@annotation：限制匹配带有某个注解的方法。spring aop可以使用&amp;&amp; ，|| ，！来对PCD进行逻辑运算。场景2：统计一个方法执行的时间step1:定义一个切面；step2:定义切点和增强，这里我想更灵活一些，通过注解实现我指定的方法来监控执行时长，因此我需要一个自定义注解。这是打印日志的级别：12345678public enum LoggerEnums &#123; INFO, DEBUG, WARN, ERROR;&#125;自定义注解：123456789@Documented@Target(&#123;ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)@Inheritedpublic @interface AopLog &#123; LoggerEnums value() default LoggerEnums.INFO;&#125;自定义注解小扩展：@Documented：该注解是否包含在javadoc中；@Inherited：该注解是否允许被继承；@Target：该注解表示可以被写在什么位置，枚举类型，常用有：TYPE表示接口、类、枚举、注解；METHOD表示方法，FIELD表示字段或枚举常量，PARAMETER表示方法参数，CONSTRUCTOR表示构造函数；@Rentention：表示保留级别，分别有RESOURCE（只存在于源码，如@Override和@SuppressWarnings），CLASS（存在于源码和CLASS文件中），RUNTIIME（保留到运行时）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@Component@Aspectpublic class LogAspect &#123; private final static Logger LOGGER = LoggerFactory.getLogger(LogAspect.class); /** *@description: 定义切点 *@author: 刘会俊 *@params: [] *@return: void */@Pointcut("@annotation(com.example.aisino.aop.AopLog)") public void pointCut()&#123; &#125; /** *@description: 定义环绕通知，计算方法执行时长 *@author: 刘会俊 *@params: [proceedingJoinPoint] *@return: java.lang.Object */ @Around("pointCut() &amp;&amp; @annotation(AopLog)") public Object printRequestLog(ProceedingJoinPoint proceedingJoinPoint)&#123; long startTime = System.currentTimeMillis(); Object object = null; MethodSignature methodSignature = (MethodSignature)proceedingJoinPoint.getSignature(); String methodName = methodSignature.getName(); AopLog aopLog = methodSignature.getMethod().getDeclaredAnnotation(AopLog.class); try &#123; object = proceedingJoinPoint.proceed(); &#125; catch (Throwable throwable) &#123; LOGGER.error("执行&#123;&#125;方法报错",methodName,throwable); &#125; execTime(methodName, startTime, System.currentTimeMillis(),aopLog); return object; &#125; private void execTime(String name,long startTime,long endTime,AopLog aopLog )&#123; long usetime = endTime - startTime; long threadId = Thread.currentThread().getId(); if (usetime &gt; 1000) LOGGER.warn("当前线程&#123;&#125;执行&#123;&#125;方法执行时间可能过长，时间为&#123;&#125;秒",threadId,name,usetime/1000L); else if (aopLog.value() == LoggerEnums.DEBUG) LOGGER.debug("当前线程&lt;&#123;&#125;&gt;执行&lt;&#123;&#125;&gt;方法执行时长为:&#123;&#125;毫秒",threadId,name,usetime); else if (aopLog.value() == LoggerEnums.WARN) LOGGER.warn("当前线程&lt;&#123;&#125;&gt;执行&lt;&#123;&#125;&gt;方法执行时长为:&#123;&#125;毫秒",threadId,name,usetime); else if (aopLog.value() == LoggerEnums.ERROR) LOGGER.error("当前线程&lt;&#123;&#125;&gt;执行&lt;&#123;&#125;&gt;方法执行时长为:&#123;&#125;毫秒",threadId,name,usetime); else LOGGER.info("当前线程&lt;&#123;&#125;&gt;执行&lt;&#123;&#125;&gt;方法执行时长为:&#123;&#125;毫秒",threadId,name,usetime); &#125;&#125;数据源配置：场景3：动态切换 数据源step1:定义切面；step2:定义切换数据源方法（假设你已经定义了两个DataSource的Spring Bean），即自定义一个数据源key的获取方法，数据源在mybatis中就是存放于Map&lt;String,Object&gt;：12345678910111213public class DataSourceContextHolder &#123; public static final String DEFAULT_DATASOURCE="ds1"; private static final ThreadLocal&lt;String&gt; contextHolder = new ThreadLocal&lt;&gt;(); public static void setDatasource(String datasource)&#123; contextHolder.set(datasource); &#125; public static String getDatasource()&#123; return contextHolder.get(); &#125;定义一个数据源路由类，以及两个key，分别为DS1和DS2，作为Spring Bean管理：12345678public class DynamicDatasource extends AbstractRoutingDataSource &#123; @Override protected Object determineCurrentLookupKey() &#123; // 从自定义的位置获取数据源标识 return DataSourceContextHolder.getDataSource(); &#125;&#125;使用自定义注解：12345678@Target(value = &#123;ElementType.TYPE,ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)@Componentpublic @interface DataSource &#123; String value() default "";&#125;定义切点和增强：1234567891011121314151617181920212223242526272829303132@Component@Aspect@Order(1)public class DataSourceAop &#123; private final static Logger LOGGER = LoggerFactory.getLogger(DataSourceAop.class); @Pointcut(value = "@annotation(com.blog.aop.DataSource)") public void pointCut()&#123; &#125; @Before(value = "pointCut()") public void changeDataSource(JoinPoint joinPoint)&#123; Class clazz = joinPoint.getTarget().getClass(); MethodSignature methodSignature = (MethodSignature) joinPoint.getSignature(); String name = methodSignature.getName(); Class[] clazzes = methodSignature.getParameterTypes(); try &#123; Method method = clazz.getMethod(name, clazzes); if(method.isAnnotationPresent(DataSource.class) || clazz.isAnnotationPresent(DataSource.class))&#123; DataSource dataSource = method.getAnnotation(DataSource.class); LOGGER.info("开始切换为数据源:&#123;&#125;",dataSource.value()); if(!StringUtils.isEmpty(dataSource.value()))&#123; DataSourceContextHolder.setDatasource(dataSource.value()); &#125;else DataSourceContextHolder.setDatasource(DataSourceContextHolder.DEFAULT_DATASOURCE); &#125; &#125; catch (NoSuchMethodException e) &#123; e.printStackTrace(); &#125; &#125;&#125;如果使用配置文件xml的形式：1234567891011&lt;bean id="routingDataSource" class="com.blog.util.DynamicDatasource"&gt; &lt;property name="targetDataSources"&gt; &lt;map key-type="java.lang.String"&gt; &lt;!-- 指定lookupKey和与之对应的数据源 --&gt; &lt;entry key="ds1" value-ref="ds1"&gt;&lt;/entry&gt; &lt;entry key="ds2" value-ref="ds2"&gt;&lt;/entry&gt; &lt;/map&gt; &lt;/property&gt; &lt;!-- 这里可以指定默认的数据源 --&gt; &lt;property name="defaultTargetDataSource" ref="ds1" /&gt; &lt;/bean&gt;如果使用spring boot的方式：配置文件如下，需要注意的是在spring boot 2.0以后，默认数据源成了HikariDataSource，而Hikari读取的数据库连接地址名称叫jdbc-url，而不是spring读取的url，所以我们要把url改成jdbc-url，直接让Hikari来读取：123456789101112131415161718spring: datasource: db1: type: com.zaxxer.hikari.HikariDataSource hikari: minimum-idle=5 connection-test-query=SELECT 1 username: root password: root jdbc-url: jdbc:mysql://localhost:3306/blog?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNull&amp;useSSL=false&amp;allowMultiQueries=true db2: type: com.zaxxer.hikari.HikariDataSource hikari: minimum-idle=5 connection-test-query=SELECT 1 username: root password: root jdbc-url: jdbc:mysql:/0.0.0.0:3306/blog?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNull&amp;useSSL=false&amp;allowMultiQueries=true然后启动类需要禁用spring boot的单数据源自动配置，并且注册两个数据源和动态数据源如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051@EnableAspectJAutoProxy@SpringBootApplication(exclude = DataSourceAutoConfiguration.class)@MapperScan("com.blog.mapper")public class MyBlogApplication &#123; /** *@description: DataSourceBuilder是spring 默认创建DataSource的建造者 *@author: 刘会俊 *@params: [] *@return: javax.sql.DataSource */ @Bean(name="ds1") @ConfigurationProperties(prefix = "spring.datasource.db1") public DataSource dataSource1()&#123; return DataSourceBuilder.create().build(); &#125; @Bean(name="ds2") @ConfigurationProperties(prefix = "spring.datasource.db2") public DataSource dataSource2()&#123; return DataSourceBuilder.create().build(); &#125; /** *@description: 由于这里有三个同为DataSource的bean，所以spring在设置jdbc连接的数据源时不知道用哪个，使用Primary注解表示spring优先使用这个datasource，这样就可以实现动态切换了 * *@author: 刘会俊 *@params: [] *@return: javax.sql.DataSource */ @Primary @Bean(name = "dynamicDateSource" ) public DataSource dynamicDatasource()&#123; DynamicDatasource dynamicDatasource = new DynamicDatasource(); dynamicDatasource.setDefaultTargetDataSource(dataSource1()); Map&lt;Object, Object&gt; map = new HashMap&lt;&gt;(); map.put("ds1", dataSource1()); map.put("ds2", dataSource2()); dynamicDatasource.setTargetDataSources(map); return dynamicDatasource; &#125; @Bean public PlatformTransactionManager transactionManager()&#123; return new DataSourceTransactionManager(dynamicDatasource()); &#125; public static void main(String[] args) &#123; SpringApplication.run(MyBlogApplication.class, args); &#125;&#125;如果不想改变spring 的配置文件的数据库连接url，也可以先初始化一个DatasourceProperties的bean，然后利用这个spring 读取的配置文件将其中一些参数传递给HikariDataSource，如下：123456789@Bean(name="ds2Prop") @ConfigurationProperties(prefix = "spring.datasource.db2") public DataSourceProperties dataSource2()&#123; return new DataSourceProperties(); &#125;@Bean(name = "ds2") public HikariDataSource hkds()&#123; return dataSource2().initializeDataSourceBuilder().type(HikariDataSource.class).build(); &#125;总结：多数据源配置稍微麻烦一些，第一步建立一个线程安全的数据源标识符存放和切换的类，第二步是一个继承了AbstractRoutingDataSource的子类用来重写父类方法来获取自定义数据源标识，第三步是建立多个DataSource的Bean，以及动态切换数据源的spring bean，并将多个数据源放入目标数据源的map里，加入事务控制，最后建立切面，通过读取连接点的注解或者连接点的类上的注解，在前置通知里调用工具类进行切换标识。]]></content>
      <categories>
        <category>编程技术</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>随记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git+Hexo搭建个人博客]]></title>
    <url>%2Fgit-hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2.html</url>
    <content type="text"><![CDATA[简述环境：腾讯云服务器+新网域名，github，hexo需求：www.guitar-coder.cn指向服务器主站，blog.guitar-coder.cn指向github.io，写个人笔记和博客。步骤安装nodejs下载nodeJS，官网https://nodejs.org/en/windows或者mac可以下载可执行文件直接一路安装即可，当然mac也可以执行brew install node,至于linux下，这里以二进制binary为例（来源于官网教程）：12345678910111213141516171819#定义linux变量VERSION=v8.11.4DISTRO=linux-x64sudo mkdir /usr/local/lib/nodejssudo tar -xJvf node-$VERSION-$DISTRO.tar.xz -C /usr/local/lib/nodejs sudo mv /usr/local/lib/nodejs/node-$VERSION-$DISTRO /usr/local/lib/nodejs/node-$VERSION#修改~/.profile文件（用户变量）或者/etc/profile（全局环境变量）export NODEJS_HOME=/usr/local/lib/nodejs/node-$VERSION/binexport PATH=$NODEJS_HOME:$PATH#变量生效. ~/.profilenode -vnpm version#将node命令连接到系统命令目录下sudo ln -s /usr/local/lib/nodejs/node-$VERSION/bin/node /usr/bin/nodesudo ln -s /usr/local/lib/nodejs/node-$VERSION/bin/npm /usr/bin/npmsudo ln -s /usr/local/lib/nodejs/node-$VERSION/bin/npx /usr/bin/npx为了方便访问，使用国内淘宝的npm镜像：npm install -g cnpm --registry=https://registry.npm.taobao.org ​以后npm和cnpm都可以用，效果基本一致，cnpm的速度更快。安装hexo首先需要安装hexo-cli脚手架工具：cnpm install hexo-cli -g然后创建一个空目录，名为blog，进入目录执行初始化：hexo init生成静态页面：hexo generate或者hexo g启动本地服务：hexo server或者hexo s出现如下结果，即可预览本地4000端口的个人主页，默认用的都是theme下的landscape主题：liuhuijundeMacBook-Air:blog liuhuijun$ hexo s INFO Start processing INFO Hexo is running at http://localhost:4000 . Press Ctrl+C to stop. 如果遇到ERROR Local hexo not found in ~/Desktop/blog ERROR Try running: &apos;npm install hexo --save&apos; 这种错，有可能是由于modules下载出现问题，删除node_modules文件夹，然后重新执行cnpm install 或者 npm install即可。远程部署在github或者gitee上新建一个仓库，可以不用gitignore，hexo已经自动生成，readme文件也可以随意。在blog目录下找到.config.yml文件，编辑，找到deploy模块，改成仓库地址，记住yml文件格式要求value前面有一个空格。deploy: type: git repo: your url branch: master 执行：cnpm intall hexo-deployer-git --save每一次新写文章，可以通过hexo clean &amp;&amp; hexo generate &amp;&amp; hexo deploy发布到博客。多机器开发此时线上的仓库里会有hexo编译成js以后的文件，还需要新建分支存放源代码：git checkout -b source git add ./ git commit -m &quot;&quot; git push origin source master分支用于存放页面，source用于存放源代码。自定义域名将blog.guitar-coder.cn指向github提供的pages。默认情况下github提供的pages是Repository name，当然我的guitar-coder.cn已经备案过。在github settings页面，填入自己的域名，如图：然后在hexo的source文件夹内新建CNAME文件，里面只需要填入你的个人域名blog.guitar-coder.cn（无需http或者https）,记住一定要push到source分支并且deploy到master分支。最后一定要配置好域名解析：因为我是要把blog.guitar-coder.cn转发到github pages的liuhuijun11832.github.io的页面，所以需要配置CNAME，这里也可以先ping 通liuhuijun11832.github.io的IP地址，然后使用记录类型A来进行解析。每个DNS服务商的刷新速度不一致，静等片刻即可。推送博客新建一篇博文：hexo new &quot;test&quot;然后找一个能够实时渲染效果的markdown编辑器，mac下推荐macdown，windows下我习惯使用markdown pad2（需要安装awison-sdk插件实时渲染），打开source/_posts/test.md完成以后使用hexo clean &amp;&amp; hexo g&amp;&amp; hexo d即可发布。参考https://haoshuai6.github.io/2016-11-25-Hexo-github-cname.html个人博客演示地址：https://blog.guitar-coder.cn/支付宝/微信 二维码生成（app生成的太不美观）：https://cli.im/weixin图标查询：https://fontawesome.com/icons?d=gallery]]></content>
      <categories>
        <category>编程技术</category>
      </categories>
      <tags>
        <tag>随记</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
